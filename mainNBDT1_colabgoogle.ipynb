{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1si0P8tFT072L1JA6f9OU0NxRgm0PdYdm",
      "authorship_tag": "ABX9TyPwE0/6azzDzDgv7/8Rb3ny",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukeliuli/SUMONBDT/blob/main/mainNBDT1_colabgoogle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd  /content/drive/MyDrive/SUMONBDT\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "import time\n",
        "from collections import namedtuple\n",
        "import resnet\n",
        "\n",
        "\n",
        "\n",
        "outputNow =torch.Tensor()\n",
        "inputNow = ()\n",
        "def hook(module, input, output):\n",
        "    '''把这层的输出拷贝到features中'''\n",
        "    global inputNow\n",
        "    global outputNow\n",
        "   \n",
        "    print(input[0].shape)\n",
        "    inputNow=input[0].clone().detach()\n",
        "    outputNow=output.clone().detach()\n",
        "    #inputNow =  input\n",
        "    \n",
        "\n",
        "    \n",
        "    #print(output.data)\n",
        "    #print(input[0].data)\n",
        "    #print(input[0].data.size())\n",
        "    #print(module.weight)\n",
        "    #print(module.bias)\n",
        "    #print(inputNow)\n",
        "    #print(outputNow)\n",
        "\n",
        "transform1 = transforms.Compose(\n",
        "    [transforms.RandomCrop(32, padding=4),  # 先四周填充0，在吧图像随机裁剪成32*32\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])  # R,G,B每层的归一化用到的均值和方差\n",
        "\n",
        "\n",
        "#transform1 = transforms.Compose(\n",
        "#    [transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])  # R,G,B每层的归一化用到的均值和方差\n",
        "\n",
        "batch_sizeV = 512\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform1)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_sizeV, shuffle=True, num_workers=2)\n",
        "\n",
        "batch_sizeV = 2\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform1)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_sizeV, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "startEpoch = 0\n",
        "\n",
        "#resnet18 = models.resnet18(pretrained=False)#采用torchvision的模型，无法达到94%的正确率，最多88%\n",
        "resnet18 = resnet.resnet18(num_classes=10)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "resnet18 = resnet18.to(device)\n",
        "\n",
        "\n",
        "modelPathName = \"/content/drive/MyDrive/SUMONBDT/trainedModes/resnet18End_accuray95.modeparams\"\n",
        "modelPath = \"/content/drive/MyDrive/SUMONBDT/trainedModes/\"\n",
        "params = torch.load(modelPathName, map_location=device)\n",
        "resnet18.load_state_dict(params[\"net\"])\n",
        "startEpoch = params[\"epoch\"]\n",
        "#print(params)\n",
        "\n",
        "\n",
        "#######################################################################\n",
        "##基于hook和name_parameters.看输出数据类型和值,网络权值\n",
        "for name, parameters in resnet18.named_parameters():\n",
        "    #print(name, ':', parameters.size())\n",
        "    params[name] = parameters.detach()\n",
        "#print(params[\"fc.bias\"])\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "outputs = resnet18(images)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "#print(outputs.data.numpy())\n",
        "print(\"predicted:\",predicted)\n",
        "print(\"labels:\",labels)\n",
        "print(\"outputs:\",outputs)\n",
        "\n",
        "\n",
        "#######################################################################\n",
        "##基于hook和name_parameters.看输出数据类型和值,网络权值\n",
        "handle = resnet18.fc.register_forward_hook(hook)\n",
        "outputs = resnet18(images)\n",
        "handle.remove()\n",
        "print(\"inputNow:\",inputNow)\n",
        "print(\"outputNow:\",outputNow)\n",
        "\n",
        "w0 = params[\"fc.weight\"]  # 10x512\n",
        "bias = params[\"fc.bias\"]  # 10x512\n",
        "\n",
        "outTmp = torch.mm(inputNow,w0.transpose(0,1))+bias\n",
        "_, predictedTmp = torch.max(outTmp.data, 1)\n",
        "print(\"outTmp:\",outTmp)\n",
        "print(\"predictedTmp:\",predictedTmp)\n",
        "########################################################################\n",
        "###简单的分级识别\n",
        "#GOD: 1. plane,bird\n",
        "#     2. deer,dog,horse,cat,frog\n",
        "#     3. car,truck,ship\n",
        "#classes = ('plane' 0, 'car' 1, 'bird' 2, 'cat' 3,\n",
        "#           'deer' 4, 'dog' 5, 'frog' 6, 'horse' 7 , 'ship' 8,  'truck' 9)\n",
        "#layerA         0 \n",
        "#layerB      1 (likebird)       2 (likecat)                           3(likecar)\n",
        "#layerC  plane,bird     deer,dog,horse,cat,frog   car,truck,ship     car,truck,ship\n",
        "\n",
        "#w0 = params[\"fc.weight\"].numpy()  # 10x512\n",
        "#bias = params[\"fc.bias\"].numpy()  # 10x512\n",
        "#wA_B = {}\n",
        "#bA_B = {}\n",
        "\n",
        "\n",
        "#wA_B['0_1_likebird'] =  (w0[0]+w0[2])/2\n",
        "#bA_B['0_1_likebird'] = (bias[0]+bias[2])/2\n",
        "\n",
        "\n",
        "#wA_B['0_2_likecat'] = (w0[3]+w0[4]+w0[5]+w0[6]+w0[7])/6\n",
        "#bA_B['0_2_likecat'] = (bias[3]+bias[4]+bias[5]+bias[6]+bias[7])/6\n",
        "\n",
        "#wA_B['0_3_likecar'] = (w0[1]+w0[8]+w0[9])/3\n",
        "#bA_B['0_3_likecar'] = (bias[1]+bias[8]+bias[9])/3\n",
        "print(\"####################################################\")\n",
        "#print(wA_B['0_1_likebird'])\n",
        "#inputTmp = inputNow[0]\n",
        "#outputTmp = outputNow[0]\n",
        "#print(inputTmp)\n",
        "#print(outputTmp)\n",
        "#handle.remove()\n",
        "\n",
        "#z= np.dot(inputTmp, w0.T)+bias\n",
        "#print(z)\n",
        "print(\"####################################################\")\n",
        "\n",
        "#s1 =np.dot(inputTmp,wA_B['0_1_likebird'])+bA_B['0_1_likebird']\n",
        "#s2 =np.dot(inputTmp,wA_B['0_2_likecat'])+bA_B['0_2_likecat']\n",
        "#s3 =np.dot(inputTmp,wA_B['0_3_likecar'])+bA_B['0_3_likecar']\n",
        "#print(s1)\n",
        "#print(s2)\n",
        "#print(s3)\n",
        "\n",
        "#wTmp = wA_B['0_1_likebird'].unsqueeze(1)\n",
        "#s1 =torch.mm(inputNow,wTmp)+bA_B['0_1_likebird']\n",
        "#wTmp = wA_B['0_2_likecat'].unsqueeze(1)\n",
        "#s2 =torch.mm(inputNow,wTmp)+bA_B['0_2_likecat']\n",
        "#wTmp = wA_B['0_3_likecar'].unsqueeze(1)\n",
        "#s3 =torch.mm(inputNow,wTmp)+bA_B['0_3_likecar']\n",
        "#print(s1)\n",
        "#print(s2)\n",
        "#print(s3)\n",
        "\n",
        "\n",
        "##########################################################################################\n",
        "###开始训练\n",
        "print(\"##开始训练################################################################################\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "resnet18 = resnet18.to(device)\n",
        "\n",
        "# trainloader\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet18.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "if device == 'cuda':\n",
        "  resnet18 = torch.nn.DataParallel(resnet18)\n",
        "  cudnn.benchmark = True\n",
        "\n",
        "startEpoc = 0\n",
        "epochs = 1000\n",
        "resnet18.train()\n",
        "print(\"start training\")\n",
        "for epoch in range(startEpoch, epochs):  # 多批次循环\n",
        "\n",
        "     resnet18.train()\n",
        "     running_loss = 0.0\n",
        "     time_start = time.time()\n",
        "     #learning rate 不变\n",
        "#     #adjust_learning_rate(optimizer, epoch, epochs, trainloader, batch_sizeV)\n",
        "     total = 0\n",
        "     correct = 0\n",
        "     for i, data in enumerate(trainloader, 0):\n",
        "         # 获取输入\n",
        "         #print(epoch,i)\n",
        "         inputs, labels = data\n",
        "\n",
        "         inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "         # 梯度置0\n",
        "         optimizer.zero_grad()\n",
        "\n",
        "         # 正向传播，反向传播，优化a\n",
        "         outputs = resnet18(inputs)\n",
        "         loss = criterion(outputs, labels)\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "\n",
        "         _, predicted = outputs.max(1)\n",
        "         total += labels.size(0)\n",
        "         correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "         # 打印状态信息\n",
        "         running_loss += loss.item()\n",
        "         if i % 20 == 19:  # 每200批次打印一次\n",
        "             time_end = time.time()\n",
        "             print('one 20 batch totally time cost %.3f' %(time_end-time_start))\n",
        "             print(\"batchIndex %d |trainLen %d | Loss: %.3f | Acc: %.3f | correct, total: (%d,%d)\" % (\n",
        "                 i, len(trainloader), running_loss/(i+1), 100.*correct/total, correct, total))\n",
        "\n",
        "     time_end = time.time()\n",
        "     print('epoch %d totally time cost %.3f' % (epoch, time_end-time_start))\n",
        "     state = {\"net\": resnet18.state_dict(), \"optimizer\": optimizer.state_dict(), \"epoch\": epoch}\n",
        "     modelPath = \"/content/drive/MyDrive/SUMONBDT/trainedModes\"\n",
        "     modelPathNameTmp = modelPath+\"/resnet18_\"+str(epoch)+\".modeparams\"\n",
        "     torch.save(state, modelPathNameTmp)\n",
        "     params = torch.load(modelPathNameTmp)\n",
        "     resnet18.load_state_dict(params[\"net\"])\n",
        "     optimizer.load_state_dict(params[\"optimizer\"])\n",
        "     #evalCifar(testloader, resnet18, classes)\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "#有两种方法，一种只保存参数，一种全保存，后者简单但存储量大，我用的是前者\n",
        "# # 保存和加载整个模型\n",
        "state = {\"net\": resnet18.state_dict(), \"optimizer\": optimizer.state_dict(), \"epoch\": epoch}\n",
        "modelPath = \"/content/drive/MyDrive/SUMONBDT/trainedModes\"\n",
        "modelPathName = modelPath+\"/resnet18_End\"+\".modeparams\"\n",
        "torch.save(state, modelPathName)\n",
        "params = torch.load(modelPathName)\n",
        "resnet18.load_state_dict(params['net'])\n",
        "optimizer.load_state_dict(params['optimizer'])\n",
        "\n",
        "# # 仅保存和加载模型参数(推荐使用)\n",
        "#torch.save(resnet18.state_dict(), './trainedModes/resnet18params.pkl')\n",
        "#resnet18.load_state_dict(torch.load('./trainedModes/resnet18params.pkl'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWSjWG0Qmpdm",
        "outputId": "a84a7cc4-5f7c-4a3c-de5d-de3c06b1761e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SUMONBDT\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "cuda\n",
            "predicted: tensor([3, 8], device='cuda:0')\n",
            "labels: tensor([3, 8], device='cuda:0')\n",
            "outputs: tensor([[-0.9038, -1.6213,  1.0547,  3.0344, -0.6569, -0.4190,  0.9986, -0.3695,\n",
            "         -1.5974,  0.4802],\n",
            "        [ 0.6200,  2.0913, -1.3626, -1.9636,  0.3405,  0.1983, -1.0960, -0.3589,\n",
            "          2.2784, -0.7471]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "torch.Size([2, 512])\n",
            "inputNow: tensor([[0.0277, 0.0183, 0.0287,  ..., 0.0040, 0.0728, 0.2346],\n",
            "        [0.1702, 0.1381, 0.0808,  ..., 0.1131, 0.0077, 0.0038]],\n",
            "       device='cuda:0')\n",
            "outputNow: tensor([[-0.9038, -1.6213,  1.0547,  3.0344, -0.6569, -0.4190,  0.9986, -0.3695,\n",
            "         -1.5974,  0.4802],\n",
            "        [ 0.6200,  2.0913, -1.3626, -1.9636,  0.3405,  0.1983, -1.0960, -0.3589,\n",
            "          2.2784, -0.7471]], device='cuda:0')\n",
            "outTmp: tensor([[-0.9038, -1.6213,  1.0547,  3.0344, -0.6569, -0.4190,  0.9986, -0.3695,\n",
            "         -1.5974,  0.4802],\n",
            "        [ 0.6200,  2.0913, -1.3626, -1.9636,  0.3405,  0.1983, -1.0960, -0.3589,\n",
            "          2.2784, -0.7471]], device='cuda:0')\n",
            "predictedTmp: tensor([3, 8], device='cuda:0')\n",
            "####################################################\n",
            "####################################################\n",
            "##开始训练################################################################################\n",
            "cuda\n",
            "start training\n",
            "one 20 batch totally time cost 26.980\n",
            "batchIndex 19 |trainLen 98 | Loss: 0.001 | Acc: 100.000 | correct, total: (10240,10240)\n",
            "one 20 batch totally time cost 53.391\n",
            "batchIndex 39 |trainLen 98 | Loss: 0.001 | Acc: 100.000 | correct, total: (20480,20480)\n",
            "one 20 batch totally time cost 79.771\n",
            "batchIndex 59 |trainLen 98 | Loss: 0.002 | Acc: 100.000 | correct, total: (30720,30720)\n",
            "one 20 batch totally time cost 106.155\n",
            "batchIndex 79 |trainLen 98 | Loss: 0.002 | Acc: 100.000 | correct, total: (40960,40960)\n",
            "epoch 268 totally time cost 129.606\n",
            "one 20 batch totally time cost 27.004\n",
            "batchIndex 19 |trainLen 98 | Loss: 0.001 | Acc: 100.000 | correct, total: (10240,10240)\n",
            "one 20 batch totally time cost 53.518\n",
            "batchIndex 39 |trainLen 98 | Loss: 0.002 | Acc: 100.000 | correct, total: (20480,20480)\n",
            "one 20 batch totally time cost 79.983\n",
            "batchIndex 59 |trainLen 98 | Loss: 0.002 | Acc: 100.000 | correct, total: (30720,30720)\n",
            "one 20 batch totally time cost 106.464\n",
            "batchIndex 79 |trainLen 98 | Loss: 0.002 | Acc: 100.000 | correct, total: (40960,40960)\n",
            "epoch 269 totally time cost 130.012\n",
            "one 20 batch totally time cost 26.903\n",
            "batchIndex 19 |trainLen 98 | Loss: 0.002 | Acc: 100.000 | correct, total: (10240,10240)\n",
            "one 20 batch totally time cost 53.291\n",
            "batchIndex 39 |trainLen 98 | Loss: 0.002 | Acc: 100.000 | correct, total: (20480,20480)\n",
            "one 20 batch totally time cost 79.685\n",
            "batchIndex 59 |trainLen 98 | Loss: 0.002 | Acc: 100.000 | correct, total: (30720,30720)\n",
            "one 20 batch totally time cost 106.059\n",
            "batchIndex 79 |trainLen 98 | Loss: 0.002 | Acc: 100.000 | correct, total: (40960,40960)\n",
            "epoch 270 totally time cost 129.527\n",
            "one 20 batch totally time cost 26.764\n",
            "batchIndex 19 |trainLen 98 | Loss: 0.002 | Acc: 100.000 | correct, total: (10240,10240)\n",
            "one 20 batch totally time cost 53.053\n",
            "batchIndex 39 |trainLen 98 | Loss: 0.002 | Acc: 100.000 | correct, total: (20480,20480)\n"
          ]
        }
      ]
    }
  ]
}