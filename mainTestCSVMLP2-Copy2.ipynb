{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6a93409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (fc1): Linear(in_features=14, out_features=200, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fc4): Linear(in_features=100, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "(723532,)\n",
      "(723532, 14)\n",
      "start training\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 1.187 | Acc: 46.191 | correct, total: (473,1024)\n",
      "##########one 200 batch totally time cost 1.497\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.518 | Acc: 82.058 | correct, total: (84868,103424)\n",
      "##########one 200 batch totally time cost 2.980\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.441 | Acc: 83.959 | correct, total: (172807,205824)\n",
      "##########one 200 batch totally time cost 4.891\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.406 | Acc: 84.916 | correct, total: (261733,308224)\n",
      "##########one 200 batch totally time cost 6.291\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.380 | Acc: 85.701 | correct, total: (351910,410624)\n",
      "##########one 200 batch totally time cost 7.707\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.362 | Acc: 86.334 | correct, total: (442914,513024)\n",
      "##########one 200 batch totally time cost 9.111\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.347 | Acc: 86.829 | correct, total: (534365,615424)\n",
      "##########one 200 batch totally time cost 10.470\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.335 | Acc: 87.251 | correct, total: (626306,717824)\n",
      "epochIndex 0 |time: 10 | Acc: 87.277 | correct, total: (631478,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.060\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.254 | Acc: 89.746 | correct, total: (919,1024)\n",
      "##########one 200 batch totally time cost 1.474\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.248 | Acc: 90.205 | correct, total: (93294,103424)\n",
      "##########one 200 batch totally time cost 2.907\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.250 | Acc: 90.131 | correct, total: (185511,205824)\n",
      "##########one 200 batch totally time cost 4.770\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.245 | Acc: 90.254 | correct, total: (278186,308224)\n",
      "##########one 200 batch totally time cost 6.189\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.245 | Acc: 90.247 | correct, total: (370576,410624)\n",
      "##########one 200 batch totally time cost 7.546\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.242 | Acc: 90.335 | correct, total: (463440,513024)\n",
      "##########one 200 batch totally time cost 8.954\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.240 | Acc: 90.411 | correct, total: (556408,615424)\n",
      "##########one 200 batch totally time cost 10.367\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.237 | Acc: 90.484 | correct, total: (649514,717824)\n",
      "epochIndex 1 |time: 10 | Acc: 90.495 | correct, total: (654758,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.203 | Acc: 92.188 | correct, total: (944,1024)\n",
      "##########one 200 batch totally time cost 1.477\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.238 | Acc: 90.475 | correct, total: (93573,103424)\n",
      "##########one 200 batch totally time cost 2.886\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.226 | Acc: 90.883 | correct, total: (187060,205824)\n",
      "##########one 200 batch totally time cost 4.232\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.228 | Acc: 90.822 | correct, total: (279934,308224)\n",
      "##########one 200 batch totally time cost 5.736\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.227 | Acc: 90.876 | correct, total: (373160,410624)\n",
      "##########one 200 batch totally time cost 7.553\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.226 | Acc: 90.904 | correct, total: (466361,513024)\n",
      "##########one 200 batch totally time cost 8.972\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.225 | Acc: 90.938 | correct, total: (559655,615424)\n",
      "##########one 200 batch totally time cost 10.423\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.224 | Acc: 90.984 | correct, total: (653105,717824)\n",
      "epochIndex 2 |time: 10 | Acc: 90.988 | correct, total: (658324,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.198 | Acc: 91.895 | correct, total: (941,1024)\n",
      "##########one 200 batch totally time cost 1.478\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.204 | Acc: 91.567 | correct, total: (94702,103424)\n",
      "##########one 200 batch totally time cost 2.908\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.206 | Acc: 91.481 | correct, total: (188290,205824)\n",
      "##########one 200 batch totally time cost 4.292\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.207 | Acc: 91.483 | correct, total: (281974,308224)\n",
      "##########one 200 batch totally time cost 6.272\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.206 | Acc: 91.524 | correct, total: (375820,410624)\n",
      "##########one 200 batch totally time cost 7.692\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.205 | Acc: 91.549 | correct, total: (469666,513024)\n",
      "##########one 200 batch totally time cost 9.583\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.204 | Acc: 91.601 | correct, total: (563733,615424)\n",
      "##########one 200 batch totally time cost 10.998\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.204 | Acc: 91.587 | correct, total: (657433,717824)\n",
      "epochIndex 3 |time: 11 | Acc: 91.584 | correct, total: (662638,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.219 | Acc: 91.895 | correct, total: (941,1024)\n",
      "##########one 200 batch totally time cost 1.434\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.201 | Acc: 91.726 | correct, total: (94867,103424)\n",
      "##########one 200 batch totally time cost 2.839\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.204 | Acc: 91.597 | correct, total: (188528,205824)\n",
      "##########one 200 batch totally time cost 4.265\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.205 | Acc: 91.591 | correct, total: (282305,308224)\n",
      "##########one 200 batch totally time cost 5.690\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.204 | Acc: 91.638 | correct, total: (376286,410624)\n",
      "##########one 200 batch totally time cost 7.125\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.204 | Acc: 91.588 | correct, total: (469870,513024)\n",
      "##########one 200 batch totally time cost 8.956\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.203 | Acc: 91.631 | correct, total: (563921,615424)\n",
      "##########one 200 batch totally time cost 10.371\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.203 | Acc: 91.651 | correct, total: (657890,717824)\n",
      "epochIndex 4 |time: 10 | Acc: 91.655 | correct, total: (663152,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.204 | Acc: 91.211 | correct, total: (934,1024)\n",
      "##########one 200 batch totally time cost 1.468\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.206 | Acc: 91.590 | correct, total: (94726,103424)\n",
      "##########one 200 batch totally time cost 2.847\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.201 | Acc: 91.641 | correct, total: (188619,205824)\n",
      "##########one 200 batch totally time cost 4.286\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.198 | Acc: 91.772 | correct, total: (282863,308224)\n",
      "##########one 200 batch totally time cost 5.720\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.200 | Acc: 91.729 | correct, total: (376661,410624)\n",
      "##########one 200 batch totally time cost 7.577\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.199 | Acc: 91.758 | correct, total: (470743,513024)\n",
      "##########one 200 batch totally time cost 9.002\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.198 | Acc: 91.780 | correct, total: (564838,615424)\n",
      "##########one 200 batch totally time cost 10.358\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.198 | Acc: 91.795 | correct, total: (658928,717824)\n",
      "epochIndex 5 |time: 10 | Acc: 91.800 | correct, total: (664199,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.227 | Acc: 90.430 | correct, total: (926,1024)\n",
      "##########one 200 batch totally time cost 1.476\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.211 | Acc: 91.298 | correct, total: (94424,103424)\n",
      "##########one 200 batch totally time cost 2.913\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.204 | Acc: 91.590 | correct, total: (188515,205824)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 4.328\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.201 | Acc: 91.713 | correct, total: (282680,308224)\n",
      "##########one 200 batch totally time cost 5.739\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.200 | Acc: 91.740 | correct, total: (376708,410624)\n",
      "##########one 200 batch totally time cost 7.104\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.199 | Acc: 91.791 | correct, total: (470910,513024)\n",
      "##########one 200 batch totally time cost 8.534\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.197 | Acc: 91.854 | correct, total: (565292,615424)\n",
      "##########one 200 batch totally time cost 9.938\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.198 | Acc: 91.831 | correct, total: (659183,717824)\n",
      "epochIndex 6 |time: 10 | Acc: 91.833 | correct, total: (664444,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.062\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.183 | Acc: 92.676 | correct, total: (949,1024)\n",
      "##########one 200 batch totally time cost 1.475\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.197 | Acc: 91.895 | correct, total: (95042,103424)\n",
      "##########one 200 batch totally time cost 2.894\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.194 | Acc: 91.944 | correct, total: (189242,205824)\n",
      "##########one 200 batch totally time cost 4.264\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.194 | Acc: 91.904 | correct, total: (283270,308224)\n",
      "##########one 200 batch totally time cost 5.752\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.193 | Acc: 91.911 | correct, total: (377409,410624)\n",
      "##########one 200 batch totally time cost 7.125\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.195 | Acc: 91.884 | correct, total: (471388,513024)\n",
      "##########one 200 batch totally time cost 8.584\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.193 | Acc: 91.939 | correct, total: (565814,615424)\n",
      "##########one 200 batch totally time cost 9.990\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.193 | Acc: 91.922 | correct, total: (659840,717824)\n",
      "epochIndex 7 |time: 10 | Acc: 91.922 | correct, total: (665088,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.184 | Acc: 92.383 | correct, total: (946,1024)\n",
      "##########one 200 batch totally time cost 1.932\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.191 | Acc: 92.002 | correct, total: (95152,103424)\n",
      "##########one 200 batch totally time cost 3.830\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.191 | Acc: 92.043 | correct, total: (189446,205824)\n",
      "##########one 200 batch totally time cost 5.182\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.193 | Acc: 91.972 | correct, total: (283479,308224)\n",
      "##########one 200 batch totally time cost 6.604\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.191 | Acc: 92.039 | correct, total: (377935,410624)\n",
      "##########one 200 batch totally time cost 8.062\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.188 | Acc: 92.156 | correct, total: (472782,513024)\n",
      "##########one 200 batch totally time cost 9.475\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.188 | Acc: 92.137 | correct, total: (567035,615424)\n",
      "##########one 200 batch totally time cost 10.898\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.188 | Acc: 92.133 | correct, total: (661351,717824)\n",
      "epochIndex 8 |time: 10 | Acc: 92.123 | correct, total: (666542,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.217 | Acc: 91.113 | correct, total: (933,1024)\n",
      "##########one 200 batch totally time cost 1.421\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.191 | Acc: 92.071 | correct, total: (95223,103424)\n",
      "##########one 200 batch totally time cost 2.844\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.190 | Acc: 92.073 | correct, total: (189509,205824)\n",
      "##########one 200 batch totally time cost 4.332\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.192 | Acc: 91.975 | correct, total: (283488,308224)\n",
      "##########one 200 batch totally time cost 5.757\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.192 | Acc: 91.967 | correct, total: (377637,410624)\n",
      "##########one 200 batch totally time cost 7.185\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.192 | Acc: 92.004 | correct, total: (472004,513024)\n",
      "##########one 200 batch totally time cost 8.554\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.192 | Acc: 92.005 | correct, total: (566218,615424)\n",
      "##########one 200 batch totally time cost 9.961\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.192 | Acc: 91.988 | correct, total: (660312,717824)\n",
      "epochIndex 9 |time: 10 | Acc: 91.987 | correct, total: (665552,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.061\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.191 | Acc: 92.285 | correct, total: (945,1024)\n",
      "##########one 200 batch totally time cost 1.459\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.186 | Acc: 92.212 | correct, total: (95369,103424)\n",
      "##########one 200 batch totally time cost 3.272\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.182 | Acc: 92.384 | correct, total: (190149,205824)\n",
      "##########one 200 batch totally time cost 4.717\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.185 | Acc: 92.246 | correct, total: (284324,308224)\n",
      "##########one 200 batch totally time cost 6.084\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.186 | Acc: 92.221 | correct, total: (378680,410624)\n",
      "##########one 200 batch totally time cost 7.572\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.185 | Acc: 92.241 | correct, total: (473221,513024)\n",
      "##########one 200 batch totally time cost 8.922\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.186 | Acc: 92.208 | correct, total: (567473,615424)\n",
      "##########one 200 batch totally time cost 10.324\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.187 | Acc: 92.199 | correct, total: (661823,717824)\n",
      "epochIndex 10 |time: 10 | Acc: 92.203 | correct, total: (667117,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.070\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.179 | Acc: 91.797 | correct, total: (940,1024)\n",
      "##########one 200 batch totally time cost 1.501\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.191 | Acc: 92.027 | correct, total: (95178,103424)\n",
      "##########one 200 batch totally time cost 2.913\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.186 | Acc: 92.244 | correct, total: (189860,205824)\n",
      "##########one 200 batch totally time cost 4.329\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.189 | Acc: 92.108 | correct, total: (283898,308224)\n",
      "##########one 200 batch totally time cost 6.188\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.188 | Acc: 92.159 | correct, total: (378425,410624)\n",
      "##########one 200 batch totally time cost 7.604\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.187 | Acc: 92.208 | correct, total: (473048,513024)\n",
      "##########one 200 batch totally time cost 9.477\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.187 | Acc: 92.169 | correct, total: (567229,615424)\n",
      "##########one 200 batch totally time cost 10.894\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.188 | Acc: 92.148 | correct, total: (661458,717824)\n",
      "epochIndex 11 |time: 10 | Acc: 92.150 | correct, total: (666736,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.066\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.174 | Acc: 91.992 | correct, total: (942,1024)\n",
      "##########one 200 batch totally time cost 1.515\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.188 | Acc: 92.097 | correct, total: (95250,103424)\n",
      "##########one 200 batch totally time cost 3.338\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.187 | Acc: 92.195 | correct, total: (189759,205824)\n",
      "##########one 200 batch totally time cost 4.760\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.187 | Acc: 92.198 | correct, total: (284176,308224)\n",
      "##########one 200 batch totally time cost 6.177\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.187 | Acc: 92.182 | correct, total: (378522,410624)\n",
      "##########one 200 batch totally time cost 7.590\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.185 | Acc: 92.262 | correct, total: (473327,513024)\n",
      "##########one 200 batch totally time cost 9.013\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.187 | Acc: 92.204 | correct, total: (567447,615424)\n",
      "##########one 200 batch totally time cost 10.370\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.186 | Acc: 92.208 | correct, total: (661890,717824)\n",
      "epochIndex 12 |time: 10 | Acc: 92.205 | correct, total: (667135,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.200 | Acc: 91.504 | correct, total: (937,1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 1.536\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.184 | Acc: 92.213 | correct, total: (95370,103424)\n",
      "##########one 200 batch totally time cost 2.881\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.190 | Acc: 92.075 | correct, total: (189512,205824)\n",
      "##########one 200 batch totally time cost 4.303\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.187 | Acc: 92.178 | correct, total: (284115,308224)\n",
      "##########one 200 batch totally time cost 5.710\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.186 | Acc: 92.230 | correct, total: (378720,410624)\n",
      "##########one 200 batch totally time cost 7.062\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.187 | Acc: 92.185 | correct, total: (472932,513024)\n",
      "##########one 200 batch totally time cost 8.521\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.189 | Acc: 92.122 | correct, total: (566941,615424)\n",
      "##########one 200 batch totally time cost 9.908\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.188 | Acc: 92.110 | correct, total: (661185,717824)\n",
      "epochIndex 13 |time: 9 | Acc: 92.103 | correct, total: (666397,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.197 | Acc: 91.797 | correct, total: (940,1024)\n",
      "##########one 200 batch totally time cost 1.480\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.184 | Acc: 92.267 | correct, total: (95426,103424)\n",
      "##########one 200 batch totally time cost 3.387\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.182 | Acc: 92.325 | correct, total: (190028,205824)\n",
      "##########one 200 batch totally time cost 5.117\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.414 | correct, total: (284843,308224)\n",
      "##########one 200 batch totally time cost 6.682\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.183 | Acc: 92.329 | correct, total: (379126,410624)\n",
      "##########one 200 batch totally time cost 8.056\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.183 | Acc: 92.315 | correct, total: (473600,513024)\n",
      "##########one 200 batch totally time cost 9.476\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.291 | correct, total: (567978,615424)\n",
      "##########one 200 batch totally time cost 10.895\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.184 | Acc: 92.262 | correct, total: (662279,717824)\n",
      "epochIndex 14 |time: 10 | Acc: 92.262 | correct, total: (667545,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.245 | Acc: 88.867 | correct, total: (910,1024)\n",
      "##########one 200 batch totally time cost 1.561\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.189 | Acc: 92.028 | correct, total: (95179,103424)\n",
      "##########one 200 batch totally time cost 2.989\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.185 | Acc: 92.214 | correct, total: (189799,205824)\n",
      "##########one 200 batch totally time cost 4.391\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.185 | Acc: 92.214 | correct, total: (284226,308224)\n",
      "##########one 200 batch totally time cost 5.829\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.185 | Acc: 92.222 | correct, total: (378684,410624)\n",
      "##########one 200 batch totally time cost 7.253\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.189 | Acc: 92.089 | correct, total: (472438,513024)\n",
      "##########one 200 batch totally time cost 8.674\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.188 | Acc: 92.126 | correct, total: (566968,615424)\n",
      "##########one 200 batch totally time cost 10.470\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.189 | Acc: 92.101 | correct, total: (661124,717824)\n",
      "epochIndex 15 |time: 10 | Acc: 92.100 | correct, total: (666374,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.169 | Acc: 92.773 | correct, total: (950,1024)\n",
      "##########one 200 batch totally time cost 1.444\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.445 | correct, total: (95610,103424)\n",
      "##########one 200 batch totally time cost 2.913\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.181 | Acc: 92.390 | correct, total: (190161,205824)\n",
      "##########one 200 batch totally time cost 4.273\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.183 | Acc: 92.305 | correct, total: (284507,308224)\n",
      "##########one 200 batch totally time cost 5.717\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.256 | correct, total: (378825,410624)\n",
      "##########one 200 batch totally time cost 7.647\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.267 | correct, total: (473352,513024)\n",
      "##########one 200 batch totally time cost 9.018\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.184 | Acc: 92.274 | correct, total: (567879,615424)\n",
      "##########one 200 batch totally time cost 10.497\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.296 | correct, total: (662522,717824)\n",
      "epochIndex 16 |time: 10 | Acc: 92.294 | correct, total: (667780,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.221 | Acc: 90.039 | correct, total: (922,1024)\n",
      "##########one 200 batch totally time cost 1.427\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.180 | Acc: 92.410 | correct, total: (95574,103424)\n",
      "##########one 200 batch totally time cost 2.848\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.183 | Acc: 92.264 | correct, total: (189901,205824)\n",
      "##########one 200 batch totally time cost 4.282\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.183 | Acc: 92.236 | correct, total: (284295,308224)\n",
      "##########one 200 batch totally time cost 5.687\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.186 | Acc: 92.145 | correct, total: (378369,410624)\n",
      "##########one 200 batch totally time cost 7.544\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.185 | Acc: 92.203 | correct, total: (473024,513024)\n",
      "##########one 200 batch totally time cost 8.906\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.186 | Acc: 92.175 | correct, total: (567268,615424)\n",
      "##########one 200 batch totally time cost 10.314\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.185 | Acc: 92.178 | correct, total: (661677,717824)\n",
      "epochIndex 17 |time: 10 | Acc: 92.180 | correct, total: (666953,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.194 | Acc: 91.211 | correct, total: (934,1024)\n",
      "##########one 200 batch totally time cost 1.478\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.182 | Acc: 92.220 | correct, total: (95378,103424)\n",
      "##########one 200 batch totally time cost 2.889\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.181 | Acc: 92.324 | correct, total: (190025,205824)\n",
      "##########one 200 batch totally time cost 4.309\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.182 | Acc: 92.300 | correct, total: (284490,308224)\n",
      "##########one 200 batch totally time cost 6.149\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.348 | correct, total: (379204,410624)\n",
      "##########one 200 batch totally time cost 7.574\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.308 | correct, total: (473563,513024)\n",
      "##########one 200 batch totally time cost 9.486\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.267 | correct, total: (567836,615424)\n",
      "##########one 200 batch totally time cost 10.903\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.275 | correct, total: (662373,717824)\n",
      "epochIndex 18 |time: 10 | Acc: 92.285 | correct, total: (667709,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.186 | Acc: 92.383 | correct, total: (946,1024)\n",
      "##########one 200 batch totally time cost 1.492\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.186 | Acc: 92.196 | correct, total: (95353,103424)\n",
      "##########one 200 batch totally time cost 2.846\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.184 | Acc: 92.244 | correct, total: (189861,205824)\n",
      "##########one 200 batch totally time cost 4.315\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.185 | Acc: 92.186 | correct, total: (284140,308224)\n",
      "##########one 200 batch totally time cost 5.686\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.185 | Acc: 92.231 | correct, total: (378722,410624)\n",
      "##########one 200 batch totally time cost 7.116\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.267 | correct, total: (473354,513024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 8.529\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.332 | correct, total: (568235,615424)\n",
      "##########one 200 batch totally time cost 9.901\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.338 | correct, total: (662827,717824)\n",
      "epochIndex 19 |time: 10 | Acc: 92.343 | correct, total: (668128,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.066\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.238 | Acc: 90.430 | correct, total: (926,1024)\n",
      "##########one 200 batch totally time cost 1.502\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.187 | Acc: 92.227 | correct, total: (95385,103424)\n",
      "##########one 200 batch totally time cost 2.875\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.185 | Acc: 92.229 | correct, total: (189829,205824)\n",
      "##########one 200 batch totally time cost 4.282\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.287 | correct, total: (284450,308224)\n",
      "##########one 200 batch totally time cost 5.681\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.182 | Acc: 92.343 | correct, total: (379183,410624)\n",
      "##########one 200 batch totally time cost 7.096\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.388 | correct, total: (473971,513024)\n",
      "##########one 200 batch totally time cost 8.619\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.410 | correct, total: (568711,615424)\n",
      "##########one 200 batch totally time cost 10.013\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.180 | Acc: 92.402 | correct, total: (663281,717824)\n",
      "epochIndex 20 |time: 10 | Acc: 92.399 | correct, total: (668539,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.193 | Acc: 91.309 | correct, total: (935,1024)\n",
      "##########one 200 batch totally time cost 1.959\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.185 | Acc: 92.239 | correct, total: (95397,103424)\n",
      "##########one 200 batch totally time cost 3.833\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.180 | Acc: 92.429 | correct, total: (190241,205824)\n",
      "##########one 200 batch totally time cost 5.267\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.181 | Acc: 92.389 | correct, total: (284766,308224)\n",
      "##########one 200 batch totally time cost 6.703\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.181 | Acc: 92.397 | correct, total: (379406,410624)\n",
      "##########one 200 batch totally time cost 8.068\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.364 | correct, total: (473850,513024)\n",
      "##########one 200 batch totally time cost 9.514\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.399 | correct, total: (568647,615424)\n",
      "##########one 200 batch totally time cost 10.946\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.441 | correct, total: (663562,717824)\n",
      "epochIndex 21 |time: 11 | Acc: 92.435 | correct, total: (668799,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.184 | Acc: 93.750 | correct, total: (960,1024)\n",
      "##########one 200 batch totally time cost 1.476\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.184 | Acc: 92.314 | correct, total: (95475,103424)\n",
      "##########one 200 batch totally time cost 2.885\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.183 | Acc: 92.288 | correct, total: (189951,205824)\n",
      "##########one 200 batch totally time cost 4.283\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.399 | correct, total: (284797,308224)\n",
      "##########one 200 batch totally time cost 5.779\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.416 | correct, total: (379481,410624)\n",
      "##########one 200 batch totally time cost 7.143\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.179 | Acc: 92.451 | correct, total: (474298,513024)\n",
      "##########one 200 batch totally time cost 8.562\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.179 | Acc: 92.450 | correct, total: (568962,615424)\n",
      "##########one 200 batch totally time cost 10.510\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.445 | correct, total: (663589,717824)\n",
      "epochIndex 22 |time: 10 | Acc: 92.442 | correct, total: (668849,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.167 | Acc: 92.578 | correct, total: (948,1024)\n",
      "##########one 200 batch totally time cost 1.933\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.594 | correct, total: (95764,103424)\n",
      "##########one 200 batch totally time cost 3.785\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.175 | Acc: 92.623 | correct, total: (190641,205824)\n",
      "##########one 200 batch totally time cost 5.135\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.528 | correct, total: (285193,308224)\n",
      "##########one 200 batch totally time cost 6.538\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.504 | correct, total: (379843,410624)\n",
      "##########one 200 batch totally time cost 7.953\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.177 | Acc: 92.524 | correct, total: (474671,513024)\n",
      "##########one 200 batch totally time cost 9.386\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.178 | Acc: 92.511 | correct, total: (569333,615424)\n",
      "##########one 200 batch totally time cost 10.803\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.178 | Acc: 92.492 | correct, total: (663928,717824)\n",
      "epochIndex 23 |time: 10 | Acc: 92.488 | correct, total: (669181,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.176 | Acc: 93.359 | correct, total: (956,1024)\n",
      "##########one 200 batch totally time cost 1.426\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.183 | Acc: 92.256 | correct, total: (95415,103424)\n",
      "##########one 200 batch totally time cost 2.830\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.184 | Acc: 92.272 | correct, total: (189917,205824)\n",
      "##########one 200 batch totally time cost 4.257\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.183 | Acc: 92.280 | correct, total: (284428,308224)\n",
      "##########one 200 batch totally time cost 5.663\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.182 | Acc: 92.301 | correct, total: (379012,410624)\n",
      "##########one 200 batch totally time cost 7.063\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.183 | Acc: 92.244 | correct, total: (473235,513024)\n",
      "##########one 200 batch totally time cost 8.428\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.182 | Acc: 92.288 | correct, total: (567961,615424)\n",
      "##########one 200 batch totally time cost 9.857\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.182 | Acc: 92.319 | correct, total: (662690,717824)\n",
      "epochIndex 24 |time: 9 | Acc: 92.324 | correct, total: (667993,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.106\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.274 | Acc: 89.062 | correct, total: (912,1024)\n",
      "##########one 200 batch totally time cost 1.484\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.185 | Acc: 92.186 | correct, total: (95342,103424)\n",
      "##########one 200 batch totally time cost 2.932\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.182 | Acc: 92.313 | correct, total: (190002,205824)\n",
      "##########one 200 batch totally time cost 4.377\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.249 | correct, total: (284333,308224)\n",
      "##########one 200 batch totally time cost 6.194\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.272 | correct, total: (378891,410624)\n",
      "##########one 200 batch totally time cost 7.659\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.355 | correct, total: (473803,513024)\n",
      "##########one 200 batch totally time cost 9.047\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.331 | correct, total: (568228,615424)\n",
      "##########one 200 batch totally time cost 10.451\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.332 | correct, total: (662784,717824)\n",
      "epochIndex 25 |time: 10 | Acc: 92.324 | correct, total: (667997,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.192 | Acc: 90.723 | correct, total: (929,1024)\n",
      "##########one 200 batch totally time cost 1.487\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.188 | Acc: 92.090 | correct, total: (95243,103424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 2.902\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.183 | Acc: 92.262 | correct, total: (189898,205824)\n",
      "##########one 200 batch totally time cost 4.320\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.181 | Acc: 92.362 | correct, total: (284683,308224)\n",
      "##########one 200 batch totally time cost 5.749\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.388 | correct, total: (379366,410624)\n",
      "##########one 200 batch totally time cost 7.169\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.179 | Acc: 92.423 | correct, total: (474151,513024)\n",
      "##########one 200 batch totally time cost 8.592\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.179 | Acc: 92.440 | correct, total: (568895,615424)\n",
      "##########one 200 batch totally time cost 10.058\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.425 | correct, total: (663447,717824)\n",
      "epochIndex 26 |time: 10 | Acc: 92.425 | correct, total: (668726,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.060\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.174 | Acc: 91.797 | correct, total: (940,1024)\n",
      "##########one 200 batch totally time cost 1.483\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.173 | Acc: 92.623 | correct, total: (95794,103424)\n",
      "##########one 200 batch totally time cost 3.307\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.521 | correct, total: (190431,205824)\n",
      "##########one 200 batch totally time cost 4.764\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.490 | correct, total: (285077,308224)\n",
      "##########one 200 batch totally time cost 7.154\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.177 | Acc: 92.493 | correct, total: (379800,410624)\n",
      "##########one 200 batch totally time cost 8.579\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.179 | Acc: 92.428 | correct, total: (474177,513024)\n",
      "##########one 200 batch totally time cost 9.995\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.399 | correct, total: (568645,615424)\n",
      "##########one 200 batch totally time cost 11.346\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.430 | correct, total: (663487,717824)\n",
      "epochIndex 27 |time: 11 | Acc: 92.431 | correct, total: (668765,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.189 | Acc: 91.797 | correct, total: (940,1024)\n",
      "##########one 200 batch totally time cost 1.560\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.181 | Acc: 92.285 | correct, total: (95445,103424)\n",
      "##########one 200 batch totally time cost 2.923\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.180 | Acc: 92.435 | correct, total: (190253,205824)\n",
      "##########one 200 batch totally time cost 4.339\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.187 | Acc: 92.175 | correct, total: (284104,308224)\n",
      "##########one 200 batch totally time cost 5.756\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.186 | Acc: 92.204 | correct, total: (378611,410624)\n",
      "##########one 200 batch totally time cost 7.113\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.266 | correct, total: (473347,513024)\n",
      "##########one 200 batch totally time cost 8.574\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.184 | Acc: 92.262 | correct, total: (567803,615424)\n",
      "##########one 200 batch totally time cost 9.945\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.298 | correct, total: (662536,717824)\n",
      "epochIndex 28 |time: 10 | Acc: 92.295 | correct, total: (667787,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.160 | Acc: 93.066 | correct, total: (953,1024)\n",
      "##########one 200 batch totally time cost 1.471\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.188 | Acc: 92.071 | correct, total: (95224,103424)\n",
      "##########one 200 batch totally time cost 2.884\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.185 | Acc: 92.164 | correct, total: (189695,205824)\n",
      "##########one 200 batch totally time cost 4.289\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.183 | Acc: 92.233 | correct, total: (284284,308224)\n",
      "##########one 200 batch totally time cost 5.738\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.183 | Acc: 92.255 | correct, total: (378822,410624)\n",
      "##########one 200 batch totally time cost 7.134\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.183 | Acc: 92.243 | correct, total: (473230,513024)\n",
      "##########one 200 batch totally time cost 8.992\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.182 | Acc: 92.292 | correct, total: (567985,615424)\n",
      "##########one 200 batch totally time cost 10.428\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.182 | Acc: 92.311 | correct, total: (662632,717824)\n",
      "epochIndex 29 |time: 10 | Acc: 92.309 | correct, total: (667884,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.187 | Acc: 91.309 | correct, total: (935,1024)\n",
      "##########one 200 batch totally time cost 1.496\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.189 | Acc: 92.043 | correct, total: (95195,103424)\n",
      "##########one 200 batch totally time cost 3.393\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.186 | Acc: 92.173 | correct, total: (189715,205824)\n",
      "##########one 200 batch totally time cost 4.783\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.220 | correct, total: (284244,308224)\n",
      "##########one 200 batch totally time cost 6.696\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.187 | Acc: 92.136 | correct, total: (378333,410624)\n",
      "##########one 200 batch totally time cost 8.110\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.188 | Acc: 92.106 | correct, total: (472526,513024)\n",
      "##########one 200 batch totally time cost 9.974\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.187 | Acc: 92.140 | correct, total: (567051,615424)\n",
      "##########one 200 batch totally time cost 11.388\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.188 | Acc: 92.081 | correct, total: (660982,717824)\n",
      "epochIndex 30 |time: 11 | Acc: 92.078 | correct, total: (666216,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.218 | Acc: 90.234 | correct, total: (924,1024)\n",
      "##########one 200 batch totally time cost 1.424\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.182 | Acc: 92.256 | correct, total: (95415,103424)\n",
      "##########one 200 batch totally time cost 2.878\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.182 | Acc: 92.304 | correct, total: (189984,205824)\n",
      "##########one 200 batch totally time cost 4.257\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.229 | correct, total: (284273,308224)\n",
      "##########one 200 batch totally time cost 5.702\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.218 | correct, total: (378671,410624)\n",
      "##########one 200 batch totally time cost 7.163\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.243 | correct, total: (473227,513024)\n",
      "##########one 200 batch totally time cost 8.545\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.248 | correct, total: (567717,615424)\n",
      "##########one 200 batch totally time cost 10.957\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.184 | Acc: 92.244 | correct, total: (662153,717824)\n",
      "epochIndex 31 |time: 11 | Acc: 92.237 | correct, total: (667363,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.061\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.241 | Acc: 90.918 | correct, total: (931,1024)\n",
      "##########one 200 batch totally time cost 1.427\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.187 | Acc: 92.127 | correct, total: (95281,103424)\n",
      "##########one 200 batch totally time cost 2.845\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.187 | Acc: 92.170 | correct, total: (189707,205824)\n",
      "##########one 200 batch totally time cost 4.254\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.186 | Acc: 92.193 | correct, total: (284162,308224)\n",
      "##########one 200 batch totally time cost 5.668\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.187 | Acc: 92.139 | correct, total: (378344,410624)\n",
      "##########one 200 batch totally time cost 7.077\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.186 | Acc: 92.172 | correct, total: (472864,513024)\n",
      "##########one 200 batch totally time cost 8.435\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.185 | Acc: 92.209 | correct, total: (567475,615424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 9.841\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.185 | Acc: 92.221 | correct, total: (661986,717824)\n",
      "epochIndex 32 |time: 9 | Acc: 92.227 | correct, total: (667293,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.178 | Acc: 91.992 | correct, total: (942,1024)\n",
      "##########one 200 batch totally time cost 1.484\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.188 | Acc: 92.014 | correct, total: (95165,103424)\n",
      "##########one 200 batch totally time cost 2.902\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.185 | Acc: 92.195 | correct, total: (189759,205824)\n",
      "##########one 200 batch totally time cost 4.312\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.186 | Acc: 92.149 | correct, total: (284024,308224)\n",
      "##########one 200 batch totally time cost 5.665\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.187 | Acc: 92.113 | correct, total: (378238,410624)\n",
      "##########one 200 batch totally time cost 7.073\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.189 | Acc: 92.062 | correct, total: (472300,513024)\n",
      "##########one 200 batch totally time cost 8.547\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.189 | Acc: 92.092 | correct, total: (566755,615424)\n",
      "##########one 200 batch totally time cost 10.439\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.188 | Acc: 92.107 | correct, total: (661167,717824)\n",
      "epochIndex 33 |time: 10 | Acc: 92.112 | correct, total: (666457,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.191 | Acc: 91.699 | correct, total: (939,1024)\n",
      "##########one 200 batch totally time cost 1.473\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.185 | Acc: 92.102 | correct, total: (95256,103424)\n",
      "##########one 200 batch totally time cost 2.835\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.186 | Acc: 92.138 | correct, total: (189642,205824)\n",
      "##########one 200 batch totally time cost 4.287\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.186 | Acc: 92.164 | correct, total: (284071,308224)\n",
      "##########one 200 batch totally time cost 5.635\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.186 | Acc: 92.154 | correct, total: (378407,410624)\n",
      "##########one 200 batch totally time cost 7.048\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.230 | correct, total: (473161,513024)\n",
      "##########one 200 batch totally time cost 8.448\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.288 | correct, total: (567964,615424)\n",
      "##########one 200 batch totally time cost 9.914\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.184 | Acc: 92.242 | correct, total: (662137,717824)\n",
      "epochIndex 34 |time: 10 | Acc: 92.245 | correct, total: (667420,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.231 | Acc: 90.820 | correct, total: (930,1024)\n",
      "##########one 200 batch totally time cost 1.466\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.184 | Acc: 92.236 | correct, total: (95394,103424)\n",
      "##########one 200 batch totally time cost 2.894\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.185 | Acc: 92.257 | correct, total: (189887,205824)\n",
      "##########one 200 batch totally time cost 4.737\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.182 | Acc: 92.323 | correct, total: (284562,308224)\n",
      "##########one 200 batch totally time cost 6.087\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.234 | correct, total: (378735,410624)\n",
      "##########one 200 batch totally time cost 7.556\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.185 | Acc: 92.238 | correct, total: (473202,513024)\n",
      "##########one 200 batch totally time cost 8.914\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.276 | correct, total: (567890,615424)\n",
      "##########one 200 batch totally time cost 10.345\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.308 | correct, total: (662608,717824)\n",
      "epochIndex 35 |time: 10 | Acc: 92.305 | correct, total: (667854,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.057\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.259 | Acc: 89.941 | correct, total: (921,1024)\n",
      "##########one 200 batch totally time cost 1.515\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.186 | Acc: 92.236 | correct, total: (95394,103424)\n",
      "##########one 200 batch totally time cost 3.398\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.184 | Acc: 92.260 | correct, total: (189893,205824)\n",
      "##########one 200 batch totally time cost 4.798\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.185 | Acc: 92.238 | correct, total: (284299,308224)\n",
      "##########one 200 batch totally time cost 6.144\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.185 | Acc: 92.263 | correct, total: (378852,410624)\n",
      "##########one 200 batch totally time cost 7.557\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.186 | Acc: 92.206 | correct, total: (473038,513024)\n",
      "##########one 200 batch totally time cost 8.968\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.185 | Acc: 92.231 | correct, total: (567612,615424)\n",
      "##########one 200 batch totally time cost 10.375\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.184 | Acc: 92.271 | correct, total: (662341,717824)\n",
      "epochIndex 36 |time: 10 | Acc: 92.275 | correct, total: (667639,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.157 | Acc: 93.359 | correct, total: (956,1024)\n",
      "##########one 200 batch totally time cost 1.527\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.197 | Acc: 91.798 | correct, total: (94941,103424)\n",
      "##########one 200 batch totally time cost 2.912\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.187 | Acc: 92.186 | correct, total: (189741,205824)\n",
      "##########one 200 batch totally time cost 4.756\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.279 | correct, total: (284425,308224)\n",
      "##########one 200 batch totally time cost 6.159\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.182 | Acc: 92.329 | correct, total: (379125,410624)\n",
      "##########one 200 batch totally time cost 7.577\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.368 | correct, total: (473872,513024)\n",
      "##########one 200 batch totally time cost 9.097\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.181 | Acc: 92.366 | correct, total: (568441,615424)\n",
      "##########one 200 batch totally time cost 10.477\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.182 | Acc: 92.347 | correct, total: (662888,717824)\n",
      "epochIndex 37 |time: 10 | Acc: 92.347 | correct, total: (668158,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.200 | Acc: 92.188 | correct, total: (944,1024)\n",
      "##########one 200 batch totally time cost 2.015\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.177 | Acc: 92.483 | correct, total: (95650,103424)\n",
      "##########one 200 batch totally time cost 3.408\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.178 | Acc: 92.414 | correct, total: (190211,205824)\n",
      "##########one 200 batch totally time cost 5.289\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.181 | Acc: 92.281 | correct, total: (284431,308224)\n",
      "##########one 200 batch totally time cost 6.698\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.181 | Acc: 92.324 | correct, total: (379104,410624)\n",
      "##########one 200 batch totally time cost 8.056\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.310 | correct, total: (473570,513024)\n",
      "##########one 200 batch totally time cost 9.567\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.342 | correct, total: (568296,615424)\n",
      "##########one 200 batch totally time cost 10.944\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.180 | Acc: 92.370 | correct, total: (663053,717824)\n",
      "epochIndex 38 |time: 11 | Acc: 92.370 | correct, total: (668329,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.171 | Acc: 92.090 | correct, total: (943,1024)\n",
      "##########one 200 batch totally time cost 1.507\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.186 | Acc: 92.109 | correct, total: (95263,103424)\n",
      "##########one 200 batch totally time cost 2.933\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.185 | Acc: 92.192 | correct, total: (189754,205824)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 4.831\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.259 | correct, total: (284363,308224)\n",
      "##########one 200 batch totally time cost 6.255\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.230 | correct, total: (378719,410624)\n",
      "##########one 200 batch totally time cost 7.609\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.185 | Acc: 92.211 | correct, total: (473066,513024)\n",
      "##########one 200 batch totally time cost 9.014\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.185 | Acc: 92.213 | correct, total: (567501,615424)\n",
      "##########one 200 batch totally time cost 10.927\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.184 | Acc: 92.231 | correct, total: (662059,717824)\n",
      "epochIndex 39 |time: 11 | Acc: 92.231 | correct, total: (667324,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.211 | Acc: 91.309 | correct, total: (935,1024)\n",
      "##########one 200 batch totally time cost 2.117\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.178 | Acc: 92.443 | correct, total: (95608,103424)\n",
      "##########one 200 batch totally time cost 3.980\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.180 | Acc: 92.376 | correct, total: (190131,205824)\n",
      "##########one 200 batch totally time cost 5.339\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.182 | Acc: 92.319 | correct, total: (284549,308224)\n",
      "##########one 200 batch totally time cost 6.750\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.266 | correct, total: (378866,410624)\n",
      "##########one 200 batch totally time cost 8.166\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.263 | correct, total: (473329,513024)\n",
      "##########one 200 batch totally time cost 9.581\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.185 | Acc: 92.213 | correct, total: (567502,615424)\n",
      "##########one 200 batch totally time cost 10.995\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.266 | correct, total: (662310,717824)\n",
      "epochIndex 40 |time: 11 | Acc: 92.262 | correct, total: (667542,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.061\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.216 | Acc: 90.332 | correct, total: (925,1024)\n",
      "##########one 200 batch totally time cost 1.449\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.185 | Acc: 92.194 | correct, total: (95351,103424)\n",
      "##########one 200 batch totally time cost 3.373\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.184 | Acc: 92.280 | correct, total: (189934,205824)\n",
      "##########one 200 batch totally time cost 4.789\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.185 | Acc: 92.203 | correct, total: (284191,308224)\n",
      "##########one 200 batch totally time cost 7.064\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.238 | correct, total: (378751,410624)\n",
      "##########one 200 batch totally time cost 8.484\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.223 | correct, total: (473124,513024)\n",
      "##########one 200 batch totally time cost 9.835\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.264 | correct, total: (567816,615424)\n",
      "##########one 200 batch totally time cost 11.296\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.258 | correct, total: (662249,717824)\n",
      "epochIndex 41 |time: 11 | Acc: 92.261 | correct, total: (667541,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.180 | Acc: 91.602 | correct, total: (938,1024)\n",
      "##########one 200 batch totally time cost 1.440\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.174 | Acc: 92.610 | correct, total: (95781,103424)\n",
      "##########one 200 batch totally time cost 3.338\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.179 | Acc: 92.428 | correct, total: (190239,205824)\n",
      "##########one 200 batch totally time cost 4.755\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.399 | correct, total: (284795,308224)\n",
      "##########one 200 batch totally time cost 6.183\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.179 | Acc: 92.432 | correct, total: (379547,410624)\n",
      "##########one 200 batch totally time cost 7.637\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.180 | Acc: 92.394 | correct, total: (474003,513024)\n",
      "##########one 200 batch totally time cost 9.470\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.181 | Acc: 92.356 | correct, total: (568383,615424)\n",
      "##########one 200 batch totally time cost 10.886\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.181 | Acc: 92.365 | correct, total: (663017,717824)\n",
      "epochIndex 42 |time: 10 | Acc: 92.368 | correct, total: (668309,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.175 | Acc: 92.676 | correct, total: (949,1024)\n",
      "##########one 200 batch totally time cost 1.489\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.182 | Acc: 92.385 | correct, total: (95548,103424)\n",
      "##########one 200 batch totally time cost 2.994\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.180 | Acc: 92.422 | correct, total: (190226,205824)\n",
      "##########one 200 batch totally time cost 4.410\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.179 | Acc: 92.435 | correct, total: (284908,308224)\n",
      "##########one 200 batch totally time cost 5.776\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.179 | Acc: 92.406 | correct, total: (379442,410624)\n",
      "##########one 200 batch totally time cost 7.194\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.353 | correct, total: (473795,513024)\n",
      "##########one 200 batch totally time cost 8.632\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.181 | Acc: 92.365 | correct, total: (568438,615424)\n",
      "##########one 200 batch totally time cost 10.075\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.180 | Acc: 92.422 | correct, total: (663426,717824)\n",
      "epochIndex 43 |time: 10 | Acc: 92.422 | correct, total: (668700,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.060\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.229 | Acc: 91.504 | correct, total: (937,1024)\n",
      "##########one 200 batch totally time cost 1.911\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.705 | correct, total: (95879,103424)\n",
      "##########one 200 batch totally time cost 3.355\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.621 | correct, total: (190636,205824)\n",
      "##########one 200 batch totally time cost 4.839\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.592 | correct, total: (285392,308224)\n",
      "##########one 200 batch totally time cost 6.679\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.526 | correct, total: (379935,410624)\n",
      "##########one 200 batch totally time cost 8.543\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.482 | correct, total: (474453,513024)\n",
      "##########one 200 batch totally time cost 9.983\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.178 | Acc: 92.467 | correct, total: (569064,615424)\n",
      "##########one 200 batch totally time cost 11.355\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.178 | Acc: 92.481 | correct, total: (663853,717824)\n",
      "epochIndex 44 |time: 11 | Acc: 92.476 | correct, total: (669090,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.187 | Acc: 92.578 | correct, total: (948,1024)\n",
      "##########one 200 batch totally time cost 1.463\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.422 | correct, total: (95587,103424)\n",
      "##########one 200 batch totally time cost 2.822\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.178 | Acc: 92.470 | correct, total: (190326,205824)\n",
      "##########one 200 batch totally time cost 4.245\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.177 | Acc: 92.508 | correct, total: (285131,308224)\n",
      "##########one 200 batch totally time cost 5.655\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.391 | correct, total: (379381,410624)\n",
      "##########one 200 batch totally time cost 7.059\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.358 | correct, total: (473818,513024)\n",
      "##########one 200 batch totally time cost 8.468\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.184 | Acc: 92.279 | correct, total: (567905,615424)\n",
      "##########one 200 batch totally time cost 9.837\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.282 | correct, total: (662425,717824)\n",
      "epochIndex 45 |time: 9 | Acc: 92.280 | correct, total: (667672,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.211 | Acc: 91.406 | correct, total: (936,1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 1.497\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.188 | Acc: 92.050 | correct, total: (95202,103424)\n",
      "##########one 200 batch totally time cost 2.917\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.189 | Acc: 92.025 | correct, total: (189410,205824)\n",
      "##########one 200 batch totally time cost 4.342\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.187 | Acc: 92.100 | correct, total: (283873,308224)\n",
      "##########one 200 batch totally time cost 5.803\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.189 | Acc: 92.053 | correct, total: (377991,410624)\n",
      "##########one 200 batch totally time cost 7.206\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.188 | Acc: 92.094 | correct, total: (472464,513024)\n",
      "##########one 200 batch totally time cost 9.533\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.187 | Acc: 92.156 | correct, total: (567148,615424)\n",
      "##########one 200 batch totally time cost 10.941\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.184 | Acc: 92.268 | correct, total: (662321,717824)\n",
      "epochIndex 46 |time: 11 | Acc: 92.269 | correct, total: (667597,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.215 | Acc: 89.941 | correct, total: (921,1024)\n",
      "##########one 200 batch totally time cost 1.462\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.176 | Acc: 92.529 | correct, total: (95697,103424)\n",
      "##########one 200 batch totally time cost 2.906\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.519 | correct, total: (190427,205824)\n",
      "##########one 200 batch totally time cost 4.267\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.177 | Acc: 92.502 | correct, total: (285114,308224)\n",
      "##########one 200 batch totally time cost 5.734\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.177 | Acc: 92.512 | correct, total: (379878,410624)\n",
      "##########one 200 batch totally time cost 7.087\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.177 | Acc: 92.517 | correct, total: (474633,513024)\n",
      "##########one 200 batch totally time cost 8.512\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.178 | Acc: 92.488 | correct, total: (569195,615424)\n",
      "##########one 200 batch totally time cost 9.956\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.177 | Acc: 92.519 | correct, total: (664127,717824)\n",
      "epochIndex 47 |time: 10 | Acc: 92.519 | correct, total: (669403,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.198 | Acc: 90.820 | correct, total: (930,1024)\n",
      "##########one 200 batch totally time cost 1.930\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.178 | Acc: 92.486 | correct, total: (95653,103424)\n",
      "##########one 200 batch totally time cost 3.361\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.179 | Acc: 92.460 | correct, total: (190305,205824)\n",
      "##########one 200 batch totally time cost 4.724\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.436 | correct, total: (284911,308224)\n",
      "##########one 200 batch totally time cost 6.152\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.432 | correct, total: (379546,410624)\n",
      "##########one 200 batch totally time cost 7.561\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.275 | correct, total: (473392,513024)\n",
      "##########one 200 batch totally time cost 9.012\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.185 | Acc: 92.253 | correct, total: (567746,615424)\n",
      "##########one 200 batch totally time cost 10.938\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.186 | Acc: 92.186 | correct, total: (661735,717824)\n",
      "epochIndex 48 |time: 11 | Acc: 92.187 | correct, total: (667004,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.178 | Acc: 92.480 | correct, total: (947,1024)\n",
      "##########one 200 batch totally time cost 1.475\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.183 | Acc: 92.363 | correct, total: (95526,103424)\n",
      "##########one 200 batch totally time cost 2.935\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.182 | Acc: 92.337 | correct, total: (190052,205824)\n",
      "##########one 200 batch totally time cost 4.884\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.413 | correct, total: (284840,308224)\n",
      "##########one 200 batch totally time cost 6.304\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.179 | Acc: 92.428 | correct, total: (379533,410624)\n",
      "##########one 200 batch totally time cost 7.766\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.180 | Acc: 92.409 | correct, total: (474080,513024)\n",
      "##########one 200 batch totally time cost 9.128\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.181 | Acc: 92.383 | correct, total: (568550,615424)\n",
      "##########one 200 batch totally time cost 10.581\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.180 | Acc: 92.400 | correct, total: (663267,717824)\n",
      "epochIndex 49 |time: 10 | Acc: 92.401 | correct, total: (668552,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.066\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.168 | Acc: 93.164 | correct, total: (954,1024)\n",
      "##########one 200 batch totally time cost 1.481\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.183 | Acc: 92.185 | correct, total: (95341,103424)\n",
      "##########one 200 batch totally time cost 2.901\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.181 | Acc: 92.360 | correct, total: (190100,205824)\n",
      "##########one 200 batch totally time cost 4.311\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.181 | Acc: 92.325 | correct, total: (284567,308224)\n",
      "##########one 200 batch totally time cost 5.687\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.181 | Acc: 92.335 | correct, total: (379151,410624)\n",
      "##########one 200 batch totally time cost 7.166\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.180 | Acc: 92.374 | correct, total: (473903,513024)\n",
      "##########one 200 batch totally time cost 8.521\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.179 | Acc: 92.408 | correct, total: (568700,615424)\n",
      "##########one 200 batch totally time cost 10.398\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.402 | correct, total: (663282,717824)\n",
      "epochIndex 50 |time: 10 | Acc: 92.396 | correct, total: (668515,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.253 | Acc: 90.039 | correct, total: (922,1024)\n",
      "##########one 200 batch totally time cost 1.522\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.187 | Acc: 92.019 | correct, total: (95170,103424)\n",
      "##########one 200 batch totally time cost 2.946\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.181 | Acc: 92.302 | correct, total: (189979,205824)\n",
      "##########one 200 batch totally time cost 4.782\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.364 | correct, total: (284689,308224)\n",
      "##########one 200 batch totally time cost 6.140\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.354 | correct, total: (379229,410624)\n",
      "##########one 200 batch totally time cost 7.558\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.444 | correct, total: (474258,513024)\n",
      "##########one 200 batch totally time cost 8.986\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.495 | correct, total: (569235,615424)\n",
      "##########one 200 batch totally time cost 10.873\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.529 | correct, total: (664198,717824)\n",
      "epochIndex 51 |time: 10 | Acc: 92.524 | correct, total: (669439,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.204 | Acc: 91.602 | correct, total: (938,1024)\n",
      "##########one 200 batch totally time cost 1.490\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.403 | correct, total: (95567,103424)\n",
      "##########one 200 batch totally time cost 2.838\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.178 | Acc: 92.474 | correct, total: (190334,205824)\n",
      "##########one 200 batch totally time cost 4.238\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.177 | Acc: 92.496 | correct, total: (285094,308224)\n",
      "##########one 200 batch totally time cost 5.651\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.177 | Acc: 92.480 | correct, total: (379747,410624)\n",
      "##########one 200 batch totally time cost 7.051\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.456 | correct, total: (474323,513024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 8.483\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.490 | correct, total: (569204,615424)\n",
      "##########one 200 batch totally time cost 9.867\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.178 | Acc: 92.469 | correct, total: (663762,717824)\n",
      "epochIndex 52 |time: 9 | Acc: 92.472 | correct, total: (669062,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.063\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.192 | Acc: 91.699 | correct, total: (939,1024)\n",
      "##########one 200 batch totally time cost 2.024\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.503 | correct, total: (95670,103424)\n",
      "##########one 200 batch totally time cost 3.367\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.175 | Acc: 92.601 | correct, total: (190596,205824)\n",
      "##########one 200 batch totally time cost 4.766\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.176 | Acc: 92.581 | correct, total: (285358,308224)\n",
      "##########one 200 batch totally time cost 6.183\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.177 | Acc: 92.545 | correct, total: (380013,410624)\n",
      "##########one 200 batch totally time cost 7.541\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.577 | correct, total: (474944,513024)\n",
      "##########one 200 batch totally time cost 9.018\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.583 | correct, total: (569780,615424)\n",
      "##########one 200 batch totally time cost 10.381\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.579 | correct, total: (664553,717824)\n",
      "epochIndex 53 |time: 10 | Acc: 92.582 | correct, total: (669858,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.154 | Acc: 93.555 | correct, total: (958,1024)\n",
      "##########one 200 batch totally time cost 1.477\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.655 | correct, total: (95828,103424)\n",
      "##########one 200 batch totally time cost 2.883\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.173 | Acc: 92.664 | correct, total: (190725,205824)\n",
      "##########one 200 batch totally time cost 4.313\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.579 | correct, total: (285352,308224)\n",
      "##########one 200 batch totally time cost 6.209\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.558 | correct, total: (380065,410624)\n",
      "##########one 200 batch totally time cost 7.562\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.549 | correct, total: (474797,513024)\n",
      "##########one 200 batch totally time cost 9.020\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.551 | correct, total: (569583,615424)\n",
      "##########one 200 batch totally time cost 10.453\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.553 | correct, total: (664370,717824)\n",
      "epochIndex 54 |time: 10 | Acc: 92.557 | correct, total: (669681,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.161 | Acc: 93.750 | correct, total: (960,1024)\n",
      "##########one 200 batch totally time cost 1.498\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.177 | Acc: 92.484 | correct, total: (95651,103424)\n",
      "##########one 200 batch totally time cost 3.367\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.517 | correct, total: (190422,205824)\n",
      "##########one 200 batch totally time cost 4.780\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.602 | correct, total: (285423,308224)\n",
      "##########one 200 batch totally time cost 6.720\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.576 | correct, total: (380141,410624)\n",
      "##########one 200 batch totally time cost 8.122\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.564 | correct, total: (474875,513024)\n",
      "##########one 200 batch totally time cost 9.539\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.569 | correct, total: (569690,615424)\n",
      "##########one 200 batch totally time cost 10.981\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.177 | Acc: 92.541 | correct, total: (664284,717824)\n",
      "epochIndex 55 |time: 11 | Acc: 92.542 | correct, total: (669572,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.162 | Acc: 93.262 | correct, total: (955,1024)\n",
      "##########one 200 batch totally time cost 1.872\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.170 | Acc: 92.858 | correct, total: (96037,103424)\n",
      "##########one 200 batch totally time cost 3.378\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.643 | correct, total: (190681,205824)\n",
      "##########one 200 batch totally time cost 4.725\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.653 | correct, total: (285578,308224)\n",
      "##########one 200 batch totally time cost 6.139\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.610 | correct, total: (380280,410624)\n",
      "##########one 200 batch totally time cost 7.588\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.583 | correct, total: (474975,513024)\n",
      "##########one 200 batch totally time cost 9.403\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.583 | correct, total: (569777,615424)\n",
      "##########one 200 batch totally time cost 10.864\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.600 | correct, total: (664705,717824)\n",
      "epochIndex 56 |time: 10 | Acc: 92.606 | correct, total: (670033,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.152 | Acc: 93.652 | correct, total: (959,1024)\n",
      "##########one 200 batch totally time cost 1.417\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.643 | correct, total: (95815,103424)\n",
      "##########one 200 batch totally time cost 2.843\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.563 | correct, total: (190516,205824)\n",
      "##########one 200 batch totally time cost 4.266\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.177 | Acc: 92.539 | correct, total: (285227,308224)\n",
      "##########one 200 batch totally time cost 5.684\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.551 | correct, total: (380038,410624)\n",
      "##########one 200 batch totally time cost 7.105\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.590 | correct, total: (475010,513024)\n",
      "##########one 200 batch totally time cost 8.451\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.579 | correct, total: (569751,615424)\n",
      "##########one 200 batch totally time cost 9.860\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.583 | correct, total: (664586,717824)\n",
      "epochIndex 57 |time: 9 | Acc: 92.586 | correct, total: (669889,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.066\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.236 | Acc: 89.160 | correct, total: (913,1024)\n",
      "##########one 200 batch totally time cost 1.481\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.774 | correct, total: (95951,103424)\n",
      "##########one 200 batch totally time cost 2.922\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.663 | correct, total: (190723,205824)\n",
      "##########one 200 batch totally time cost 4.344\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.612 | correct, total: (285452,308224)\n",
      "##########one 200 batch totally time cost 5.709\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.599 | correct, total: (380233,410624)\n",
      "##########one 200 batch totally time cost 7.154\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.587 | correct, total: (474991,513024)\n",
      "##########one 200 batch totally time cost 8.599\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.586 | correct, total: (569799,615424)\n",
      "##########one 200 batch totally time cost 10.502\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.589 | correct, total: (664627,717824)\n",
      "epochIndex 58 |time: 10 | Acc: 92.595 | correct, total: (669951,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.174 | Acc: 92.188 | correct, total: (944,1024)\n",
      "##########one 200 batch totally time cost 1.481\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.173 | Acc: 92.691 | correct, total: (95865,103424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 2.876\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.624 | correct, total: (190643,205824)\n",
      "##########one 200 batch totally time cost 4.332\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.626 | correct, total: (285497,308224)\n",
      "##########one 200 batch totally time cost 5.701\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.598 | correct, total: (380229,410624)\n",
      "##########one 200 batch totally time cost 7.125\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.174 | Acc: 92.614 | correct, total: (475134,513024)\n",
      "##########one 200 batch totally time cost 8.537\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.585 | correct, total: (569793,615424)\n",
      "##########one 200 batch totally time cost 9.928\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.575 | correct, total: (664524,717824)\n",
      "epochIndex 59 |time: 10 | Acc: 92.575 | correct, total: (669811,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.110\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.182 | Acc: 92.285 | correct, total: (945,1024)\n",
      "##########one 200 batch totally time cost 1.530\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.177 | Acc: 92.493 | correct, total: (95660,103424)\n",
      "##########one 200 batch totally time cost 3.405\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.491 | correct, total: (190368,205824)\n",
      "##########one 200 batch totally time cost 4.827\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.604 | correct, total: (285429,308224)\n",
      "##########one 200 batch totally time cost 6.262\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.592 | correct, total: (380207,410624)\n",
      "##########one 200 batch totally time cost 7.676\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.579 | correct, total: (474951,513024)\n",
      "##########one 200 batch totally time cost 9.190\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.583 | correct, total: (569779,615424)\n",
      "##########one 200 batch totally time cost 10.570\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.626 | correct, total: (664895,717824)\n",
      "epochIndex 60 |time: 10 | Acc: 92.622 | correct, total: (670152,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.212 | Acc: 91.406 | correct, total: (936,1024)\n",
      "##########one 200 batch totally time cost 1.527\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.171 | Acc: 92.758 | correct, total: (95934,103424)\n",
      "##########one 200 batch totally time cost 3.703\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.171 | Acc: 92.774 | correct, total: (190951,205824)\n",
      "##########one 200 batch totally time cost 5.128\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.171 | Acc: 92.771 | correct, total: (285944,308224)\n",
      "##########one 200 batch totally time cost 6.536\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.174 | Acc: 92.665 | correct, total: (380504,410624)\n",
      "##########one 200 batch totally time cost 7.898\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.640 | correct, total: (475265,513024)\n",
      "##########one 200 batch totally time cost 9.314\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.636 | correct, total: (570107,615424)\n",
      "##########one 200 batch totally time cost 10.750\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.642 | correct, total: (665010,717824)\n",
      "epochIndex 61 |time: 10 | Acc: 92.643 | correct, total: (670302,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.213 | Acc: 91.211 | correct, total: (934,1024)\n",
      "##########one 200 batch totally time cost 1.465\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.183 | Acc: 92.319 | correct, total: (95480,103424)\n",
      "##########one 200 batch totally time cost 2.871\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.179 | Acc: 92.473 | correct, total: (190331,205824)\n",
      "##########one 200 batch totally time cost 4.277\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.511 | correct, total: (285142,308224)\n",
      "##########one 200 batch totally time cost 5.774\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.504 | correct, total: (379842,410624)\n",
      "##########one 200 batch totally time cost 7.612\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.179 | Acc: 92.486 | correct, total: (474475,513024)\n",
      "##########one 200 batch totally time cost 9.029\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.179 | Acc: 92.474 | correct, total: (569105,615424)\n",
      "##########one 200 batch totally time cost 10.446\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.474 | correct, total: (663801,717824)\n",
      "epochIndex 62 |time: 10 | Acc: 92.477 | correct, total: (669102,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.143 | Acc: 94.043 | correct, total: (963,1024)\n",
      "##########one 200 batch totally time cost 1.502\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.729 | correct, total: (95904,103424)\n",
      "##########one 200 batch totally time cost 2.944\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.175 | Acc: 92.591 | correct, total: (190575,205824)\n",
      "##########one 200 batch totally time cost 4.799\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.179 | Acc: 92.459 | correct, total: (284981,308224)\n",
      "##########one 200 batch totally time cost 6.668\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.486 | correct, total: (379768,410624)\n",
      "##########one 200 batch totally time cost 8.083\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.579 | correct, total: (474953,513024)\n",
      "##########one 200 batch totally time cost 9.498\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.556 | correct, total: (569614,615424)\n",
      "##########one 200 batch totally time cost 10.907\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.579 | correct, total: (664552,717824)\n",
      "epochIndex 63 |time: 10 | Acc: 92.576 | correct, total: (669815,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.057\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.151 | Acc: 93.848 | correct, total: (961,1024)\n",
      "##########one 200 batch totally time cost 1.398\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.173 | Acc: 92.627 | correct, total: (95799,103424)\n",
      "##########one 200 batch totally time cost 2.853\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.178 | Acc: 92.550 | correct, total: (190491,205824)\n",
      "##########one 200 batch totally time cost 4.255\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.558 | correct, total: (285285,308224)\n",
      "##########one 200 batch totally time cost 5.660\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.177 | Acc: 92.578 | correct, total: (380148,410624)\n",
      "##########one 200 batch totally time cost 7.071\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.601 | correct, total: (475065,513024)\n",
      "##########one 200 batch totally time cost 8.437\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.580 | correct, total: (569761,615424)\n",
      "##########one 200 batch totally time cost 9.870\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.602 | correct, total: (664716,717824)\n",
      "epochIndex 64 |time: 9 | Acc: 92.603 | correct, total: (670012,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.224 | Acc: 91.406 | correct, total: (936,1024)\n",
      "##########one 200 batch totally time cost 1.468\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.178 | Acc: 92.480 | correct, total: (95646,103424)\n",
      "##########one 200 batch totally time cost 3.364\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.510 | correct, total: (190408,205824)\n",
      "##########one 200 batch totally time cost 4.796\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.615 | correct, total: (285463,308224)\n",
      "##########one 200 batch totally time cost 6.168\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.618 | correct, total: (380313,410624)\n",
      "##########one 200 batch totally time cost 8.025\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.615 | correct, total: (475135,513024)\n",
      "##########one 200 batch totally time cost 9.392\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.620 | correct, total: (570004,615424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 10.910\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.618 | correct, total: (664835,717824)\n",
      "epochIndex 65 |time: 10 | Acc: 92.617 | correct, total: (670115,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.289 | Acc: 89.941 | correct, total: (921,1024)\n",
      "##########one 200 batch totally time cost 1.469\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.180 | Acc: 92.480 | correct, total: (95647,103424)\n",
      "##########one 200 batch totally time cost 2.913\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.179 | Acc: 92.496 | correct, total: (190378,205824)\n",
      "##########one 200 batch totally time cost 4.382\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.500 | correct, total: (285107,308224)\n",
      "##########one 200 batch totally time cost 6.214\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.450 | correct, total: (379620,410624)\n",
      "##########one 200 batch totally time cost 7.621\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.522 | correct, total: (474658,513024)\n",
      "##########one 200 batch totally time cost 9.070\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.567 | correct, total: (569677,615424)\n",
      "##########one 200 batch totally time cost 10.547\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.583 | correct, total: (664583,717824)\n",
      "epochIndex 66 |time: 10 | Acc: 92.582 | correct, total: (669860,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.204 | Acc: 91.895 | correct, total: (941,1024)\n",
      "##########one 200 batch totally time cost 1.866\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.176 | Acc: 92.543 | correct, total: (95712,103424)\n",
      "##########one 200 batch totally time cost 3.227\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.532 | correct, total: (190453,205824)\n",
      "##########one 200 batch totally time cost 4.641\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.591 | correct, total: (285387,308224)\n",
      "##########one 200 batch totally time cost 6.100\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.579 | correct, total: (380153,410624)\n",
      "##########one 200 batch totally time cost 7.522\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.579 | correct, total: (474952,513024)\n",
      "##########one 200 batch totally time cost 8.931\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.606 | correct, total: (569919,615424)\n",
      "##########one 200 batch totally time cost 10.744\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.608 | correct, total: (664763,717824)\n",
      "epochIndex 67 |time: 10 | Acc: 92.608 | correct, total: (670045,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.193 | Acc: 92.676 | correct, total: (949,1024)\n",
      "##########one 200 batch totally time cost 1.493\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.480 | correct, total: (95647,103424)\n",
      "##########one 200 batch totally time cost 2.899\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.178 | Acc: 92.463 | correct, total: (190311,205824)\n",
      "##########one 200 batch totally time cost 4.296\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.177 | Acc: 92.524 | correct, total: (285180,308224)\n",
      "##########one 200 batch totally time cost 5.708\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.548 | correct, total: (380026,410624)\n",
      "##########one 200 batch totally time cost 7.083\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.177 | Acc: 92.520 | correct, total: (474649,513024)\n",
      "##########one 200 batch totally time cost 8.562\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.547 | correct, total: (569554,615424)\n",
      "##########one 200 batch totally time cost 9.933\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.566 | correct, total: (664458,717824)\n",
      "epochIndex 68 |time: 10 | Acc: 92.573 | correct, total: (669798,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.194 | Acc: 91.602 | correct, total: (938,1024)\n",
      "##########one 200 batch totally time cost 1.492\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.755 | correct, total: (95931,103424)\n",
      "##########one 200 batch totally time cost 3.356\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.171 | Acc: 92.730 | correct, total: (190861,205824)\n",
      "##########one 200 batch totally time cost 4.762\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.173 | Acc: 92.690 | correct, total: (285694,308224)\n",
      "##########one 200 batch totally time cost 6.167\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.173 | Acc: 92.704 | correct, total: (380666,410624)\n",
      "##########one 200 batch totally time cost 7.517\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.173 | Acc: 92.691 | correct, total: (475528,513024)\n",
      "##########one 200 batch totally time cost 8.927\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.685 | correct, total: (570404,615424)\n",
      "##########one 200 batch totally time cost 10.372\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.173 | Acc: 92.675 | correct, total: (665243,717824)\n",
      "epochIndex 69 |time: 10 | Acc: 92.674 | correct, total: (670524,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.192 | Acc: 91.211 | correct, total: (934,1024)\n",
      "##########one 200 batch totally time cost 1.470\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.169 | Acc: 92.713 | correct, total: (95887,103424)\n",
      "##########one 200 batch totally time cost 3.320\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.168 | Acc: 92.807 | correct, total: (191019,205824)\n",
      "##########one 200 batch totally time cost 4.683\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.171 | Acc: 92.740 | correct, total: (285846,308224)\n",
      "##########one 200 batch totally time cost 6.110\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.172 | Acc: 92.718 | correct, total: (380724,410624)\n",
      "##########one 200 batch totally time cost 7.508\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.172 | Acc: 92.706 | correct, total: (475604,513024)\n",
      "##########one 200 batch totally time cost 8.908\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.691 | correct, total: (570441,615424)\n",
      "##########one 200 batch totally time cost 10.350\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.173 | Acc: 92.686 | correct, total: (665325,717824)\n",
      "epochIndex 70 |time: 10 | Acc: 92.688 | correct, total: (670626,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.219 | Acc: 91.895 | correct, total: (941,1024)\n",
      "##########one 200 batch totally time cost 1.459\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.727 | correct, total: (95902,103424)\n",
      "##########one 200 batch totally time cost 2.889\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.172 | Acc: 92.720 | correct, total: (190839,205824)\n",
      "##########one 200 batch totally time cost 4.292\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.173 | Acc: 92.683 | correct, total: (285671,308224)\n",
      "##########one 200 batch totally time cost 5.712\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.605 | correct, total: (380257,410624)\n",
      "##########one 200 batch totally time cost 7.210\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.628 | correct, total: (475204,513024)\n",
      "##########one 200 batch totally time cost 8.588\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.637 | correct, total: (570108,615424)\n",
      "##########one 200 batch totally time cost 10.056\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.647 | correct, total: (665039,717824)\n",
      "epochIndex 71 |time: 10 | Acc: 92.646 | correct, total: (670322,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.167 | Acc: 92.090 | correct, total: (943,1024)\n",
      "##########one 200 batch totally time cost 1.452\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.171 | Acc: 92.783 | correct, total: (95960,103424)\n",
      "##########one 200 batch totally time cost 2.882\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.655 | correct, total: (190707,205824)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 4.294\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.587 | correct, total: (285375,308224)\n",
      "##########one 200 batch totally time cost 5.716\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.578 | correct, total: (380149,410624)\n",
      "##########one 200 batch totally time cost 7.111\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.597 | correct, total: (475047,513024)\n",
      "##########one 200 batch totally time cost 8.516\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.609 | correct, total: (569938,615424)\n",
      "##########one 200 batch totally time cost 9.926\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.608 | correct, total: (664760,717824)\n",
      "epochIndex 72 |time: 10 | Acc: 92.608 | correct, total: (670046,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.192 | Acc: 92.090 | correct, total: (943,1024)\n",
      "##########one 200 batch totally time cost 1.494\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.169 | Acc: 92.828 | correct, total: (96006,103424)\n",
      "##########one 200 batch totally time cost 2.900\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.605 | correct, total: (190604,205824)\n",
      "##########one 200 batch totally time cost 4.787\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.173 | Acc: 92.675 | correct, total: (285646,308224)\n",
      "##########one 200 batch totally time cost 6.153\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.172 | Acc: 92.711 | correct, total: (380694,410624)\n",
      "##########one 200 batch totally time cost 7.563\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.171 | Acc: 92.740 | correct, total: (475777,513024)\n",
      "##########one 200 batch totally time cost 9.024\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.685 | correct, total: (570405,615424)\n",
      "##########one 200 batch totally time cost 10.523\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.672 | correct, total: (665219,717824)\n",
      "epochIndex 73 |time: 10 | Acc: 92.666 | correct, total: (670468,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.189 | Acc: 92.676 | correct, total: (949,1024)\n",
      "##########one 200 batch totally time cost 2.373\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.174 | Acc: 92.747 | correct, total: (95923,103424)\n",
      "##########one 200 batch totally time cost 3.722\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.172 | Acc: 92.736 | correct, total: (190872,205824)\n",
      "##########one 200 batch totally time cost 5.186\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.645 | correct, total: (285555,308224)\n",
      "##########one 200 batch totally time cost 6.553\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.173 | Acc: 92.683 | correct, total: (380579,410624)\n",
      "##########one 200 batch totally time cost 7.967\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.172 | Acc: 92.724 | correct, total: (475697,513024)\n",
      "##########one 200 batch totally time cost 9.402\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.695 | correct, total: (570466,615424)\n",
      "##########one 200 batch totally time cost 10.758\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.172 | Acc: 92.705 | correct, total: (665457,717824)\n",
      "epochIndex 74 |time: 10 | Acc: 92.711 | correct, total: (670793,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.146 | Acc: 93.848 | correct, total: (961,1024)\n",
      "##########one 200 batch totally time cost 1.528\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.174 | Acc: 92.703 | correct, total: (95877,103424)\n",
      "##########one 200 batch totally time cost 2.881\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.696 | correct, total: (190791,205824)\n",
      "##########one 200 batch totally time cost 4.330\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.683 | correct, total: (285671,308224)\n",
      "##########one 200 batch totally time cost 5.740\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.174 | Acc: 92.663 | correct, total: (380496,410624)\n",
      "##########one 200 batch totally time cost 7.168\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.174 | Acc: 92.662 | correct, total: (475379,513024)\n",
      "##########one 200 batch totally time cost 9.043\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.676 | correct, total: (570348,615424)\n",
      "##########one 200 batch totally time cost 10.397\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.656 | correct, total: (665108,717824)\n",
      "epochIndex 75 |time: 10 | Acc: 92.659 | correct, total: (670420,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.156 | Acc: 93.848 | correct, total: (961,1024)\n",
      "##########one 200 batch totally time cost 1.473\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.502 | correct, total: (95669,103424)\n",
      "##########one 200 batch totally time cost 2.894\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.680 | correct, total: (190757,205824)\n",
      "##########one 200 batch totally time cost 4.303\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.176 | Acc: 92.588 | correct, total: (285377,308224)\n",
      "##########one 200 batch totally time cost 5.696\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.601 | correct, total: (380241,410624)\n",
      "##########one 200 batch totally time cost 7.045\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.647 | correct, total: (475302,513024)\n",
      "##########one 200 batch totally time cost 8.455\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.174 | Acc: 92.687 | correct, total: (570418,615424)\n",
      "##########one 200 batch totally time cost 9.901\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.677 | correct, total: (665256,717824)\n",
      "epochIndex 76 |time: 9 | Acc: 92.679 | correct, total: (670564,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.168 | Acc: 91.895 | correct, total: (941,1024)\n",
      "##########one 200 batch totally time cost 1.951\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.626 | correct, total: (95798,103424)\n",
      "##########one 200 batch totally time cost 3.362\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.172 | Acc: 92.681 | correct, total: (190759,205824)\n",
      "##########one 200 batch totally time cost 4.847\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.604 | correct, total: (285428,308224)\n",
      "##########one 200 batch totally time cost 6.807\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.174 | Acc: 92.633 | correct, total: (380374,410624)\n",
      "##########one 200 batch totally time cost 8.634\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.173 | Acc: 92.673 | correct, total: (475433,513024)\n",
      "##########one 200 batch totally time cost 10.474\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.174 | Acc: 92.655 | correct, total: (570221,615424)\n",
      "##########one 200 batch totally time cost 11.932\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.644 | correct, total: (665024,717824)\n",
      "epochIndex 77 |time: 12 | Acc: 92.651 | correct, total: (670363,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.146 | Acc: 94.238 | correct, total: (965,1024)\n",
      "##########one 200 batch totally time cost 1.433\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.178 | Acc: 92.564 | correct, total: (95733,103424)\n",
      "##########one 200 batch totally time cost 2.899\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.651 | correct, total: (190698,205824)\n",
      "##########one 200 batch totally time cost 4.285\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.176 | Acc: 92.587 | correct, total: (285374,308224)\n",
      "##########one 200 batch totally time cost 5.712\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.599 | correct, total: (380233,410624)\n",
      "##########one 200 batch totally time cost 7.127\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.605 | correct, total: (475084,513024)\n",
      "##########one 200 batch totally time cost 8.538\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.612 | correct, total: (569955,615424)\n",
      "##########one 200 batch totally time cost 9.968\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.582 | correct, total: (664577,717824)\n",
      "epochIndex 78 |time: 10 | Acc: 92.585 | correct, total: (669881,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.175 | Acc: 92.871 | correct, total: (951,1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 1.470\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.551 | correct, total: (95720,103424)\n",
      "##########one 200 batch totally time cost 2.882\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.175 | Acc: 92.648 | correct, total: (190691,205824)\n",
      "##########one 200 batch totally time cost 4.293\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.680 | correct, total: (285661,308224)\n",
      "##########one 200 batch totally time cost 5.723\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.616 | correct, total: (380302,410624)\n",
      "##########one 200 batch totally time cost 7.153\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.595 | correct, total: (475036,513024)\n",
      "##########one 200 batch totally time cost 8.510\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.580 | correct, total: (569761,615424)\n",
      "##########one 200 batch totally time cost 9.939\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.587 | correct, total: (664610,717824)\n",
      "epochIndex 79 |time: 10 | Acc: 92.584 | correct, total: (669875,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.060\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.189 | Acc: 91.797 | correct, total: (940,1024)\n",
      "##########one 200 batch totally time cost 1.864\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.178 | Acc: 92.544 | correct, total: (95713,103424)\n",
      "##########one 200 batch totally time cost 3.838\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.173 | Acc: 92.745 | correct, total: (190892,205824)\n",
      "##########one 200 batch totally time cost 5.274\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.173 | Acc: 92.703 | correct, total: (285732,308224)\n",
      "##########one 200 batch totally time cost 7.095\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.174 | Acc: 92.692 | correct, total: (380616,410624)\n",
      "##########one 200 batch totally time cost 8.553\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.174 | Acc: 92.677 | correct, total: (475454,513024)\n",
      "##########one 200 batch totally time cost 9.919\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.174 | Acc: 92.664 | correct, total: (570277,615424)\n",
      "##########one 200 batch totally time cost 11.327\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.639 | correct, total: (664988,717824)\n",
      "epochIndex 80 |time: 11 | Acc: 92.643 | correct, total: (670303,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.182 | Acc: 92.383 | correct, total: (946,1024)\n",
      "##########one 200 batch totally time cost 1.460\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.173 | Acc: 92.661 | correct, total: (95834,103424)\n",
      "##########one 200 batch totally time cost 2.854\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.173 | Acc: 92.682 | correct, total: (190761,205824)\n",
      "##########one 200 batch totally time cost 4.275\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.617 | correct, total: (285468,308224)\n",
      "##########one 200 batch totally time cost 5.628\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.587 | correct, total: (380185,410624)\n",
      "##########one 200 batch totally time cost 7.030\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.630 | correct, total: (475216,513024)\n",
      "##########one 200 batch totally time cost 8.427\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.613 | correct, total: (569963,615424)\n",
      "##########one 200 batch totally time cost 9.832\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.620 | correct, total: (664848,717824)\n",
      "epochIndex 81 |time: 9 | Acc: 92.627 | correct, total: (670184,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.179 | Acc: 92.090 | correct, total: (943,1024)\n",
      "##########one 200 batch totally time cost 1.476\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.631 | correct, total: (95803,103424)\n",
      "##########one 200 batch totally time cost 2.827\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.171 | Acc: 92.667 | correct, total: (190730,205824)\n",
      "##########one 200 batch totally time cost 4.268\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.173 | Acc: 92.634 | correct, total: (285520,308224)\n",
      "##########one 200 batch totally time cost 6.086\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.532 | correct, total: (379957,410624)\n",
      "##########one 200 batch totally time cost 7.525\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.590 | correct, total: (475011,513024)\n",
      "##########one 200 batch totally time cost 8.933\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.589 | correct, total: (569818,615424)\n",
      "##########one 200 batch totally time cost 10.292\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.637 | correct, total: (664968,717824)\n",
      "epochIndex 82 |time: 10 | Acc: 92.639 | correct, total: (670272,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.156 | Acc: 94.238 | correct, total: (965,1024)\n",
      "##########one 200 batch totally time cost 1.558\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.177 | Acc: 92.621 | correct, total: (95792,103424)\n",
      "##########one 200 batch totally time cost 2.988\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.663 | correct, total: (190723,205824)\n",
      "##########one 200 batch totally time cost 4.410\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.633 | correct, total: (285518,308224)\n",
      "##########one 200 batch totally time cost 5.819\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.173 | Acc: 92.697 | correct, total: (380637,410624)\n",
      "##########one 200 batch totally time cost 7.175\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.173 | Acc: 92.721 | correct, total: (475683,513024)\n",
      "##########one 200 batch totally time cost 8.643\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.174 | Acc: 92.672 | correct, total: (570328,615424)\n",
      "##########one 200 batch totally time cost 10.000\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.173 | Acc: 92.687 | correct, total: (665333,717824)\n",
      "epochIndex 83 |time: 10 | Acc: 92.684 | correct, total: (670601,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.195 | Acc: 91.699 | correct, total: (939,1024)\n",
      "##########one 200 batch totally time cost 1.494\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.174 | Acc: 92.621 | correct, total: (95792,103424)\n",
      "##########one 200 batch totally time cost 2.961\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.652 | correct, total: (190701,205824)\n",
      "##########one 200 batch totally time cost 4.810\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.172 | Acc: 92.703 | correct, total: (285734,308224)\n",
      "##########one 200 batch totally time cost 6.262\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.172 | Acc: 92.736 | correct, total: (380797,410624)\n",
      "##########one 200 batch totally time cost 8.079\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.173 | Acc: 92.694 | correct, total: (475543,513024)\n",
      "##########one 200 batch totally time cost 9.547\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.697 | correct, total: (570482,615424)\n",
      "##########one 200 batch totally time cost 10.991\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.173 | Acc: 92.696 | correct, total: (665396,717824)\n",
      "epochIndex 84 |time: 11 | Acc: 92.695 | correct, total: (670680,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.219 | Acc: 91.309 | correct, total: (935,1024)\n",
      "##########one 200 batch totally time cost 1.909\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.513 | correct, total: (95681,103424)\n",
      "##########one 200 batch totally time cost 3.328\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.500 | correct, total: (190387,205824)\n",
      "##########one 200 batch totally time cost 4.698\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.581 | correct, total: (285356,308224)\n",
      "##########one 200 batch totally time cost 6.106\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.602 | correct, total: (380246,410624)\n",
      "##########one 200 batch totally time cost 7.508\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.174 | Acc: 92.643 | correct, total: (475279,513024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 8.946\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.596 | correct, total: (569855,615424)\n",
      "##########one 200 batch totally time cost 10.812\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.622 | correct, total: (664866,717824)\n",
      "epochIndex 85 |time: 10 | Acc: 92.620 | correct, total: (670134,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.060\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.178 | Acc: 93.164 | correct, total: (954,1024)\n",
      "##########one 200 batch totally time cost 1.442\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.176 | Acc: 92.626 | correct, total: (95797,103424)\n",
      "##########one 200 batch totally time cost 2.859\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.554 | correct, total: (190499,205824)\n",
      "##########one 200 batch totally time cost 4.266\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.176 | Acc: 92.600 | correct, total: (285414,308224)\n",
      "##########one 200 batch totally time cost 5.667\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.174 | Acc: 92.639 | correct, total: (380396,410624)\n",
      "##########one 200 batch totally time cost 7.107\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.173 | Acc: 92.676 | correct, total: (475451,513024)\n",
      "##########one 200 batch totally time cost 8.931\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.658 | correct, total: (570237,615424)\n",
      "##########one 200 batch totally time cost 10.388\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.671 | correct, total: (665218,717824)\n",
      "epochIndex 86 |time: 10 | Acc: 92.674 | correct, total: (670526,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.211 | Acc: 90.723 | correct, total: (929,1024)\n",
      "##########one 200 batch totally time cost 1.432\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.167 | Acc: 92.935 | correct, total: (96117,103424)\n",
      "##########one 200 batch totally time cost 2.853\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.171 | Acc: 92.774 | correct, total: (190951,205824)\n",
      "##########one 200 batch totally time cost 4.255\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.172 | Acc: 92.723 | correct, total: (285796,308224)\n",
      "##########one 200 batch totally time cost 5.657\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.173 | Acc: 92.703 | correct, total: (380662,410624)\n",
      "##########one 200 batch totally time cost 7.063\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.562 | correct, total: (474867,513024)\n",
      "##########one 200 batch totally time cost 8.430\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.178 | Acc: 92.479 | correct, total: (569138,615424)\n",
      "##########one 200 batch totally time cost 9.833\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.433 | correct, total: (663506,717824)\n",
      "epochIndex 87 |time: 9 | Acc: 92.439 | correct, total: (668826,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.206 | Acc: 90.137 | correct, total: (923,1024)\n",
      "##########one 200 batch totally time cost 1.488\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.186 | Acc: 92.112 | correct, total: (95266,103424)\n",
      "##########one 200 batch totally time cost 2.891\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.186 | Acc: 92.150 | correct, total: (189667,205824)\n",
      "##########one 200 batch totally time cost 4.320\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.186 | Acc: 92.139 | correct, total: (283994,308224)\n",
      "##########one 200 batch totally time cost 5.682\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.189 | Acc: 92.094 | correct, total: (378159,410624)\n",
      "##########one 200 batch totally time cost 7.095\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.187 | Acc: 92.159 | correct, total: (472799,513024)\n",
      "##########one 200 batch totally time cost 8.624\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.186 | Acc: 92.158 | correct, total: (567162,615424)\n",
      "##########one 200 batch totally time cost 10.541\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.186 | Acc: 92.180 | correct, total: (661688,717824)\n",
      "epochIndex 88 |time: 10 | Acc: 92.181 | correct, total: (666958,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.204 | Acc: 91.406 | correct, total: (936,1024)\n",
      "##########one 200 batch totally time cost 1.483\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.186 | Acc: 92.172 | correct, total: (95328,103424)\n",
      "##########one 200 batch totally time cost 2.844\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.184 | Acc: 92.273 | correct, total: (189921,205824)\n",
      "##########one 200 batch totally time cost 4.260\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.248 | correct, total: (284331,308224)\n",
      "##########one 200 batch totally time cost 6.137\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.183 | Acc: 92.264 | correct, total: (378859,410624)\n",
      "##########one 200 batch totally time cost 7.551\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.183 | Acc: 92.291 | correct, total: (473477,513024)\n",
      "##########one 200 batch totally time cost 8.993\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.182 | Acc: 92.343 | correct, total: (568303,615424)\n",
      "##########one 200 batch totally time cost 10.375\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.182 | Acc: 92.313 | correct, total: (662646,717824)\n",
      "epochIndex 89 |time: 10 | Acc: 92.308 | correct, total: (667877,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.164 | Acc: 93.652 | correct, total: (959,1024)\n",
      "##########one 200 batch totally time cost 2.003\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.181 | Acc: 92.368 | correct, total: (95531,103424)\n",
      "##########one 200 batch totally time cost 3.350\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.181 | Acc: 92.348 | correct, total: (190075,205824)\n",
      "##########one 200 batch totally time cost 4.751\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.447 | correct, total: (284945,308224)\n",
      "##########one 200 batch totally time cost 6.227\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.179 | Acc: 92.443 | correct, total: (379592,410624)\n",
      "##########one 200 batch totally time cost 7.657\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.454 | correct, total: (474310,513024)\n",
      "##########one 200 batch totally time cost 9.100\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.179 | Acc: 92.417 | correct, total: (568756,615424)\n",
      "##########one 200 batch totally time cost 11.401\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.181 | Acc: 92.370 | correct, total: (663056,717824)\n",
      "epochIndex 90 |time: 11 | Acc: 92.377 | correct, total: (668377,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.158 | Acc: 93.262 | correct, total: (955,1024)\n",
      "##########one 200 batch totally time cost 1.475\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.640 | correct, total: (95812,103424)\n",
      "##########one 200 batch totally time cost 2.884\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.181 | Acc: 92.404 | correct, total: (190190,205824)\n",
      "##########one 200 batch totally time cost 4.300\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.179 | Acc: 92.451 | correct, total: (284957,308224)\n",
      "##########one 200 batch totally time cost 5.716\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.420 | correct, total: (379499,410624)\n",
      "##########one 200 batch totally time cost 7.072\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.475 | correct, total: (474421,513024)\n",
      "##########one 200 batch totally time cost 8.495\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.179 | Acc: 92.446 | correct, total: (568937,615424)\n",
      "##########one 200 batch totally time cost 9.908\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.457 | correct, total: (663677,717824)\n",
      "epochIndex 91 |time: 9 | Acc: 92.461 | correct, total: (668986,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.211 | Acc: 91.113 | correct, total: (933,1024)\n",
      "##########one 200 batch totally time cost 1.512\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.178 | Acc: 92.524 | correct, total: (95692,103424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 3.398\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.565 | correct, total: (190520,205824)\n",
      "##########one 200 batch totally time cost 4.762\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.176 | Acc: 92.496 | correct, total: (285096,308224)\n",
      "##########one 200 batch totally time cost 6.202\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.449 | correct, total: (379618,410624)\n",
      "##########one 200 batch totally time cost 7.626\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.177 | Acc: 92.454 | correct, total: (474312,513024)\n",
      "##########one 200 batch totally time cost 9.504\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.506 | correct, total: (569304,615424)\n",
      "##########one 200 batch totally time cost 10.979\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.178 | Acc: 92.472 | correct, total: (663789,717824)\n",
      "epochIndex 92 |time: 11 | Acc: 92.474 | correct, total: (669082,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.060\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.190 | Acc: 93.066 | correct, total: (953,1024)\n",
      "##########one 200 batch totally time cost 1.432\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.426 | correct, total: (95591,103424)\n",
      "##########one 200 batch totally time cost 3.350\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.482 | correct, total: (190350,205824)\n",
      "##########one 200 batch totally time cost 4.715\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.551 | correct, total: (285265,308224)\n",
      "##########one 200 batch totally time cost 6.151\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.537 | correct, total: (379978,410624)\n",
      "##########one 200 batch totally time cost 7.597\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.177 | Acc: 92.492 | correct, total: (474507,513024)\n",
      "##########one 200 batch totally time cost 9.475\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.494 | correct, total: (569233,615424)\n",
      "##########one 200 batch totally time cost 10.924\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.177 | Acc: 92.496 | correct, total: (663956,717824)\n",
      "epochIndex 93 |time: 11 | Acc: 92.491 | correct, total: (669200,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.256 | Acc: 91.992 | correct, total: (942,1024)\n",
      "##########one 200 batch totally time cost 1.418\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.181 | Acc: 92.372 | correct, total: (95535,103424)\n",
      "##########one 200 batch totally time cost 2.835\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.512 | correct, total: (190412,205824)\n",
      "##########one 200 batch totally time cost 4.345\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.455 | correct, total: (284968,308224)\n",
      "##########one 200 batch totally time cost 5.770\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.552 | correct, total: (380040,410624)\n",
      "##########one 200 batch totally time cost 7.188\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.533 | correct, total: (474718,513024)\n",
      "##########one 200 batch totally time cost 8.547\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.508 | correct, total: (569314,615424)\n",
      "##########one 200 batch totally time cost 9.962\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.536 | correct, total: (664243,717824)\n",
      "epochIndex 94 |time: 10 | Acc: 92.542 | correct, total: (669572,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.162 | Acc: 92.285 | correct, total: (945,1024)\n",
      "##########one 200 batch totally time cost 1.495\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.173 | Acc: 92.654 | correct, total: (95826,103424)\n",
      "##########one 200 batch totally time cost 2.939\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.473 | correct, total: (190332,205824)\n",
      "##########one 200 batch totally time cost 4.819\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.536 | correct, total: (285218,308224)\n",
      "##########one 200 batch totally time cost 6.184\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.177 | Acc: 92.517 | correct, total: (379898,410624)\n",
      "##########one 200 batch totally time cost 7.661\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.489 | correct, total: (474491,513024)\n",
      "##########one 200 batch totally time cost 9.042\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.400 | correct, total: (568654,615424)\n",
      "##########one 200 batch totally time cost 10.462\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.181 | Acc: 92.380 | correct, total: (663126,717824)\n",
      "epochIndex 95 |time: 10 | Acc: 92.379 | correct, total: (668392,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.183 | Acc: 92.871 | correct, total: (951,1024)\n",
      "##########one 200 batch totally time cost 1.509\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.173 | Acc: 92.644 | correct, total: (95816,103424)\n",
      "##########one 200 batch totally time cost 3.320\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.178 | Acc: 92.489 | correct, total: (190365,205824)\n",
      "##########one 200 batch totally time cost 4.781\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.179 | Acc: 92.439 | correct, total: (284919,308224)\n",
      "##########one 200 batch totally time cost 6.151\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.470 | correct, total: (379703,410624)\n",
      "##########one 200 batch totally time cost 7.594\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.179 | Acc: 92.422 | correct, total: (474147,513024)\n",
      "##########one 200 batch totally time cost 10.143\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.406 | correct, total: (568689,615424)\n",
      "##########one 200 batch totally time cost 12.197\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.181 | Acc: 92.380 | correct, total: (663124,717824)\n",
      "epochIndex 96 |time: 12 | Acc: 92.375 | correct, total: (668365,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.186 | Acc: 91.406 | correct, total: (936,1024)\n",
      "##########one 200 batch totally time cost 1.480\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.535 | correct, total: (95703,103424)\n",
      "##########one 200 batch totally time cost 2.863\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.176 | Acc: 92.504 | correct, total: (190396,205824)\n",
      "##########one 200 batch totally time cost 4.853\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.394 | correct, total: (284782,308224)\n",
      "##########one 200 batch totally time cost 6.279\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.383 | correct, total: (379347,410624)\n",
      "##########one 200 batch totally time cost 8.600\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.180 | Acc: 92.383 | correct, total: (473947,513024)\n",
      "##########one 200 batch totally time cost 10.043\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.377 | correct, total: (568513,615424)\n",
      "##########one 200 batch totally time cost 11.401\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.181 | Acc: 92.346 | correct, total: (662880,717824)\n",
      "epochIndex 97 |time: 11 | Acc: 92.347 | correct, total: (668159,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.169 | Acc: 92.188 | correct, total: (944,1024)\n",
      "##########one 200 batch totally time cost 1.509\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.471 | correct, total: (95637,103424)\n",
      "##########one 200 batch totally time cost 3.422\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.182 | Acc: 92.364 | correct, total: (190107,205824)\n",
      "##########one 200 batch totally time cost 4.849\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.181 | Acc: 92.373 | correct, total: (284716,308224)\n",
      "##########one 200 batch totally time cost 6.285\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.179 | Acc: 92.442 | correct, total: (379589,410624)\n",
      "##########one 200 batch totally time cost 7.655\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.369 | correct, total: (473874,513024)\n",
      "##########one 200 batch totally time cost 9.147\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.181 | Acc: 92.388 | correct, total: (568580,615424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 10.532\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.181 | Acc: 92.383 | correct, total: (663149,717824)\n",
      "epochIndex 98 |time: 10 | Acc: 92.385 | correct, total: (668437,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.165 | Acc: 92.676 | correct, total: (949,1024)\n",
      "##########one 200 batch totally time cost 1.885\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.577 | correct, total: (95747,103424)\n",
      "##########one 200 batch totally time cost 3.308\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.179 | Acc: 92.421 | correct, total: (190225,205824)\n",
      "##########one 200 batch totally time cost 4.661\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.179 | Acc: 92.426 | correct, total: (284879,308224)\n",
      "##########one 200 batch totally time cost 6.127\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.454 | correct, total: (379640,410624)\n",
      "##########one 200 batch totally time cost 7.510\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.447 | correct, total: (474276,513024)\n",
      "##########one 200 batch totally time cost 9.487\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.394 | correct, total: (568613,615424)\n",
      "##########one 200 batch totally time cost 11.367\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.180 | Acc: 92.409 | correct, total: (663331,717824)\n",
      "epochIndex 99 |time: 11 | Acc: 92.401 | correct, total: (668550,723532)\n",
      "########################################################################\n"
     ]
    }
   ],
   "source": [
    "###csvmlp\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# \n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 200)\n",
    "        self.fc3 = nn.Linear(200, 100)\n",
    "        self.fc4 = nn.Linear(100, num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "\n",
    "mlp = NeuralNet(14,200,4)\n",
    "print(mlp)\n",
    "\n",
    "##############################################CSV\n",
    "file1 = \"./trainData/dataAllSim.csv\"\n",
    "##1\n",
    "data1=[]\n",
    "csv_reader = csv.reader(open(file1))\n",
    "#for row in csv_reader:\n",
    "#        data1.append(row)\n",
    "#print(data1[0])        \n",
    "\n",
    "##2\n",
    "#https://blog.csdn.net/zw__chen/article/details/82806900\n",
    "csvfile = open(file1, 'r')\n",
    "xyData= np.loadtxt(file1,delimiter=',',skiprows=1)\n",
    "x = xyData[:,0:-1]\n",
    "y = xyData[:,-1]\n",
    "print(y.shape )\n",
    "print(x.shape )\n",
    "x1 =torch.from_numpy(x)\n",
    "y1 =torch.from_numpy(y)\n",
    "\n",
    "dataset1 = TensorDataset(x1.float(),y1.long())\n",
    "\n",
    "#train_dataset, test_dataset = random_split(\n",
    "#    dataset=dataset1,\n",
    "#    lengths=[7, 3],\n",
    "#    generator=torch.Generator().manual_seed(0)\n",
    "#)\n",
    "\n",
    "#################################\n",
    "#\n",
    "#tmp = y.T[0]\n",
    "#trainratio = np.bincount(tmp.astype(\"int64\"))\n",
    "#train_weights = 1./torch.tensor(trainratio, dtype=torch.float)\n",
    "#train_sampleweights = train_weights[y]\n",
    "#train_sampler = WeightedRandomSampler(weights=train_sampleweights, num_samples = len(train_sampleweights))\n",
    "#train_loader = DataLoader( dataset1, batch_size=4, num_workers=1, sampler=train_sampler)\n",
    "train_loader = DataLoader(dataset=dataset1, batch_size=512, shuffle=True)\n",
    "\n",
    "#\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == 'cuda':\n",
    "    mlp = torch.nn.DataParallel(mlp)\n",
    "    cudnn.benchmark = True\n",
    "    mlp =  mlp.to(device)\n",
    "print(device)\n",
    "\n",
    "#\n",
    "state = {\"net\": mlp.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "modelPathName = \"./trainedModes/\"+\"redTLS.modeparams\"\n",
    "params = torch.load(modelPathName)\n",
    "mlp.load_state_dict(params['net'])\n",
    "optimizer.load_state_dict(params['optimizer'])\n",
    "\n",
    "#################################\n",
    "#\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mlp.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "running_loss = 0\n",
    "startEpoch = 0\n",
    "epochs = 3000#8\n",
    "print(\"start training\")\n",
    "\n",
    "for epoch in range(startEpoch, epochs):  # \n",
    "\n",
    "     mlp.train()\n",
    "     time_start = time.time()\n",
    "     total = 0\n",
    "     correct = 0\n",
    "     running_loss = 0.0\n",
    "     \n",
    "     for i, data in enumerate(train_loader, 0):\n",
    "         # \n",
    "         #print(epoch,i)\n",
    "         inputs, labels = data\n",
    "         #inputs, labels = inputs.to(device), labels.to(device)\n",
    "         inputs=inputs.type(torch.float32)\n",
    "         labels=labels\n",
    "           \n",
    "         if device == 'cuda':\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "         # 0\n",
    "         optimizer.zero_grad()\n",
    "\n",
    "         # a\n",
    "         outputs = mlp(inputs)\n",
    "         #print(\"inputs:\",inputs)\n",
    "         #print(\"###################################\")\n",
    "         #print(\"outputs:\",outputs)\n",
    "         #print(\"labels\",labels)\n",
    "\n",
    "         loss = criterion(outputs, labels)\n",
    "         #print(\"loss:\",loss.item())\n",
    "        \n",
    "         loss.backward()\n",
    "         optimizer.step()\n",
    "\n",
    "         _, predicted = torch.max(outputs.data,1)\n",
    "         total += labels.size(0)\n",
    "         correct += predicted.eq(labels).sum().item()\n",
    "         \n",
    "         #print(\"labels.size(0):\",labels.size(0))\n",
    "         #print(\"predicted:\",predicted)\n",
    "         #print(\"predicted.eq(labels).sum().item():\",predicted.eq(labels).sum().item())\n",
    "         \n",
    "         running_loss += loss.item()\n",
    "         \n",
    "         #os.input()\n",
    "         if i % 200 == 1:  # 200\n",
    "             time_end = time.time()\n",
    "             print('##########one 200 batch totally time cost %.3f' %(time_end-time_start))\n",
    "             print(\"batchIndex %d |trainLen %d | Loss: %.3f | Acc: %.3f | correct, total: (%d,%d)\" % (\n",
    "                 i, len(train_loader), running_loss/(i+1), 100.*correct/total, correct, total))\n",
    "             \n",
    "     time_end = time.time()\n",
    "     print(\"epochIndex %d |time: %d | Acc: %.3f | correct, total: (%d,%d)\" % (\n",
    "                 epoch, (time_end-time_start), 100.*correct/total, correct, total))\n",
    "     print(\"########################################################################\")\n",
    "     \n",
    "    \n",
    "state = {\"net\": mlp.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "modelPathName = \"./trainedModes/\"+\"redTLS.modeparams\"\n",
    "torch.save(state, modelPathName)\n",
    "params = torch.load(modelPathName)\n",
    "mlp.load_state_dict(params['net'])\n",
    "optimizer.load_state_dict(params['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "422e83c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"net\": mlp.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "modelPathName = \"./trainedModes/\"+\"redTLS.modeparams\"\n",
    "torch.save(state, modelPathName)\n",
    "params = torch.load(modelPathName)\n",
    "mlp.load_state_dict(params['net'])\n",
    "optimizer.load_state_dict(params['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98475bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 5e9094a] csvMLPOK\n",
      " 6 files changed, 2828 insertions(+), 402 deletions(-)\n",
      " rewrite mainNBDT1.ipynb (99%)\n",
      " create mode 100644 mainTestCSVMLP2-Copy1.ipynb\n",
      " create mode 100644 mainTestCSVMLP2.ipynb\n",
      " rewrite trainData/dataAllSim.zip (90%)\n",
      " create mode 100644 trainedModes/redTLS.modeparams\n",
      "Enumerating objects: 27, done.\n",
      "Counting objects: 100% (27/27), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (18/18), done.\n",
      "Writing objects:  85% (17/20), 325.52 MiB | 1.21 MiB/s \r"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m  \"csvMLPOK\"\n",
    "!git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
