{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6a93409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (fc1): Linear(in_features=14, out_features=200, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fc4): Linear(in_features=100, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "(723532,)\n",
      "(723532, 14)\n",
      "start training\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 1.187 | Acc: 46.191 | correct, total: (473,1024)\n",
      "##########one 200 batch totally time cost 1.497\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.518 | Acc: 82.058 | correct, total: (84868,103424)\n",
      "##########one 200 batch totally time cost 2.980\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.441 | Acc: 83.959 | correct, total: (172807,205824)\n",
      "##########one 200 batch totally time cost 4.891\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.406 | Acc: 84.916 | correct, total: (261733,308224)\n",
      "##########one 200 batch totally time cost 6.291\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.380 | Acc: 85.701 | correct, total: (351910,410624)\n",
      "##########one 200 batch totally time cost 7.707\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.362 | Acc: 86.334 | correct, total: (442914,513024)\n",
      "##########one 200 batch totally time cost 9.111\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.347 | Acc: 86.829 | correct, total: (534365,615424)\n",
      "##########one 200 batch totally time cost 10.470\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.335 | Acc: 87.251 | correct, total: (626306,717824)\n",
      "epochIndex 0 |time: 10 | Acc: 87.277 | correct, total: (631478,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.060\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.254 | Acc: 89.746 | correct, total: (919,1024)\n",
      "##########one 200 batch totally time cost 1.474\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.248 | Acc: 90.205 | correct, total: (93294,103424)\n",
      "##########one 200 batch totally time cost 2.907\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.250 | Acc: 90.131 | correct, total: (185511,205824)\n",
      "##########one 200 batch totally time cost 4.770\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.245 | Acc: 90.254 | correct, total: (278186,308224)\n",
      "##########one 200 batch totally time cost 6.189\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.245 | Acc: 90.247 | correct, total: (370576,410624)\n",
      "##########one 200 batch totally time cost 7.546\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.242 | Acc: 90.335 | correct, total: (463440,513024)\n",
      "##########one 200 batch totally time cost 8.954\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.240 | Acc: 90.411 | correct, total: (556408,615424)\n",
      "##########one 200 batch totally time cost 10.367\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.237 | Acc: 90.484 | correct, total: (649514,717824)\n",
      "epochIndex 1 |time: 10 | Acc: 90.495 | correct, total: (654758,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.203 | Acc: 92.188 | correct, total: (944,1024)\n",
      "##########one 200 batch totally time cost 1.477\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.238 | Acc: 90.475 | correct, total: (93573,103424)\n",
      "##########one 200 batch totally time cost 2.886\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.226 | Acc: 90.883 | correct, total: (187060,205824)\n",
      "##########one 200 batch totally time cost 4.232\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.228 | Acc: 90.822 | correct, total: (279934,308224)\n",
      "##########one 200 batch totally time cost 5.736\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.227 | Acc: 90.876 | correct, total: (373160,410624)\n",
      "##########one 200 batch totally time cost 7.553\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.226 | Acc: 90.904 | correct, total: (466361,513024)\n",
      "##########one 200 batch totally time cost 8.972\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.225 | Acc: 90.938 | correct, total: (559655,615424)\n",
      "##########one 200 batch totally time cost 10.423\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.224 | Acc: 90.984 | correct, total: (653105,717824)\n",
      "epochIndex 2 |time: 10 | Acc: 90.988 | correct, total: (658324,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.198 | Acc: 91.895 | correct, total: (941,1024)\n",
      "##########one 200 batch totally time cost 1.478\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.204 | Acc: 91.567 | correct, total: (94702,103424)\n",
      "##########one 200 batch totally time cost 2.908\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.206 | Acc: 91.481 | correct, total: (188290,205824)\n",
      "##########one 200 batch totally time cost 4.292\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.207 | Acc: 91.483 | correct, total: (281974,308224)\n",
      "##########one 200 batch totally time cost 6.272\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.206 | Acc: 91.524 | correct, total: (375820,410624)\n",
      "##########one 200 batch totally time cost 7.692\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.205 | Acc: 91.549 | correct, total: (469666,513024)\n",
      "##########one 200 batch totally time cost 9.583\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.204 | Acc: 91.601 | correct, total: (563733,615424)\n",
      "##########one 200 batch totally time cost 10.998\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.204 | Acc: 91.587 | correct, total: (657433,717824)\n",
      "epochIndex 3 |time: 11 | Acc: 91.584 | correct, total: (662638,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.219 | Acc: 91.895 | correct, total: (941,1024)\n",
      "##########one 200 batch totally time cost 1.434\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.201 | Acc: 91.726 | correct, total: (94867,103424)\n",
      "##########one 200 batch totally time cost 2.839\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.204 | Acc: 91.597 | correct, total: (188528,205824)\n",
      "##########one 200 batch totally time cost 4.265\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.205 | Acc: 91.591 | correct, total: (282305,308224)\n",
      "##########one 200 batch totally time cost 5.690\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.204 | Acc: 91.638 | correct, total: (376286,410624)\n",
      "##########one 200 batch totally time cost 7.125\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.204 | Acc: 91.588 | correct, total: (469870,513024)\n",
      "##########one 200 batch totally time cost 8.956\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.203 | Acc: 91.631 | correct, total: (563921,615424)\n",
      "##########one 200 batch totally time cost 10.371\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.203 | Acc: 91.651 | correct, total: (657890,717824)\n",
      "epochIndex 4 |time: 10 | Acc: 91.655 | correct, total: (663152,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.204 | Acc: 91.211 | correct, total: (934,1024)\n",
      "##########one 200 batch totally time cost 1.468\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.206 | Acc: 91.590 | correct, total: (94726,103424)\n",
      "##########one 200 batch totally time cost 2.847\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.201 | Acc: 91.641 | correct, total: (188619,205824)\n",
      "##########one 200 batch totally time cost 4.286\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.198 | Acc: 91.772 | correct, total: (282863,308224)\n",
      "##########one 200 batch totally time cost 5.720\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.200 | Acc: 91.729 | correct, total: (376661,410624)\n",
      "##########one 200 batch totally time cost 7.577\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.199 | Acc: 91.758 | correct, total: (470743,513024)\n",
      "##########one 200 batch totally time cost 9.002\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.198 | Acc: 91.780 | correct, total: (564838,615424)\n",
      "##########one 200 batch totally time cost 10.358\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.198 | Acc: 91.795 | correct, total: (658928,717824)\n",
      "epochIndex 5 |time: 10 | Acc: 91.800 | correct, total: (664199,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.227 | Acc: 90.430 | correct, total: (926,1024)\n",
      "##########one 200 batch totally time cost 1.476\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.211 | Acc: 91.298 | correct, total: (94424,103424)\n",
      "##########one 200 batch totally time cost 2.913\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.204 | Acc: 91.590 | correct, total: (188515,205824)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 4.328\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.201 | Acc: 91.713 | correct, total: (282680,308224)\n",
      "##########one 200 batch totally time cost 5.739\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.200 | Acc: 91.740 | correct, total: (376708,410624)\n",
      "##########one 200 batch totally time cost 7.104\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.199 | Acc: 91.791 | correct, total: (470910,513024)\n",
      "##########one 200 batch totally time cost 8.534\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.197 | Acc: 91.854 | correct, total: (565292,615424)\n",
      "##########one 200 batch totally time cost 9.938\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.198 | Acc: 91.831 | correct, total: (659183,717824)\n",
      "epochIndex 6 |time: 10 | Acc: 91.833 | correct, total: (664444,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.062\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.183 | Acc: 92.676 | correct, total: (949,1024)\n",
      "##########one 200 batch totally time cost 1.475\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.197 | Acc: 91.895 | correct, total: (95042,103424)\n",
      "##########one 200 batch totally time cost 2.894\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.194 | Acc: 91.944 | correct, total: (189242,205824)\n",
      "##########one 200 batch totally time cost 4.264\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.194 | Acc: 91.904 | correct, total: (283270,308224)\n",
      "##########one 200 batch totally time cost 5.752\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.193 | Acc: 91.911 | correct, total: (377409,410624)\n",
      "##########one 200 batch totally time cost 7.125\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.195 | Acc: 91.884 | correct, total: (471388,513024)\n",
      "##########one 200 batch totally time cost 8.584\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.193 | Acc: 91.939 | correct, total: (565814,615424)\n",
      "##########one 200 batch totally time cost 9.990\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.193 | Acc: 91.922 | correct, total: (659840,717824)\n",
      "epochIndex 7 |time: 10 | Acc: 91.922 | correct, total: (665088,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.184 | Acc: 92.383 | correct, total: (946,1024)\n",
      "##########one 200 batch totally time cost 1.932\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.191 | Acc: 92.002 | correct, total: (95152,103424)\n",
      "##########one 200 batch totally time cost 3.830\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.191 | Acc: 92.043 | correct, total: (189446,205824)\n",
      "##########one 200 batch totally time cost 5.182\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.193 | Acc: 91.972 | correct, total: (283479,308224)\n",
      "##########one 200 batch totally time cost 6.604\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.191 | Acc: 92.039 | correct, total: (377935,410624)\n",
      "##########one 200 batch totally time cost 8.062\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.188 | Acc: 92.156 | correct, total: (472782,513024)\n",
      "##########one 200 batch totally time cost 9.475\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.188 | Acc: 92.137 | correct, total: (567035,615424)\n",
      "##########one 200 batch totally time cost 10.898\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.188 | Acc: 92.133 | correct, total: (661351,717824)\n",
      "epochIndex 8 |time: 10 | Acc: 92.123 | correct, total: (666542,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.217 | Acc: 91.113 | correct, total: (933,1024)\n",
      "##########one 200 batch totally time cost 1.421\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.191 | Acc: 92.071 | correct, total: (95223,103424)\n",
      "##########one 200 batch totally time cost 2.844\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.190 | Acc: 92.073 | correct, total: (189509,205824)\n",
      "##########one 200 batch totally time cost 4.332\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.192 | Acc: 91.975 | correct, total: (283488,308224)\n",
      "##########one 200 batch totally time cost 5.757\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.192 | Acc: 91.967 | correct, total: (377637,410624)\n",
      "##########one 200 batch totally time cost 7.185\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.192 | Acc: 92.004 | correct, total: (472004,513024)\n",
      "##########one 200 batch totally time cost 8.554\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.192 | Acc: 92.005 | correct, total: (566218,615424)\n",
      "##########one 200 batch totally time cost 9.961\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.192 | Acc: 91.988 | correct, total: (660312,717824)\n",
      "epochIndex 9 |time: 10 | Acc: 91.987 | correct, total: (665552,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.061\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.191 | Acc: 92.285 | correct, total: (945,1024)\n",
      "##########one 200 batch totally time cost 1.459\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.186 | Acc: 92.212 | correct, total: (95369,103424)\n",
      "##########one 200 batch totally time cost 3.272\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.182 | Acc: 92.384 | correct, total: (190149,205824)\n",
      "##########one 200 batch totally time cost 4.717\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.185 | Acc: 92.246 | correct, total: (284324,308224)\n",
      "##########one 200 batch totally time cost 6.084\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.186 | Acc: 92.221 | correct, total: (378680,410624)\n",
      "##########one 200 batch totally time cost 7.572\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.185 | Acc: 92.241 | correct, total: (473221,513024)\n",
      "##########one 200 batch totally time cost 8.922\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.186 | Acc: 92.208 | correct, total: (567473,615424)\n",
      "##########one 200 batch totally time cost 10.324\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.187 | Acc: 92.199 | correct, total: (661823,717824)\n",
      "epochIndex 10 |time: 10 | Acc: 92.203 | correct, total: (667117,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.070\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.179 | Acc: 91.797 | correct, total: (940,1024)\n",
      "##########one 200 batch totally time cost 1.501\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.191 | Acc: 92.027 | correct, total: (95178,103424)\n",
      "##########one 200 batch totally time cost 2.913\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.186 | Acc: 92.244 | correct, total: (189860,205824)\n",
      "##########one 200 batch totally time cost 4.329\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.189 | Acc: 92.108 | correct, total: (283898,308224)\n",
      "##########one 200 batch totally time cost 6.188\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.188 | Acc: 92.159 | correct, total: (378425,410624)\n",
      "##########one 200 batch totally time cost 7.604\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.187 | Acc: 92.208 | correct, total: (473048,513024)\n",
      "##########one 200 batch totally time cost 9.477\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.187 | Acc: 92.169 | correct, total: (567229,615424)\n",
      "##########one 200 batch totally time cost 10.894\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.188 | Acc: 92.148 | correct, total: (661458,717824)\n",
      "epochIndex 11 |time: 10 | Acc: 92.150 | correct, total: (666736,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.066\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.174 | Acc: 91.992 | correct, total: (942,1024)\n",
      "##########one 200 batch totally time cost 1.515\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.188 | Acc: 92.097 | correct, total: (95250,103424)\n",
      "##########one 200 batch totally time cost 3.338\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.187 | Acc: 92.195 | correct, total: (189759,205824)\n",
      "##########one 200 batch totally time cost 4.760\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.187 | Acc: 92.198 | correct, total: (284176,308224)\n",
      "##########one 200 batch totally time cost 6.177\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.187 | Acc: 92.182 | correct, total: (378522,410624)\n",
      "##########one 200 batch totally time cost 7.590\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.185 | Acc: 92.262 | correct, total: (473327,513024)\n",
      "##########one 200 batch totally time cost 9.013\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.187 | Acc: 92.204 | correct, total: (567447,615424)\n",
      "##########one 200 batch totally time cost 10.370\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.186 | Acc: 92.208 | correct, total: (661890,717824)\n",
      "epochIndex 12 |time: 10 | Acc: 92.205 | correct, total: (667135,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.200 | Acc: 91.504 | correct, total: (937,1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 1.536\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.184 | Acc: 92.213 | correct, total: (95370,103424)\n",
      "##########one 200 batch totally time cost 2.881\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.190 | Acc: 92.075 | correct, total: (189512,205824)\n",
      "##########one 200 batch totally time cost 4.303\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.187 | Acc: 92.178 | correct, total: (284115,308224)\n",
      "##########one 200 batch totally time cost 5.710\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.186 | Acc: 92.230 | correct, total: (378720,410624)\n",
      "##########one 200 batch totally time cost 7.062\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.187 | Acc: 92.185 | correct, total: (472932,513024)\n",
      "##########one 200 batch totally time cost 8.521\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.189 | Acc: 92.122 | correct, total: (566941,615424)\n",
      "##########one 200 batch totally time cost 9.908\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.188 | Acc: 92.110 | correct, total: (661185,717824)\n",
      "epochIndex 13 |time: 9 | Acc: 92.103 | correct, total: (666397,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.197 | Acc: 91.797 | correct, total: (940,1024)\n",
      "##########one 200 batch totally time cost 1.480\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.184 | Acc: 92.267 | correct, total: (95426,103424)\n",
      "##########one 200 batch totally time cost 3.387\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.182 | Acc: 92.325 | correct, total: (190028,205824)\n",
      "##########one 200 batch totally time cost 5.117\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.414 | correct, total: (284843,308224)\n",
      "##########one 200 batch totally time cost 6.682\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.183 | Acc: 92.329 | correct, total: (379126,410624)\n",
      "##########one 200 batch totally time cost 8.056\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.183 | Acc: 92.315 | correct, total: (473600,513024)\n",
      "##########one 200 batch totally time cost 9.476\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.291 | correct, total: (567978,615424)\n",
      "##########one 200 batch totally time cost 10.895\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.184 | Acc: 92.262 | correct, total: (662279,717824)\n",
      "epochIndex 14 |time: 10 | Acc: 92.262 | correct, total: (667545,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.245 | Acc: 88.867 | correct, total: (910,1024)\n",
      "##########one 200 batch totally time cost 1.561\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.189 | Acc: 92.028 | correct, total: (95179,103424)\n",
      "##########one 200 batch totally time cost 2.989\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.185 | Acc: 92.214 | correct, total: (189799,205824)\n",
      "##########one 200 batch totally time cost 4.391\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.185 | Acc: 92.214 | correct, total: (284226,308224)\n",
      "##########one 200 batch totally time cost 5.829\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.185 | Acc: 92.222 | correct, total: (378684,410624)\n",
      "##########one 200 batch totally time cost 7.253\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.189 | Acc: 92.089 | correct, total: (472438,513024)\n",
      "##########one 200 batch totally time cost 8.674\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.188 | Acc: 92.126 | correct, total: (566968,615424)\n",
      "##########one 200 batch totally time cost 10.470\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.189 | Acc: 92.101 | correct, total: (661124,717824)\n",
      "epochIndex 15 |time: 10 | Acc: 92.100 | correct, total: (666374,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.169 | Acc: 92.773 | correct, total: (950,1024)\n",
      "##########one 200 batch totally time cost 1.444\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.445 | correct, total: (95610,103424)\n",
      "##########one 200 batch totally time cost 2.913\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.181 | Acc: 92.390 | correct, total: (190161,205824)\n",
      "##########one 200 batch totally time cost 4.273\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.183 | Acc: 92.305 | correct, total: (284507,308224)\n",
      "##########one 200 batch totally time cost 5.717\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.256 | correct, total: (378825,410624)\n",
      "##########one 200 batch totally time cost 7.647\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.267 | correct, total: (473352,513024)\n",
      "##########one 200 batch totally time cost 9.018\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.184 | Acc: 92.274 | correct, total: (567879,615424)\n",
      "##########one 200 batch totally time cost 10.497\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.296 | correct, total: (662522,717824)\n",
      "epochIndex 16 |time: 10 | Acc: 92.294 | correct, total: (667780,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.221 | Acc: 90.039 | correct, total: (922,1024)\n",
      "##########one 200 batch totally time cost 1.427\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.180 | Acc: 92.410 | correct, total: (95574,103424)\n",
      "##########one 200 batch totally time cost 2.848\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.183 | Acc: 92.264 | correct, total: (189901,205824)\n",
      "##########one 200 batch totally time cost 4.282\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.183 | Acc: 92.236 | correct, total: (284295,308224)\n",
      "##########one 200 batch totally time cost 5.687\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.186 | Acc: 92.145 | correct, total: (378369,410624)\n",
      "##########one 200 batch totally time cost 7.544\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.185 | Acc: 92.203 | correct, total: (473024,513024)\n",
      "##########one 200 batch totally time cost 8.906\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.186 | Acc: 92.175 | correct, total: (567268,615424)\n",
      "##########one 200 batch totally time cost 10.314\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.185 | Acc: 92.178 | correct, total: (661677,717824)\n",
      "epochIndex 17 |time: 10 | Acc: 92.180 | correct, total: (666953,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.194 | Acc: 91.211 | correct, total: (934,1024)\n",
      "##########one 200 batch totally time cost 1.478\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.182 | Acc: 92.220 | correct, total: (95378,103424)\n",
      "##########one 200 batch totally time cost 2.889\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.181 | Acc: 92.324 | correct, total: (190025,205824)\n",
      "##########one 200 batch totally time cost 4.309\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.182 | Acc: 92.300 | correct, total: (284490,308224)\n",
      "##########one 200 batch totally time cost 6.149\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.348 | correct, total: (379204,410624)\n",
      "##########one 200 batch totally time cost 7.574\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.308 | correct, total: (473563,513024)\n",
      "##########one 200 batch totally time cost 9.486\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.267 | correct, total: (567836,615424)\n",
      "##########one 200 batch totally time cost 10.903\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.275 | correct, total: (662373,717824)\n",
      "epochIndex 18 |time: 10 | Acc: 92.285 | correct, total: (667709,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.186 | Acc: 92.383 | correct, total: (946,1024)\n",
      "##########one 200 batch totally time cost 1.492\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.186 | Acc: 92.196 | correct, total: (95353,103424)\n",
      "##########one 200 batch totally time cost 2.846\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.184 | Acc: 92.244 | correct, total: (189861,205824)\n",
      "##########one 200 batch totally time cost 4.315\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.185 | Acc: 92.186 | correct, total: (284140,308224)\n",
      "##########one 200 batch totally time cost 5.686\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.185 | Acc: 92.231 | correct, total: (378722,410624)\n",
      "##########one 200 batch totally time cost 7.116\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.267 | correct, total: (473354,513024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 8.529\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.332 | correct, total: (568235,615424)\n",
      "##########one 200 batch totally time cost 9.901\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.338 | correct, total: (662827,717824)\n",
      "epochIndex 19 |time: 10 | Acc: 92.343 | correct, total: (668128,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.066\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.238 | Acc: 90.430 | correct, total: (926,1024)\n",
      "##########one 200 batch totally time cost 1.502\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.187 | Acc: 92.227 | correct, total: (95385,103424)\n",
      "##########one 200 batch totally time cost 2.875\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.185 | Acc: 92.229 | correct, total: (189829,205824)\n",
      "##########one 200 batch totally time cost 4.282\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.287 | correct, total: (284450,308224)\n",
      "##########one 200 batch totally time cost 5.681\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.182 | Acc: 92.343 | correct, total: (379183,410624)\n",
      "##########one 200 batch totally time cost 7.096\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.388 | correct, total: (473971,513024)\n",
      "##########one 200 batch totally time cost 8.619\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.410 | correct, total: (568711,615424)\n",
      "##########one 200 batch totally time cost 10.013\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.180 | Acc: 92.402 | correct, total: (663281,717824)\n",
      "epochIndex 20 |time: 10 | Acc: 92.399 | correct, total: (668539,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.193 | Acc: 91.309 | correct, total: (935,1024)\n",
      "##########one 200 batch totally time cost 1.959\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.185 | Acc: 92.239 | correct, total: (95397,103424)\n",
      "##########one 200 batch totally time cost 3.833\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.180 | Acc: 92.429 | correct, total: (190241,205824)\n",
      "##########one 200 batch totally time cost 5.267\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.181 | Acc: 92.389 | correct, total: (284766,308224)\n",
      "##########one 200 batch totally time cost 6.703\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.181 | Acc: 92.397 | correct, total: (379406,410624)\n",
      "##########one 200 batch totally time cost 8.068\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.364 | correct, total: (473850,513024)\n",
      "##########one 200 batch totally time cost 9.514\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.399 | correct, total: (568647,615424)\n",
      "##########one 200 batch totally time cost 10.946\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.441 | correct, total: (663562,717824)\n",
      "epochIndex 21 |time: 11 | Acc: 92.435 | correct, total: (668799,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.184 | Acc: 93.750 | correct, total: (960,1024)\n",
      "##########one 200 batch totally time cost 1.476\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.184 | Acc: 92.314 | correct, total: (95475,103424)\n",
      "##########one 200 batch totally time cost 2.885\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.183 | Acc: 92.288 | correct, total: (189951,205824)\n",
      "##########one 200 batch totally time cost 4.283\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.399 | correct, total: (284797,308224)\n",
      "##########one 200 batch totally time cost 5.779\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.416 | correct, total: (379481,410624)\n",
      "##########one 200 batch totally time cost 7.143\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.179 | Acc: 92.451 | correct, total: (474298,513024)\n",
      "##########one 200 batch totally time cost 8.562\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.179 | Acc: 92.450 | correct, total: (568962,615424)\n",
      "##########one 200 batch totally time cost 10.510\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.445 | correct, total: (663589,717824)\n",
      "epochIndex 22 |time: 10 | Acc: 92.442 | correct, total: (668849,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.167 | Acc: 92.578 | correct, total: (948,1024)\n",
      "##########one 200 batch totally time cost 1.933\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.594 | correct, total: (95764,103424)\n",
      "##########one 200 batch totally time cost 3.785\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.175 | Acc: 92.623 | correct, total: (190641,205824)\n",
      "##########one 200 batch totally time cost 5.135\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.528 | correct, total: (285193,308224)\n",
      "##########one 200 batch totally time cost 6.538\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.504 | correct, total: (379843,410624)\n",
      "##########one 200 batch totally time cost 7.953\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.177 | Acc: 92.524 | correct, total: (474671,513024)\n",
      "##########one 200 batch totally time cost 9.386\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.178 | Acc: 92.511 | correct, total: (569333,615424)\n",
      "##########one 200 batch totally time cost 10.803\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.178 | Acc: 92.492 | correct, total: (663928,717824)\n",
      "epochIndex 23 |time: 10 | Acc: 92.488 | correct, total: (669181,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.176 | Acc: 93.359 | correct, total: (956,1024)\n",
      "##########one 200 batch totally time cost 1.426\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.183 | Acc: 92.256 | correct, total: (95415,103424)\n",
      "##########one 200 batch totally time cost 2.830\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.184 | Acc: 92.272 | correct, total: (189917,205824)\n",
      "##########one 200 batch totally time cost 4.257\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.183 | Acc: 92.280 | correct, total: (284428,308224)\n",
      "##########one 200 batch totally time cost 5.663\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.182 | Acc: 92.301 | correct, total: (379012,410624)\n",
      "##########one 200 batch totally time cost 7.063\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.183 | Acc: 92.244 | correct, total: (473235,513024)\n",
      "##########one 200 batch totally time cost 8.428\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.182 | Acc: 92.288 | correct, total: (567961,615424)\n",
      "##########one 200 batch totally time cost 9.857\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.182 | Acc: 92.319 | correct, total: (662690,717824)\n",
      "epochIndex 24 |time: 9 | Acc: 92.324 | correct, total: (667993,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.106\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.274 | Acc: 89.062 | correct, total: (912,1024)\n",
      "##########one 200 batch totally time cost 1.484\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.185 | Acc: 92.186 | correct, total: (95342,103424)\n",
      "##########one 200 batch totally time cost 2.932\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.182 | Acc: 92.313 | correct, total: (190002,205824)\n",
      "##########one 200 batch totally time cost 4.377\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.249 | correct, total: (284333,308224)\n",
      "##########one 200 batch totally time cost 6.194\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.272 | correct, total: (378891,410624)\n",
      "##########one 200 batch totally time cost 7.659\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.355 | correct, total: (473803,513024)\n",
      "##########one 200 batch totally time cost 9.047\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.331 | correct, total: (568228,615424)\n",
      "##########one 200 batch totally time cost 10.451\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.332 | correct, total: (662784,717824)\n",
      "epochIndex 25 |time: 10 | Acc: 92.324 | correct, total: (667997,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.192 | Acc: 90.723 | correct, total: (929,1024)\n",
      "##########one 200 batch totally time cost 1.487\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.188 | Acc: 92.090 | correct, total: (95243,103424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 2.902\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.183 | Acc: 92.262 | correct, total: (189898,205824)\n",
      "##########one 200 batch totally time cost 4.320\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.181 | Acc: 92.362 | correct, total: (284683,308224)\n",
      "##########one 200 batch totally time cost 5.749\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.388 | correct, total: (379366,410624)\n",
      "##########one 200 batch totally time cost 7.169\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.179 | Acc: 92.423 | correct, total: (474151,513024)\n",
      "##########one 200 batch totally time cost 8.592\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.179 | Acc: 92.440 | correct, total: (568895,615424)\n",
      "##########one 200 batch totally time cost 10.058\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.425 | correct, total: (663447,717824)\n",
      "epochIndex 26 |time: 10 | Acc: 92.425 | correct, total: (668726,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.060\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.174 | Acc: 91.797 | correct, total: (940,1024)\n",
      "##########one 200 batch totally time cost 1.483\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.173 | Acc: 92.623 | correct, total: (95794,103424)\n",
      "##########one 200 batch totally time cost 3.307\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.521 | correct, total: (190431,205824)\n",
      "##########one 200 batch totally time cost 4.764\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.490 | correct, total: (285077,308224)\n",
      "##########one 200 batch totally time cost 7.154\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.177 | Acc: 92.493 | correct, total: (379800,410624)\n",
      "##########one 200 batch totally time cost 8.579\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.179 | Acc: 92.428 | correct, total: (474177,513024)\n",
      "##########one 200 batch totally time cost 9.995\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.399 | correct, total: (568645,615424)\n",
      "##########one 200 batch totally time cost 11.346\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.430 | correct, total: (663487,717824)\n",
      "epochIndex 27 |time: 11 | Acc: 92.431 | correct, total: (668765,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.189 | Acc: 91.797 | correct, total: (940,1024)\n",
      "##########one 200 batch totally time cost 1.560\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.181 | Acc: 92.285 | correct, total: (95445,103424)\n",
      "##########one 200 batch totally time cost 2.923\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.180 | Acc: 92.435 | correct, total: (190253,205824)\n",
      "##########one 200 batch totally time cost 4.339\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.187 | Acc: 92.175 | correct, total: (284104,308224)\n",
      "##########one 200 batch totally time cost 5.756\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.186 | Acc: 92.204 | correct, total: (378611,410624)\n",
      "##########one 200 batch totally time cost 7.113\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.266 | correct, total: (473347,513024)\n",
      "##########one 200 batch totally time cost 8.574\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.184 | Acc: 92.262 | correct, total: (567803,615424)\n",
      "##########one 200 batch totally time cost 9.945\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.298 | correct, total: (662536,717824)\n",
      "epochIndex 28 |time: 10 | Acc: 92.295 | correct, total: (667787,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.160 | Acc: 93.066 | correct, total: (953,1024)\n",
      "##########one 200 batch totally time cost 1.471\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.188 | Acc: 92.071 | correct, total: (95224,103424)\n",
      "##########one 200 batch totally time cost 2.884\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.185 | Acc: 92.164 | correct, total: (189695,205824)\n",
      "##########one 200 batch totally time cost 4.289\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.183 | Acc: 92.233 | correct, total: (284284,308224)\n",
      "##########one 200 batch totally time cost 5.738\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.183 | Acc: 92.255 | correct, total: (378822,410624)\n",
      "##########one 200 batch totally time cost 7.134\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.183 | Acc: 92.243 | correct, total: (473230,513024)\n",
      "##########one 200 batch totally time cost 8.992\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.182 | Acc: 92.292 | correct, total: (567985,615424)\n",
      "##########one 200 batch totally time cost 10.428\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.182 | Acc: 92.311 | correct, total: (662632,717824)\n",
      "epochIndex 29 |time: 10 | Acc: 92.309 | correct, total: (667884,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.187 | Acc: 91.309 | correct, total: (935,1024)\n",
      "##########one 200 batch totally time cost 1.496\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.189 | Acc: 92.043 | correct, total: (95195,103424)\n",
      "##########one 200 batch totally time cost 3.393\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.186 | Acc: 92.173 | correct, total: (189715,205824)\n",
      "##########one 200 batch totally time cost 4.783\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.220 | correct, total: (284244,308224)\n",
      "##########one 200 batch totally time cost 6.696\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.187 | Acc: 92.136 | correct, total: (378333,410624)\n",
      "##########one 200 batch totally time cost 8.110\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.188 | Acc: 92.106 | correct, total: (472526,513024)\n",
      "##########one 200 batch totally time cost 9.974\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.187 | Acc: 92.140 | correct, total: (567051,615424)\n",
      "##########one 200 batch totally time cost 11.388\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.188 | Acc: 92.081 | correct, total: (660982,717824)\n",
      "epochIndex 30 |time: 11 | Acc: 92.078 | correct, total: (666216,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.218 | Acc: 90.234 | correct, total: (924,1024)\n",
      "##########one 200 batch totally time cost 1.424\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.182 | Acc: 92.256 | correct, total: (95415,103424)\n",
      "##########one 200 batch totally time cost 2.878\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.182 | Acc: 92.304 | correct, total: (189984,205824)\n",
      "##########one 200 batch totally time cost 4.257\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.229 | correct, total: (284273,308224)\n",
      "##########one 200 batch totally time cost 5.702\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.218 | correct, total: (378671,410624)\n",
      "##########one 200 batch totally time cost 7.163\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.243 | correct, total: (473227,513024)\n",
      "##########one 200 batch totally time cost 8.545\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.248 | correct, total: (567717,615424)\n",
      "##########one 200 batch totally time cost 10.957\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.184 | Acc: 92.244 | correct, total: (662153,717824)\n",
      "epochIndex 31 |time: 11 | Acc: 92.237 | correct, total: (667363,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.061\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.241 | Acc: 90.918 | correct, total: (931,1024)\n",
      "##########one 200 batch totally time cost 1.427\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.187 | Acc: 92.127 | correct, total: (95281,103424)\n",
      "##########one 200 batch totally time cost 2.845\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.187 | Acc: 92.170 | correct, total: (189707,205824)\n",
      "##########one 200 batch totally time cost 4.254\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.186 | Acc: 92.193 | correct, total: (284162,308224)\n",
      "##########one 200 batch totally time cost 5.668\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.187 | Acc: 92.139 | correct, total: (378344,410624)\n",
      "##########one 200 batch totally time cost 7.077\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.186 | Acc: 92.172 | correct, total: (472864,513024)\n",
      "##########one 200 batch totally time cost 8.435\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.185 | Acc: 92.209 | correct, total: (567475,615424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 9.841\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.185 | Acc: 92.221 | correct, total: (661986,717824)\n",
      "epochIndex 32 |time: 9 | Acc: 92.227 | correct, total: (667293,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.178 | Acc: 91.992 | correct, total: (942,1024)\n",
      "##########one 200 batch totally time cost 1.484\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.188 | Acc: 92.014 | correct, total: (95165,103424)\n",
      "##########one 200 batch totally time cost 2.902\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.185 | Acc: 92.195 | correct, total: (189759,205824)\n",
      "##########one 200 batch totally time cost 4.312\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.186 | Acc: 92.149 | correct, total: (284024,308224)\n",
      "##########one 200 batch totally time cost 5.665\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.187 | Acc: 92.113 | correct, total: (378238,410624)\n",
      "##########one 200 batch totally time cost 7.073\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.189 | Acc: 92.062 | correct, total: (472300,513024)\n",
      "##########one 200 batch totally time cost 8.547\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.189 | Acc: 92.092 | correct, total: (566755,615424)\n",
      "##########one 200 batch totally time cost 10.439\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.188 | Acc: 92.107 | correct, total: (661167,717824)\n",
      "epochIndex 33 |time: 10 | Acc: 92.112 | correct, total: (666457,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.191 | Acc: 91.699 | correct, total: (939,1024)\n",
      "##########one 200 batch totally time cost 1.473\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.185 | Acc: 92.102 | correct, total: (95256,103424)\n",
      "##########one 200 batch totally time cost 2.835\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.186 | Acc: 92.138 | correct, total: (189642,205824)\n",
      "##########one 200 batch totally time cost 4.287\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.186 | Acc: 92.164 | correct, total: (284071,308224)\n",
      "##########one 200 batch totally time cost 5.635\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.186 | Acc: 92.154 | correct, total: (378407,410624)\n",
      "##########one 200 batch totally time cost 7.048\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.230 | correct, total: (473161,513024)\n",
      "##########one 200 batch totally time cost 8.448\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.288 | correct, total: (567964,615424)\n",
      "##########one 200 batch totally time cost 9.914\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.184 | Acc: 92.242 | correct, total: (662137,717824)\n",
      "epochIndex 34 |time: 10 | Acc: 92.245 | correct, total: (667420,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.231 | Acc: 90.820 | correct, total: (930,1024)\n",
      "##########one 200 batch totally time cost 1.466\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.184 | Acc: 92.236 | correct, total: (95394,103424)\n",
      "##########one 200 batch totally time cost 2.894\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.185 | Acc: 92.257 | correct, total: (189887,205824)\n",
      "##########one 200 batch totally time cost 4.737\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.182 | Acc: 92.323 | correct, total: (284562,308224)\n",
      "##########one 200 batch totally time cost 6.087\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.234 | correct, total: (378735,410624)\n",
      "##########one 200 batch totally time cost 7.556\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.185 | Acc: 92.238 | correct, total: (473202,513024)\n",
      "##########one 200 batch totally time cost 8.914\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.276 | correct, total: (567890,615424)\n",
      "##########one 200 batch totally time cost 10.345\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.308 | correct, total: (662608,717824)\n",
      "epochIndex 35 |time: 10 | Acc: 92.305 | correct, total: (667854,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.057\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.259 | Acc: 89.941 | correct, total: (921,1024)\n",
      "##########one 200 batch totally time cost 1.515\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.186 | Acc: 92.236 | correct, total: (95394,103424)\n",
      "##########one 200 batch totally time cost 3.398\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.184 | Acc: 92.260 | correct, total: (189893,205824)\n",
      "##########one 200 batch totally time cost 4.798\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.185 | Acc: 92.238 | correct, total: (284299,308224)\n",
      "##########one 200 batch totally time cost 6.144\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.185 | Acc: 92.263 | correct, total: (378852,410624)\n",
      "##########one 200 batch totally time cost 7.557\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.186 | Acc: 92.206 | correct, total: (473038,513024)\n",
      "##########one 200 batch totally time cost 8.968\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.185 | Acc: 92.231 | correct, total: (567612,615424)\n",
      "##########one 200 batch totally time cost 10.375\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.184 | Acc: 92.271 | correct, total: (662341,717824)\n",
      "epochIndex 36 |time: 10 | Acc: 92.275 | correct, total: (667639,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.157 | Acc: 93.359 | correct, total: (956,1024)\n",
      "##########one 200 batch totally time cost 1.527\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.197 | Acc: 91.798 | correct, total: (94941,103424)\n",
      "##########one 200 batch totally time cost 2.912\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.187 | Acc: 92.186 | correct, total: (189741,205824)\n",
      "##########one 200 batch totally time cost 4.756\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.279 | correct, total: (284425,308224)\n",
      "##########one 200 batch totally time cost 6.159\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.182 | Acc: 92.329 | correct, total: (379125,410624)\n",
      "##########one 200 batch totally time cost 7.577\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.368 | correct, total: (473872,513024)\n",
      "##########one 200 batch totally time cost 9.097\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.181 | Acc: 92.366 | correct, total: (568441,615424)\n",
      "##########one 200 batch totally time cost 10.477\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.182 | Acc: 92.347 | correct, total: (662888,717824)\n",
      "epochIndex 37 |time: 10 | Acc: 92.347 | correct, total: (668158,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.200 | Acc: 92.188 | correct, total: (944,1024)\n",
      "##########one 200 batch totally time cost 2.015\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.177 | Acc: 92.483 | correct, total: (95650,103424)\n",
      "##########one 200 batch totally time cost 3.408\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.178 | Acc: 92.414 | correct, total: (190211,205824)\n",
      "##########one 200 batch totally time cost 5.289\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.181 | Acc: 92.281 | correct, total: (284431,308224)\n",
      "##########one 200 batch totally time cost 6.698\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.181 | Acc: 92.324 | correct, total: (379104,410624)\n",
      "##########one 200 batch totally time cost 8.056\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.310 | correct, total: (473570,513024)\n",
      "##########one 200 batch totally time cost 9.567\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.342 | correct, total: (568296,615424)\n",
      "##########one 200 batch totally time cost 10.944\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.180 | Acc: 92.370 | correct, total: (663053,717824)\n",
      "epochIndex 38 |time: 11 | Acc: 92.370 | correct, total: (668329,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.171 | Acc: 92.090 | correct, total: (943,1024)\n",
      "##########one 200 batch totally time cost 1.507\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.186 | Acc: 92.109 | correct, total: (95263,103424)\n",
      "##########one 200 batch totally time cost 2.933\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.185 | Acc: 92.192 | correct, total: (189754,205824)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 4.831\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.259 | correct, total: (284363,308224)\n",
      "##########one 200 batch totally time cost 6.255\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.230 | correct, total: (378719,410624)\n",
      "##########one 200 batch totally time cost 7.609\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.185 | Acc: 92.211 | correct, total: (473066,513024)\n",
      "##########one 200 batch totally time cost 9.014\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.185 | Acc: 92.213 | correct, total: (567501,615424)\n",
      "##########one 200 batch totally time cost 10.927\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.184 | Acc: 92.231 | correct, total: (662059,717824)\n",
      "epochIndex 39 |time: 11 | Acc: 92.231 | correct, total: (667324,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.211 | Acc: 91.309 | correct, total: (935,1024)\n",
      "##########one 200 batch totally time cost 2.117\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.178 | Acc: 92.443 | correct, total: (95608,103424)\n",
      "##########one 200 batch totally time cost 3.980\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.180 | Acc: 92.376 | correct, total: (190131,205824)\n",
      "##########one 200 batch totally time cost 5.339\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.182 | Acc: 92.319 | correct, total: (284549,308224)\n",
      "##########one 200 batch totally time cost 6.750\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.266 | correct, total: (378866,410624)\n",
      "##########one 200 batch totally time cost 8.166\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.263 | correct, total: (473329,513024)\n",
      "##########one 200 batch totally time cost 9.581\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.185 | Acc: 92.213 | correct, total: (567502,615424)\n",
      "##########one 200 batch totally time cost 10.995\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.266 | correct, total: (662310,717824)\n",
      "epochIndex 40 |time: 11 | Acc: 92.262 | correct, total: (667542,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.061\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.216 | Acc: 90.332 | correct, total: (925,1024)\n",
      "##########one 200 batch totally time cost 1.449\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.185 | Acc: 92.194 | correct, total: (95351,103424)\n",
      "##########one 200 batch totally time cost 3.373\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.184 | Acc: 92.280 | correct, total: (189934,205824)\n",
      "##########one 200 batch totally time cost 4.789\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.185 | Acc: 92.203 | correct, total: (284191,308224)\n",
      "##########one 200 batch totally time cost 7.064\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.184 | Acc: 92.238 | correct, total: (378751,410624)\n",
      "##########one 200 batch totally time cost 8.484\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.223 | correct, total: (473124,513024)\n",
      "##########one 200 batch totally time cost 9.835\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.183 | Acc: 92.264 | correct, total: (567816,615424)\n",
      "##########one 200 batch totally time cost 11.296\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.258 | correct, total: (662249,717824)\n",
      "epochIndex 41 |time: 11 | Acc: 92.261 | correct, total: (667541,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.180 | Acc: 91.602 | correct, total: (938,1024)\n",
      "##########one 200 batch totally time cost 1.440\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.174 | Acc: 92.610 | correct, total: (95781,103424)\n",
      "##########one 200 batch totally time cost 3.338\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.179 | Acc: 92.428 | correct, total: (190239,205824)\n",
      "##########one 200 batch totally time cost 4.755\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.399 | correct, total: (284795,308224)\n",
      "##########one 200 batch totally time cost 6.183\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.179 | Acc: 92.432 | correct, total: (379547,410624)\n",
      "##########one 200 batch totally time cost 7.637\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.180 | Acc: 92.394 | correct, total: (474003,513024)\n",
      "##########one 200 batch totally time cost 9.470\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.181 | Acc: 92.356 | correct, total: (568383,615424)\n",
      "##########one 200 batch totally time cost 10.886\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.181 | Acc: 92.365 | correct, total: (663017,717824)\n",
      "epochIndex 42 |time: 10 | Acc: 92.368 | correct, total: (668309,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.175 | Acc: 92.676 | correct, total: (949,1024)\n",
      "##########one 200 batch totally time cost 1.489\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.182 | Acc: 92.385 | correct, total: (95548,103424)\n",
      "##########one 200 batch totally time cost 2.994\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.180 | Acc: 92.422 | correct, total: (190226,205824)\n",
      "##########one 200 batch totally time cost 4.410\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.179 | Acc: 92.435 | correct, total: (284908,308224)\n",
      "##########one 200 batch totally time cost 5.776\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.179 | Acc: 92.406 | correct, total: (379442,410624)\n",
      "##########one 200 batch totally time cost 7.194\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.353 | correct, total: (473795,513024)\n",
      "##########one 200 batch totally time cost 8.632\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.181 | Acc: 92.365 | correct, total: (568438,615424)\n",
      "##########one 200 batch totally time cost 10.075\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.180 | Acc: 92.422 | correct, total: (663426,717824)\n",
      "epochIndex 43 |time: 10 | Acc: 92.422 | correct, total: (668700,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.060\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.229 | Acc: 91.504 | correct, total: (937,1024)\n",
      "##########one 200 batch totally time cost 1.911\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.705 | correct, total: (95879,103424)\n",
      "##########one 200 batch totally time cost 3.355\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.621 | correct, total: (190636,205824)\n",
      "##########one 200 batch totally time cost 4.839\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.592 | correct, total: (285392,308224)\n",
      "##########one 200 batch totally time cost 6.679\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.526 | correct, total: (379935,410624)\n",
      "##########one 200 batch totally time cost 8.543\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.482 | correct, total: (474453,513024)\n",
      "##########one 200 batch totally time cost 9.983\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.178 | Acc: 92.467 | correct, total: (569064,615424)\n",
      "##########one 200 batch totally time cost 11.355\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.178 | Acc: 92.481 | correct, total: (663853,717824)\n",
      "epochIndex 44 |time: 11 | Acc: 92.476 | correct, total: (669090,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.187 | Acc: 92.578 | correct, total: (948,1024)\n",
      "##########one 200 batch totally time cost 1.463\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.422 | correct, total: (95587,103424)\n",
      "##########one 200 batch totally time cost 2.822\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.178 | Acc: 92.470 | correct, total: (190326,205824)\n",
      "##########one 200 batch totally time cost 4.245\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.177 | Acc: 92.508 | correct, total: (285131,308224)\n",
      "##########one 200 batch totally time cost 5.655\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.391 | correct, total: (379381,410624)\n",
      "##########one 200 batch totally time cost 7.059\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.358 | correct, total: (473818,513024)\n",
      "##########one 200 batch totally time cost 8.468\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.184 | Acc: 92.279 | correct, total: (567905,615424)\n",
      "##########one 200 batch totally time cost 9.837\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.183 | Acc: 92.282 | correct, total: (662425,717824)\n",
      "epochIndex 45 |time: 9 | Acc: 92.280 | correct, total: (667672,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.211 | Acc: 91.406 | correct, total: (936,1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 1.497\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.188 | Acc: 92.050 | correct, total: (95202,103424)\n",
      "##########one 200 batch totally time cost 2.917\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.189 | Acc: 92.025 | correct, total: (189410,205824)\n",
      "##########one 200 batch totally time cost 4.342\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.187 | Acc: 92.100 | correct, total: (283873,308224)\n",
      "##########one 200 batch totally time cost 5.803\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.189 | Acc: 92.053 | correct, total: (377991,410624)\n",
      "##########one 200 batch totally time cost 7.206\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.188 | Acc: 92.094 | correct, total: (472464,513024)\n",
      "##########one 200 batch totally time cost 9.533\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.187 | Acc: 92.156 | correct, total: (567148,615424)\n",
      "##########one 200 batch totally time cost 10.941\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.184 | Acc: 92.268 | correct, total: (662321,717824)\n",
      "epochIndex 46 |time: 11 | Acc: 92.269 | correct, total: (667597,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.215 | Acc: 89.941 | correct, total: (921,1024)\n",
      "##########one 200 batch totally time cost 1.462\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.176 | Acc: 92.529 | correct, total: (95697,103424)\n",
      "##########one 200 batch totally time cost 2.906\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.519 | correct, total: (190427,205824)\n",
      "##########one 200 batch totally time cost 4.267\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.177 | Acc: 92.502 | correct, total: (285114,308224)\n",
      "##########one 200 batch totally time cost 5.734\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.177 | Acc: 92.512 | correct, total: (379878,410624)\n",
      "##########one 200 batch totally time cost 7.087\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.177 | Acc: 92.517 | correct, total: (474633,513024)\n",
      "##########one 200 batch totally time cost 8.512\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.178 | Acc: 92.488 | correct, total: (569195,615424)\n",
      "##########one 200 batch totally time cost 9.956\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.177 | Acc: 92.519 | correct, total: (664127,717824)\n",
      "epochIndex 47 |time: 10 | Acc: 92.519 | correct, total: (669403,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.198 | Acc: 90.820 | correct, total: (930,1024)\n",
      "##########one 200 batch totally time cost 1.930\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.178 | Acc: 92.486 | correct, total: (95653,103424)\n",
      "##########one 200 batch totally time cost 3.361\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.179 | Acc: 92.460 | correct, total: (190305,205824)\n",
      "##########one 200 batch totally time cost 4.724\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.436 | correct, total: (284911,308224)\n",
      "##########one 200 batch totally time cost 6.152\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.432 | correct, total: (379546,410624)\n",
      "##########one 200 batch totally time cost 7.561\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.184 | Acc: 92.275 | correct, total: (473392,513024)\n",
      "##########one 200 batch totally time cost 9.012\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.185 | Acc: 92.253 | correct, total: (567746,615424)\n",
      "##########one 200 batch totally time cost 10.938\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.186 | Acc: 92.186 | correct, total: (661735,717824)\n",
      "epochIndex 48 |time: 11 | Acc: 92.187 | correct, total: (667004,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.178 | Acc: 92.480 | correct, total: (947,1024)\n",
      "##########one 200 batch totally time cost 1.475\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.183 | Acc: 92.363 | correct, total: (95526,103424)\n",
      "##########one 200 batch totally time cost 2.935\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.182 | Acc: 92.337 | correct, total: (190052,205824)\n",
      "##########one 200 batch totally time cost 4.884\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.413 | correct, total: (284840,308224)\n",
      "##########one 200 batch totally time cost 6.304\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.179 | Acc: 92.428 | correct, total: (379533,410624)\n",
      "##########one 200 batch totally time cost 7.766\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.180 | Acc: 92.409 | correct, total: (474080,513024)\n",
      "##########one 200 batch totally time cost 9.128\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.181 | Acc: 92.383 | correct, total: (568550,615424)\n",
      "##########one 200 batch totally time cost 10.581\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.180 | Acc: 92.400 | correct, total: (663267,717824)\n",
      "epochIndex 49 |time: 10 | Acc: 92.401 | correct, total: (668552,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.066\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.168 | Acc: 93.164 | correct, total: (954,1024)\n",
      "##########one 200 batch totally time cost 1.481\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.183 | Acc: 92.185 | correct, total: (95341,103424)\n",
      "##########one 200 batch totally time cost 2.901\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.181 | Acc: 92.360 | correct, total: (190100,205824)\n",
      "##########one 200 batch totally time cost 4.311\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.181 | Acc: 92.325 | correct, total: (284567,308224)\n",
      "##########one 200 batch totally time cost 5.687\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.181 | Acc: 92.335 | correct, total: (379151,410624)\n",
      "##########one 200 batch totally time cost 7.166\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.180 | Acc: 92.374 | correct, total: (473903,513024)\n",
      "##########one 200 batch totally time cost 8.521\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.179 | Acc: 92.408 | correct, total: (568700,615424)\n",
      "##########one 200 batch totally time cost 10.398\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.402 | correct, total: (663282,717824)\n",
      "epochIndex 50 |time: 10 | Acc: 92.396 | correct, total: (668515,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.253 | Acc: 90.039 | correct, total: (922,1024)\n",
      "##########one 200 batch totally time cost 1.522\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.187 | Acc: 92.019 | correct, total: (95170,103424)\n",
      "##########one 200 batch totally time cost 2.946\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.181 | Acc: 92.302 | correct, total: (189979,205824)\n",
      "##########one 200 batch totally time cost 4.782\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.364 | correct, total: (284689,308224)\n",
      "##########one 200 batch totally time cost 6.140\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.354 | correct, total: (379229,410624)\n",
      "##########one 200 batch totally time cost 7.558\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.444 | correct, total: (474258,513024)\n",
      "##########one 200 batch totally time cost 8.986\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.495 | correct, total: (569235,615424)\n",
      "##########one 200 batch totally time cost 10.873\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.529 | correct, total: (664198,717824)\n",
      "epochIndex 51 |time: 10 | Acc: 92.524 | correct, total: (669439,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.204 | Acc: 91.602 | correct, total: (938,1024)\n",
      "##########one 200 batch totally time cost 1.490\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.403 | correct, total: (95567,103424)\n",
      "##########one 200 batch totally time cost 2.838\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.178 | Acc: 92.474 | correct, total: (190334,205824)\n",
      "##########one 200 batch totally time cost 4.238\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.177 | Acc: 92.496 | correct, total: (285094,308224)\n",
      "##########one 200 batch totally time cost 5.651\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.177 | Acc: 92.480 | correct, total: (379747,410624)\n",
      "##########one 200 batch totally time cost 7.051\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.456 | correct, total: (474323,513024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 8.483\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.490 | correct, total: (569204,615424)\n",
      "##########one 200 batch totally time cost 9.867\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.178 | Acc: 92.469 | correct, total: (663762,717824)\n",
      "epochIndex 52 |time: 9 | Acc: 92.472 | correct, total: (669062,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.063\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.192 | Acc: 91.699 | correct, total: (939,1024)\n",
      "##########one 200 batch totally time cost 2.024\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.503 | correct, total: (95670,103424)\n",
      "##########one 200 batch totally time cost 3.367\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.175 | Acc: 92.601 | correct, total: (190596,205824)\n",
      "##########one 200 batch totally time cost 4.766\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.176 | Acc: 92.581 | correct, total: (285358,308224)\n",
      "##########one 200 batch totally time cost 6.183\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.177 | Acc: 92.545 | correct, total: (380013,410624)\n",
      "##########one 200 batch totally time cost 7.541\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.577 | correct, total: (474944,513024)\n",
      "##########one 200 batch totally time cost 9.018\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.583 | correct, total: (569780,615424)\n",
      "##########one 200 batch totally time cost 10.381\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.579 | correct, total: (664553,717824)\n",
      "epochIndex 53 |time: 10 | Acc: 92.582 | correct, total: (669858,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.154 | Acc: 93.555 | correct, total: (958,1024)\n",
      "##########one 200 batch totally time cost 1.477\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.655 | correct, total: (95828,103424)\n",
      "##########one 200 batch totally time cost 2.883\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.173 | Acc: 92.664 | correct, total: (190725,205824)\n",
      "##########one 200 batch totally time cost 4.313\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.579 | correct, total: (285352,308224)\n",
      "##########one 200 batch totally time cost 6.209\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.558 | correct, total: (380065,410624)\n",
      "##########one 200 batch totally time cost 7.562\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.549 | correct, total: (474797,513024)\n",
      "##########one 200 batch totally time cost 9.020\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.551 | correct, total: (569583,615424)\n",
      "##########one 200 batch totally time cost 10.453\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.553 | correct, total: (664370,717824)\n",
      "epochIndex 54 |time: 10 | Acc: 92.557 | correct, total: (669681,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.161 | Acc: 93.750 | correct, total: (960,1024)\n",
      "##########one 200 batch totally time cost 1.498\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.177 | Acc: 92.484 | correct, total: (95651,103424)\n",
      "##########one 200 batch totally time cost 3.367\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.517 | correct, total: (190422,205824)\n",
      "##########one 200 batch totally time cost 4.780\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.602 | correct, total: (285423,308224)\n",
      "##########one 200 batch totally time cost 6.720\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.576 | correct, total: (380141,410624)\n",
      "##########one 200 batch totally time cost 8.122\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.564 | correct, total: (474875,513024)\n",
      "##########one 200 batch totally time cost 9.539\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.569 | correct, total: (569690,615424)\n",
      "##########one 200 batch totally time cost 10.981\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.177 | Acc: 92.541 | correct, total: (664284,717824)\n",
      "epochIndex 55 |time: 11 | Acc: 92.542 | correct, total: (669572,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.162 | Acc: 93.262 | correct, total: (955,1024)\n",
      "##########one 200 batch totally time cost 1.872\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.170 | Acc: 92.858 | correct, total: (96037,103424)\n",
      "##########one 200 batch totally time cost 3.378\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.643 | correct, total: (190681,205824)\n",
      "##########one 200 batch totally time cost 4.725\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.653 | correct, total: (285578,308224)\n",
      "##########one 200 batch totally time cost 6.139\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.610 | correct, total: (380280,410624)\n",
      "##########one 200 batch totally time cost 7.588\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.583 | correct, total: (474975,513024)\n",
      "##########one 200 batch totally time cost 9.403\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.583 | correct, total: (569777,615424)\n",
      "##########one 200 batch totally time cost 10.864\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.600 | correct, total: (664705,717824)\n",
      "epochIndex 56 |time: 10 | Acc: 92.606 | correct, total: (670033,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.152 | Acc: 93.652 | correct, total: (959,1024)\n",
      "##########one 200 batch totally time cost 1.417\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.643 | correct, total: (95815,103424)\n",
      "##########one 200 batch totally time cost 2.843\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.563 | correct, total: (190516,205824)\n",
      "##########one 200 batch totally time cost 4.266\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.177 | Acc: 92.539 | correct, total: (285227,308224)\n",
      "##########one 200 batch totally time cost 5.684\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.551 | correct, total: (380038,410624)\n",
      "##########one 200 batch totally time cost 7.105\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.590 | correct, total: (475010,513024)\n",
      "##########one 200 batch totally time cost 8.451\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.579 | correct, total: (569751,615424)\n",
      "##########one 200 batch totally time cost 9.860\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.583 | correct, total: (664586,717824)\n",
      "epochIndex 57 |time: 9 | Acc: 92.586 | correct, total: (669889,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.066\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.236 | Acc: 89.160 | correct, total: (913,1024)\n",
      "##########one 200 batch totally time cost 1.481\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.774 | correct, total: (95951,103424)\n",
      "##########one 200 batch totally time cost 2.922\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.663 | correct, total: (190723,205824)\n",
      "##########one 200 batch totally time cost 4.344\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.612 | correct, total: (285452,308224)\n",
      "##########one 200 batch totally time cost 5.709\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.599 | correct, total: (380233,410624)\n",
      "##########one 200 batch totally time cost 7.154\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.587 | correct, total: (474991,513024)\n",
      "##########one 200 batch totally time cost 8.599\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.586 | correct, total: (569799,615424)\n",
      "##########one 200 batch totally time cost 10.502\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.589 | correct, total: (664627,717824)\n",
      "epochIndex 58 |time: 10 | Acc: 92.595 | correct, total: (669951,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.174 | Acc: 92.188 | correct, total: (944,1024)\n",
      "##########one 200 batch totally time cost 1.481\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.173 | Acc: 92.691 | correct, total: (95865,103424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 2.876\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.624 | correct, total: (190643,205824)\n",
      "##########one 200 batch totally time cost 4.332\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.626 | correct, total: (285497,308224)\n",
      "##########one 200 batch totally time cost 5.701\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.598 | correct, total: (380229,410624)\n",
      "##########one 200 batch totally time cost 7.125\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.174 | Acc: 92.614 | correct, total: (475134,513024)\n",
      "##########one 200 batch totally time cost 8.537\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.585 | correct, total: (569793,615424)\n",
      "##########one 200 batch totally time cost 9.928\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.575 | correct, total: (664524,717824)\n",
      "epochIndex 59 |time: 10 | Acc: 92.575 | correct, total: (669811,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.110\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.182 | Acc: 92.285 | correct, total: (945,1024)\n",
      "##########one 200 batch totally time cost 1.530\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.177 | Acc: 92.493 | correct, total: (95660,103424)\n",
      "##########one 200 batch totally time cost 3.405\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.491 | correct, total: (190368,205824)\n",
      "##########one 200 batch totally time cost 4.827\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.604 | correct, total: (285429,308224)\n",
      "##########one 200 batch totally time cost 6.262\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.592 | correct, total: (380207,410624)\n",
      "##########one 200 batch totally time cost 7.676\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.579 | correct, total: (474951,513024)\n",
      "##########one 200 batch totally time cost 9.190\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.583 | correct, total: (569779,615424)\n",
      "##########one 200 batch totally time cost 10.570\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.626 | correct, total: (664895,717824)\n",
      "epochIndex 60 |time: 10 | Acc: 92.622 | correct, total: (670152,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.212 | Acc: 91.406 | correct, total: (936,1024)\n",
      "##########one 200 batch totally time cost 1.527\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.171 | Acc: 92.758 | correct, total: (95934,103424)\n",
      "##########one 200 batch totally time cost 3.703\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.171 | Acc: 92.774 | correct, total: (190951,205824)\n",
      "##########one 200 batch totally time cost 5.128\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.171 | Acc: 92.771 | correct, total: (285944,308224)\n",
      "##########one 200 batch totally time cost 6.536\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.174 | Acc: 92.665 | correct, total: (380504,410624)\n",
      "##########one 200 batch totally time cost 7.898\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.640 | correct, total: (475265,513024)\n",
      "##########one 200 batch totally time cost 9.314\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.636 | correct, total: (570107,615424)\n",
      "##########one 200 batch totally time cost 10.750\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.642 | correct, total: (665010,717824)\n",
      "epochIndex 61 |time: 10 | Acc: 92.643 | correct, total: (670302,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.213 | Acc: 91.211 | correct, total: (934,1024)\n",
      "##########one 200 batch totally time cost 1.465\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.183 | Acc: 92.319 | correct, total: (95480,103424)\n",
      "##########one 200 batch totally time cost 2.871\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.179 | Acc: 92.473 | correct, total: (190331,205824)\n",
      "##########one 200 batch totally time cost 4.277\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.511 | correct, total: (285142,308224)\n",
      "##########one 200 batch totally time cost 5.774\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.504 | correct, total: (379842,410624)\n",
      "##########one 200 batch totally time cost 7.612\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.179 | Acc: 92.486 | correct, total: (474475,513024)\n",
      "##########one 200 batch totally time cost 9.029\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.179 | Acc: 92.474 | correct, total: (569105,615424)\n",
      "##########one 200 batch totally time cost 10.446\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.474 | correct, total: (663801,717824)\n",
      "epochIndex 62 |time: 10 | Acc: 92.477 | correct, total: (669102,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.143 | Acc: 94.043 | correct, total: (963,1024)\n",
      "##########one 200 batch totally time cost 1.502\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.729 | correct, total: (95904,103424)\n",
      "##########one 200 batch totally time cost 2.944\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.175 | Acc: 92.591 | correct, total: (190575,205824)\n",
      "##########one 200 batch totally time cost 4.799\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.179 | Acc: 92.459 | correct, total: (284981,308224)\n",
      "##########one 200 batch totally time cost 6.668\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.486 | correct, total: (379768,410624)\n",
      "##########one 200 batch totally time cost 8.083\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.579 | correct, total: (474953,513024)\n",
      "##########one 200 batch totally time cost 9.498\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.556 | correct, total: (569614,615424)\n",
      "##########one 200 batch totally time cost 10.907\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.579 | correct, total: (664552,717824)\n",
      "epochIndex 63 |time: 10 | Acc: 92.576 | correct, total: (669815,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.057\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.151 | Acc: 93.848 | correct, total: (961,1024)\n",
      "##########one 200 batch totally time cost 1.398\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.173 | Acc: 92.627 | correct, total: (95799,103424)\n",
      "##########one 200 batch totally time cost 2.853\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.178 | Acc: 92.550 | correct, total: (190491,205824)\n",
      "##########one 200 batch totally time cost 4.255\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.558 | correct, total: (285285,308224)\n",
      "##########one 200 batch totally time cost 5.660\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.177 | Acc: 92.578 | correct, total: (380148,410624)\n",
      "##########one 200 batch totally time cost 7.071\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.601 | correct, total: (475065,513024)\n",
      "##########one 200 batch totally time cost 8.437\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.580 | correct, total: (569761,615424)\n",
      "##########one 200 batch totally time cost 9.870\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.602 | correct, total: (664716,717824)\n",
      "epochIndex 64 |time: 9 | Acc: 92.603 | correct, total: (670012,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.224 | Acc: 91.406 | correct, total: (936,1024)\n",
      "##########one 200 batch totally time cost 1.468\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.178 | Acc: 92.480 | correct, total: (95646,103424)\n",
      "##########one 200 batch totally time cost 3.364\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.510 | correct, total: (190408,205824)\n",
      "##########one 200 batch totally time cost 4.796\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.615 | correct, total: (285463,308224)\n",
      "##########one 200 batch totally time cost 6.168\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.618 | correct, total: (380313,410624)\n",
      "##########one 200 batch totally time cost 8.025\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.615 | correct, total: (475135,513024)\n",
      "##########one 200 batch totally time cost 9.392\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.620 | correct, total: (570004,615424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 10.910\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.618 | correct, total: (664835,717824)\n",
      "epochIndex 65 |time: 10 | Acc: 92.617 | correct, total: (670115,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.289 | Acc: 89.941 | correct, total: (921,1024)\n",
      "##########one 200 batch totally time cost 1.469\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.180 | Acc: 92.480 | correct, total: (95647,103424)\n",
      "##########one 200 batch totally time cost 2.913\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.179 | Acc: 92.496 | correct, total: (190378,205824)\n",
      "##########one 200 batch totally time cost 4.382\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.500 | correct, total: (285107,308224)\n",
      "##########one 200 batch totally time cost 6.214\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.450 | correct, total: (379620,410624)\n",
      "##########one 200 batch totally time cost 7.621\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.522 | correct, total: (474658,513024)\n",
      "##########one 200 batch totally time cost 9.070\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.567 | correct, total: (569677,615424)\n",
      "##########one 200 batch totally time cost 10.547\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.583 | correct, total: (664583,717824)\n",
      "epochIndex 66 |time: 10 | Acc: 92.582 | correct, total: (669860,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.204 | Acc: 91.895 | correct, total: (941,1024)\n",
      "##########one 200 batch totally time cost 1.866\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.176 | Acc: 92.543 | correct, total: (95712,103424)\n",
      "##########one 200 batch totally time cost 3.227\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.532 | correct, total: (190453,205824)\n",
      "##########one 200 batch totally time cost 4.641\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.591 | correct, total: (285387,308224)\n",
      "##########one 200 batch totally time cost 6.100\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.579 | correct, total: (380153,410624)\n",
      "##########one 200 batch totally time cost 7.522\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.579 | correct, total: (474952,513024)\n",
      "##########one 200 batch totally time cost 8.931\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.606 | correct, total: (569919,615424)\n",
      "##########one 200 batch totally time cost 10.744\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.608 | correct, total: (664763,717824)\n",
      "epochIndex 67 |time: 10 | Acc: 92.608 | correct, total: (670045,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.193 | Acc: 92.676 | correct, total: (949,1024)\n",
      "##########one 200 batch totally time cost 1.493\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.480 | correct, total: (95647,103424)\n",
      "##########one 200 batch totally time cost 2.899\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.178 | Acc: 92.463 | correct, total: (190311,205824)\n",
      "##########one 200 batch totally time cost 4.296\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.177 | Acc: 92.524 | correct, total: (285180,308224)\n",
      "##########one 200 batch totally time cost 5.708\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.548 | correct, total: (380026,410624)\n",
      "##########one 200 batch totally time cost 7.083\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.177 | Acc: 92.520 | correct, total: (474649,513024)\n",
      "##########one 200 batch totally time cost 8.562\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.547 | correct, total: (569554,615424)\n",
      "##########one 200 batch totally time cost 9.933\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.566 | correct, total: (664458,717824)\n",
      "epochIndex 68 |time: 10 | Acc: 92.573 | correct, total: (669798,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.194 | Acc: 91.602 | correct, total: (938,1024)\n",
      "##########one 200 batch totally time cost 1.492\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.755 | correct, total: (95931,103424)\n",
      "##########one 200 batch totally time cost 3.356\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.171 | Acc: 92.730 | correct, total: (190861,205824)\n",
      "##########one 200 batch totally time cost 4.762\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.173 | Acc: 92.690 | correct, total: (285694,308224)\n",
      "##########one 200 batch totally time cost 6.167\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.173 | Acc: 92.704 | correct, total: (380666,410624)\n",
      "##########one 200 batch totally time cost 7.517\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.173 | Acc: 92.691 | correct, total: (475528,513024)\n",
      "##########one 200 batch totally time cost 8.927\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.685 | correct, total: (570404,615424)\n",
      "##########one 200 batch totally time cost 10.372\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.173 | Acc: 92.675 | correct, total: (665243,717824)\n",
      "epochIndex 69 |time: 10 | Acc: 92.674 | correct, total: (670524,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.192 | Acc: 91.211 | correct, total: (934,1024)\n",
      "##########one 200 batch totally time cost 1.470\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.169 | Acc: 92.713 | correct, total: (95887,103424)\n",
      "##########one 200 batch totally time cost 3.320\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.168 | Acc: 92.807 | correct, total: (191019,205824)\n",
      "##########one 200 batch totally time cost 4.683\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.171 | Acc: 92.740 | correct, total: (285846,308224)\n",
      "##########one 200 batch totally time cost 6.110\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.172 | Acc: 92.718 | correct, total: (380724,410624)\n",
      "##########one 200 batch totally time cost 7.508\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.172 | Acc: 92.706 | correct, total: (475604,513024)\n",
      "##########one 200 batch totally time cost 8.908\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.691 | correct, total: (570441,615424)\n",
      "##########one 200 batch totally time cost 10.350\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.173 | Acc: 92.686 | correct, total: (665325,717824)\n",
      "epochIndex 70 |time: 10 | Acc: 92.688 | correct, total: (670626,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.219 | Acc: 91.895 | correct, total: (941,1024)\n",
      "##########one 200 batch totally time cost 1.459\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.727 | correct, total: (95902,103424)\n",
      "##########one 200 batch totally time cost 2.889\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.172 | Acc: 92.720 | correct, total: (190839,205824)\n",
      "##########one 200 batch totally time cost 4.292\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.173 | Acc: 92.683 | correct, total: (285671,308224)\n",
      "##########one 200 batch totally time cost 5.712\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.605 | correct, total: (380257,410624)\n",
      "##########one 200 batch totally time cost 7.210\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.628 | correct, total: (475204,513024)\n",
      "##########one 200 batch totally time cost 8.588\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.637 | correct, total: (570108,615424)\n",
      "##########one 200 batch totally time cost 10.056\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.647 | correct, total: (665039,717824)\n",
      "epochIndex 71 |time: 10 | Acc: 92.646 | correct, total: (670322,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.167 | Acc: 92.090 | correct, total: (943,1024)\n",
      "##########one 200 batch totally time cost 1.452\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.171 | Acc: 92.783 | correct, total: (95960,103424)\n",
      "##########one 200 batch totally time cost 2.882\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.655 | correct, total: (190707,205824)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 4.294\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.587 | correct, total: (285375,308224)\n",
      "##########one 200 batch totally time cost 5.716\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.578 | correct, total: (380149,410624)\n",
      "##########one 200 batch totally time cost 7.111\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.597 | correct, total: (475047,513024)\n",
      "##########one 200 batch totally time cost 8.516\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.609 | correct, total: (569938,615424)\n",
      "##########one 200 batch totally time cost 9.926\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.608 | correct, total: (664760,717824)\n",
      "epochIndex 72 |time: 10 | Acc: 92.608 | correct, total: (670046,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.192 | Acc: 92.090 | correct, total: (943,1024)\n",
      "##########one 200 batch totally time cost 1.494\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.169 | Acc: 92.828 | correct, total: (96006,103424)\n",
      "##########one 200 batch totally time cost 2.900\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.605 | correct, total: (190604,205824)\n",
      "##########one 200 batch totally time cost 4.787\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.173 | Acc: 92.675 | correct, total: (285646,308224)\n",
      "##########one 200 batch totally time cost 6.153\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.172 | Acc: 92.711 | correct, total: (380694,410624)\n",
      "##########one 200 batch totally time cost 7.563\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.171 | Acc: 92.740 | correct, total: (475777,513024)\n",
      "##########one 200 batch totally time cost 9.024\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.685 | correct, total: (570405,615424)\n",
      "##########one 200 batch totally time cost 10.523\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.672 | correct, total: (665219,717824)\n",
      "epochIndex 73 |time: 10 | Acc: 92.666 | correct, total: (670468,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.189 | Acc: 92.676 | correct, total: (949,1024)\n",
      "##########one 200 batch totally time cost 2.373\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.174 | Acc: 92.747 | correct, total: (95923,103424)\n",
      "##########one 200 batch totally time cost 3.722\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.172 | Acc: 92.736 | correct, total: (190872,205824)\n",
      "##########one 200 batch totally time cost 5.186\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.645 | correct, total: (285555,308224)\n",
      "##########one 200 batch totally time cost 6.553\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.173 | Acc: 92.683 | correct, total: (380579,410624)\n",
      "##########one 200 batch totally time cost 7.967\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.172 | Acc: 92.724 | correct, total: (475697,513024)\n",
      "##########one 200 batch totally time cost 9.402\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.695 | correct, total: (570466,615424)\n",
      "##########one 200 batch totally time cost 10.758\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.172 | Acc: 92.705 | correct, total: (665457,717824)\n",
      "epochIndex 74 |time: 10 | Acc: 92.711 | correct, total: (670793,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.146 | Acc: 93.848 | correct, total: (961,1024)\n",
      "##########one 200 batch totally time cost 1.528\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.174 | Acc: 92.703 | correct, total: (95877,103424)\n",
      "##########one 200 batch totally time cost 2.881\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.696 | correct, total: (190791,205824)\n",
      "##########one 200 batch totally time cost 4.330\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.683 | correct, total: (285671,308224)\n",
      "##########one 200 batch totally time cost 5.740\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.174 | Acc: 92.663 | correct, total: (380496,410624)\n",
      "##########one 200 batch totally time cost 7.168\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.174 | Acc: 92.662 | correct, total: (475379,513024)\n",
      "##########one 200 batch totally time cost 9.043\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.676 | correct, total: (570348,615424)\n",
      "##########one 200 batch totally time cost 10.397\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.656 | correct, total: (665108,717824)\n",
      "epochIndex 75 |time: 10 | Acc: 92.659 | correct, total: (670420,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.156 | Acc: 93.848 | correct, total: (961,1024)\n",
      "##########one 200 batch totally time cost 1.473\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.502 | correct, total: (95669,103424)\n",
      "##########one 200 batch totally time cost 2.894\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.680 | correct, total: (190757,205824)\n",
      "##########one 200 batch totally time cost 4.303\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.176 | Acc: 92.588 | correct, total: (285377,308224)\n",
      "##########one 200 batch totally time cost 5.696\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.601 | correct, total: (380241,410624)\n",
      "##########one 200 batch totally time cost 7.045\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.647 | correct, total: (475302,513024)\n",
      "##########one 200 batch totally time cost 8.455\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.174 | Acc: 92.687 | correct, total: (570418,615424)\n",
      "##########one 200 batch totally time cost 9.901\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.677 | correct, total: (665256,717824)\n",
      "epochIndex 76 |time: 9 | Acc: 92.679 | correct, total: (670564,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.168 | Acc: 91.895 | correct, total: (941,1024)\n",
      "##########one 200 batch totally time cost 1.951\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.626 | correct, total: (95798,103424)\n",
      "##########one 200 batch totally time cost 3.362\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.172 | Acc: 92.681 | correct, total: (190759,205824)\n",
      "##########one 200 batch totally time cost 4.847\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.604 | correct, total: (285428,308224)\n",
      "##########one 200 batch totally time cost 6.807\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.174 | Acc: 92.633 | correct, total: (380374,410624)\n",
      "##########one 200 batch totally time cost 8.634\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.173 | Acc: 92.673 | correct, total: (475433,513024)\n",
      "##########one 200 batch totally time cost 10.474\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.174 | Acc: 92.655 | correct, total: (570221,615424)\n",
      "##########one 200 batch totally time cost 11.932\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.644 | correct, total: (665024,717824)\n",
      "epochIndex 77 |time: 12 | Acc: 92.651 | correct, total: (670363,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.146 | Acc: 94.238 | correct, total: (965,1024)\n",
      "##########one 200 batch totally time cost 1.433\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.178 | Acc: 92.564 | correct, total: (95733,103424)\n",
      "##########one 200 batch totally time cost 2.899\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.651 | correct, total: (190698,205824)\n",
      "##########one 200 batch totally time cost 4.285\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.176 | Acc: 92.587 | correct, total: (285374,308224)\n",
      "##########one 200 batch totally time cost 5.712\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.599 | correct, total: (380233,410624)\n",
      "##########one 200 batch totally time cost 7.127\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.605 | correct, total: (475084,513024)\n",
      "##########one 200 batch totally time cost 8.538\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.612 | correct, total: (569955,615424)\n",
      "##########one 200 batch totally time cost 9.968\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.582 | correct, total: (664577,717824)\n",
      "epochIndex 78 |time: 10 | Acc: 92.585 | correct, total: (669881,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.175 | Acc: 92.871 | correct, total: (951,1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 1.470\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.551 | correct, total: (95720,103424)\n",
      "##########one 200 batch totally time cost 2.882\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.175 | Acc: 92.648 | correct, total: (190691,205824)\n",
      "##########one 200 batch totally time cost 4.293\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.174 | Acc: 92.680 | correct, total: (285661,308224)\n",
      "##########one 200 batch totally time cost 5.723\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.616 | correct, total: (380302,410624)\n",
      "##########one 200 batch totally time cost 7.153\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.595 | correct, total: (475036,513024)\n",
      "##########one 200 batch totally time cost 8.510\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.580 | correct, total: (569761,615424)\n",
      "##########one 200 batch totally time cost 9.939\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.587 | correct, total: (664610,717824)\n",
      "epochIndex 79 |time: 10 | Acc: 92.584 | correct, total: (669875,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.060\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.189 | Acc: 91.797 | correct, total: (940,1024)\n",
      "##########one 200 batch totally time cost 1.864\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.178 | Acc: 92.544 | correct, total: (95713,103424)\n",
      "##########one 200 batch totally time cost 3.838\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.173 | Acc: 92.745 | correct, total: (190892,205824)\n",
      "##########one 200 batch totally time cost 5.274\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.173 | Acc: 92.703 | correct, total: (285732,308224)\n",
      "##########one 200 batch totally time cost 7.095\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.174 | Acc: 92.692 | correct, total: (380616,410624)\n",
      "##########one 200 batch totally time cost 8.553\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.174 | Acc: 92.677 | correct, total: (475454,513024)\n",
      "##########one 200 batch totally time cost 9.919\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.174 | Acc: 92.664 | correct, total: (570277,615424)\n",
      "##########one 200 batch totally time cost 11.327\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.639 | correct, total: (664988,717824)\n",
      "epochIndex 80 |time: 11 | Acc: 92.643 | correct, total: (670303,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.182 | Acc: 92.383 | correct, total: (946,1024)\n",
      "##########one 200 batch totally time cost 1.460\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.173 | Acc: 92.661 | correct, total: (95834,103424)\n",
      "##########one 200 batch totally time cost 2.854\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.173 | Acc: 92.682 | correct, total: (190761,205824)\n",
      "##########one 200 batch totally time cost 4.275\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.617 | correct, total: (285468,308224)\n",
      "##########one 200 batch totally time cost 5.628\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.587 | correct, total: (380185,410624)\n",
      "##########one 200 batch totally time cost 7.030\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.630 | correct, total: (475216,513024)\n",
      "##########one 200 batch totally time cost 8.427\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.176 | Acc: 92.613 | correct, total: (569963,615424)\n",
      "##########one 200 batch totally time cost 9.832\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.175 | Acc: 92.620 | correct, total: (664848,717824)\n",
      "epochIndex 81 |time: 9 | Acc: 92.627 | correct, total: (670184,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.179 | Acc: 92.090 | correct, total: (943,1024)\n",
      "##########one 200 batch totally time cost 1.476\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.172 | Acc: 92.631 | correct, total: (95803,103424)\n",
      "##########one 200 batch totally time cost 2.827\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.171 | Acc: 92.667 | correct, total: (190730,205824)\n",
      "##########one 200 batch totally time cost 4.268\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.173 | Acc: 92.634 | correct, total: (285520,308224)\n",
      "##########one 200 batch totally time cost 6.086\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.532 | correct, total: (379957,410624)\n",
      "##########one 200 batch totally time cost 7.525\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.175 | Acc: 92.590 | correct, total: (475011,513024)\n",
      "##########one 200 batch totally time cost 8.933\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.589 | correct, total: (569818,615424)\n",
      "##########one 200 batch totally time cost 10.292\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.637 | correct, total: (664968,717824)\n",
      "epochIndex 82 |time: 10 | Acc: 92.639 | correct, total: (670272,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.156 | Acc: 94.238 | correct, total: (965,1024)\n",
      "##########one 200 batch totally time cost 1.558\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.177 | Acc: 92.621 | correct, total: (95792,103424)\n",
      "##########one 200 batch totally time cost 2.988\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.663 | correct, total: (190723,205824)\n",
      "##########one 200 batch totally time cost 4.410\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.633 | correct, total: (285518,308224)\n",
      "##########one 200 batch totally time cost 5.819\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.173 | Acc: 92.697 | correct, total: (380637,410624)\n",
      "##########one 200 batch totally time cost 7.175\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.173 | Acc: 92.721 | correct, total: (475683,513024)\n",
      "##########one 200 batch totally time cost 8.643\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.174 | Acc: 92.672 | correct, total: (570328,615424)\n",
      "##########one 200 batch totally time cost 10.000\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.173 | Acc: 92.687 | correct, total: (665333,717824)\n",
      "epochIndex 83 |time: 10 | Acc: 92.684 | correct, total: (670601,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.195 | Acc: 91.699 | correct, total: (939,1024)\n",
      "##########one 200 batch totally time cost 1.494\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.174 | Acc: 92.621 | correct, total: (95792,103424)\n",
      "##########one 200 batch totally time cost 2.961\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.652 | correct, total: (190701,205824)\n",
      "##########one 200 batch totally time cost 4.810\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.172 | Acc: 92.703 | correct, total: (285734,308224)\n",
      "##########one 200 batch totally time cost 6.262\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.172 | Acc: 92.736 | correct, total: (380797,410624)\n",
      "##########one 200 batch totally time cost 8.079\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.173 | Acc: 92.694 | correct, total: (475543,513024)\n",
      "##########one 200 batch totally time cost 9.547\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.697 | correct, total: (570482,615424)\n",
      "##########one 200 batch totally time cost 10.991\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.173 | Acc: 92.696 | correct, total: (665396,717824)\n",
      "epochIndex 84 |time: 11 | Acc: 92.695 | correct, total: (670680,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.219 | Acc: 91.309 | correct, total: (935,1024)\n",
      "##########one 200 batch totally time cost 1.909\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.513 | correct, total: (95681,103424)\n",
      "##########one 200 batch totally time cost 3.328\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.500 | correct, total: (190387,205824)\n",
      "##########one 200 batch totally time cost 4.698\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.581 | correct, total: (285356,308224)\n",
      "##########one 200 batch totally time cost 6.106\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.602 | correct, total: (380246,410624)\n",
      "##########one 200 batch totally time cost 7.508\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.174 | Acc: 92.643 | correct, total: (475279,513024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 8.946\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.175 | Acc: 92.596 | correct, total: (569855,615424)\n",
      "##########one 200 batch totally time cost 10.812\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.622 | correct, total: (664866,717824)\n",
      "epochIndex 85 |time: 10 | Acc: 92.620 | correct, total: (670134,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.060\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.178 | Acc: 93.164 | correct, total: (954,1024)\n",
      "##########one 200 batch totally time cost 1.442\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.176 | Acc: 92.626 | correct, total: (95797,103424)\n",
      "##########one 200 batch totally time cost 2.859\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.554 | correct, total: (190499,205824)\n",
      "##########one 200 batch totally time cost 4.266\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.176 | Acc: 92.600 | correct, total: (285414,308224)\n",
      "##########one 200 batch totally time cost 5.667\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.174 | Acc: 92.639 | correct, total: (380396,410624)\n",
      "##########one 200 batch totally time cost 7.107\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.173 | Acc: 92.676 | correct, total: (475451,513024)\n",
      "##########one 200 batch totally time cost 8.931\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.173 | Acc: 92.658 | correct, total: (570237,615424)\n",
      "##########one 200 batch totally time cost 10.388\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.174 | Acc: 92.671 | correct, total: (665218,717824)\n",
      "epochIndex 86 |time: 10 | Acc: 92.674 | correct, total: (670526,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.211 | Acc: 90.723 | correct, total: (929,1024)\n",
      "##########one 200 batch totally time cost 1.432\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.167 | Acc: 92.935 | correct, total: (96117,103424)\n",
      "##########one 200 batch totally time cost 2.853\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.171 | Acc: 92.774 | correct, total: (190951,205824)\n",
      "##########one 200 batch totally time cost 4.255\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.172 | Acc: 92.723 | correct, total: (285796,308224)\n",
      "##########one 200 batch totally time cost 5.657\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.173 | Acc: 92.703 | correct, total: (380662,410624)\n",
      "##########one 200 batch totally time cost 7.063\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.562 | correct, total: (474867,513024)\n",
      "##########one 200 batch totally time cost 8.430\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.178 | Acc: 92.479 | correct, total: (569138,615424)\n",
      "##########one 200 batch totally time cost 9.833\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.433 | correct, total: (663506,717824)\n",
      "epochIndex 87 |time: 9 | Acc: 92.439 | correct, total: (668826,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.206 | Acc: 90.137 | correct, total: (923,1024)\n",
      "##########one 200 batch totally time cost 1.488\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.186 | Acc: 92.112 | correct, total: (95266,103424)\n",
      "##########one 200 batch totally time cost 2.891\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.186 | Acc: 92.150 | correct, total: (189667,205824)\n",
      "##########one 200 batch totally time cost 4.320\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.186 | Acc: 92.139 | correct, total: (283994,308224)\n",
      "##########one 200 batch totally time cost 5.682\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.189 | Acc: 92.094 | correct, total: (378159,410624)\n",
      "##########one 200 batch totally time cost 7.095\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.187 | Acc: 92.159 | correct, total: (472799,513024)\n",
      "##########one 200 batch totally time cost 8.624\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.186 | Acc: 92.158 | correct, total: (567162,615424)\n",
      "##########one 200 batch totally time cost 10.541\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.186 | Acc: 92.180 | correct, total: (661688,717824)\n",
      "epochIndex 88 |time: 10 | Acc: 92.181 | correct, total: (666958,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.204 | Acc: 91.406 | correct, total: (936,1024)\n",
      "##########one 200 batch totally time cost 1.483\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.186 | Acc: 92.172 | correct, total: (95328,103424)\n",
      "##########one 200 batch totally time cost 2.844\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.184 | Acc: 92.273 | correct, total: (189921,205824)\n",
      "##########one 200 batch totally time cost 4.260\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.184 | Acc: 92.248 | correct, total: (284331,308224)\n",
      "##########one 200 batch totally time cost 6.137\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.183 | Acc: 92.264 | correct, total: (378859,410624)\n",
      "##########one 200 batch totally time cost 7.551\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.183 | Acc: 92.291 | correct, total: (473477,513024)\n",
      "##########one 200 batch totally time cost 8.993\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.182 | Acc: 92.343 | correct, total: (568303,615424)\n",
      "##########one 200 batch totally time cost 10.375\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.182 | Acc: 92.313 | correct, total: (662646,717824)\n",
      "epochIndex 89 |time: 10 | Acc: 92.308 | correct, total: (667877,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.164 | Acc: 93.652 | correct, total: (959,1024)\n",
      "##########one 200 batch totally time cost 2.003\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.181 | Acc: 92.368 | correct, total: (95531,103424)\n",
      "##########one 200 batch totally time cost 3.350\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.181 | Acc: 92.348 | correct, total: (190075,205824)\n",
      "##########one 200 batch totally time cost 4.751\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.447 | correct, total: (284945,308224)\n",
      "##########one 200 batch totally time cost 6.227\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.179 | Acc: 92.443 | correct, total: (379592,410624)\n",
      "##########one 200 batch totally time cost 7.657\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.454 | correct, total: (474310,513024)\n",
      "##########one 200 batch totally time cost 9.100\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.179 | Acc: 92.417 | correct, total: (568756,615424)\n",
      "##########one 200 batch totally time cost 11.401\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.181 | Acc: 92.370 | correct, total: (663056,717824)\n",
      "epochIndex 90 |time: 11 | Acc: 92.377 | correct, total: (668377,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.158 | Acc: 93.262 | correct, total: (955,1024)\n",
      "##########one 200 batch totally time cost 1.475\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.640 | correct, total: (95812,103424)\n",
      "##########one 200 batch totally time cost 2.884\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.181 | Acc: 92.404 | correct, total: (190190,205824)\n",
      "##########one 200 batch totally time cost 4.300\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.179 | Acc: 92.451 | correct, total: (284957,308224)\n",
      "##########one 200 batch totally time cost 5.716\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.420 | correct, total: (379499,410624)\n",
      "##########one 200 batch totally time cost 7.072\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.475 | correct, total: (474421,513024)\n",
      "##########one 200 batch totally time cost 8.495\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.179 | Acc: 92.446 | correct, total: (568937,615424)\n",
      "##########one 200 batch totally time cost 9.908\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.179 | Acc: 92.457 | correct, total: (663677,717824)\n",
      "epochIndex 91 |time: 9 | Acc: 92.461 | correct, total: (668986,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.058\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.211 | Acc: 91.113 | correct, total: (933,1024)\n",
      "##########one 200 batch totally time cost 1.512\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.178 | Acc: 92.524 | correct, total: (95692,103424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 3.398\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.174 | Acc: 92.565 | correct, total: (190520,205824)\n",
      "##########one 200 batch totally time cost 4.762\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.176 | Acc: 92.496 | correct, total: (285096,308224)\n",
      "##########one 200 batch totally time cost 6.202\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.449 | correct, total: (379618,410624)\n",
      "##########one 200 batch totally time cost 7.626\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.177 | Acc: 92.454 | correct, total: (474312,513024)\n",
      "##########one 200 batch totally time cost 9.504\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.506 | correct, total: (569304,615424)\n",
      "##########one 200 batch totally time cost 10.979\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.178 | Acc: 92.472 | correct, total: (663789,717824)\n",
      "epochIndex 92 |time: 11 | Acc: 92.474 | correct, total: (669082,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.060\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.190 | Acc: 93.066 | correct, total: (953,1024)\n",
      "##########one 200 batch totally time cost 1.432\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.426 | correct, total: (95591,103424)\n",
      "##########one 200 batch totally time cost 3.350\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.482 | correct, total: (190350,205824)\n",
      "##########one 200 batch totally time cost 4.715\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.551 | correct, total: (285265,308224)\n",
      "##########one 200 batch totally time cost 6.151\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.176 | Acc: 92.537 | correct, total: (379978,410624)\n",
      "##########one 200 batch totally time cost 7.597\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.177 | Acc: 92.492 | correct, total: (474507,513024)\n",
      "##########one 200 batch totally time cost 9.475\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.494 | correct, total: (569233,615424)\n",
      "##########one 200 batch totally time cost 10.924\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.177 | Acc: 92.496 | correct, total: (663956,717824)\n",
      "epochIndex 93 |time: 11 | Acc: 92.491 | correct, total: (669200,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.059\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.256 | Acc: 91.992 | correct, total: (942,1024)\n",
      "##########one 200 batch totally time cost 1.418\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.181 | Acc: 92.372 | correct, total: (95535,103424)\n",
      "##########one 200 batch totally time cost 2.835\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.512 | correct, total: (190412,205824)\n",
      "##########one 200 batch totally time cost 4.345\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.178 | Acc: 92.455 | correct, total: (284968,308224)\n",
      "##########one 200 batch totally time cost 5.770\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.175 | Acc: 92.552 | correct, total: (380040,410624)\n",
      "##########one 200 batch totally time cost 7.188\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.176 | Acc: 92.533 | correct, total: (474718,513024)\n",
      "##########one 200 batch totally time cost 8.547\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.177 | Acc: 92.508 | correct, total: (569314,615424)\n",
      "##########one 200 batch totally time cost 9.962\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.176 | Acc: 92.536 | correct, total: (664243,717824)\n",
      "epochIndex 94 |time: 10 | Acc: 92.542 | correct, total: (669572,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.162 | Acc: 92.285 | correct, total: (945,1024)\n",
      "##########one 200 batch totally time cost 1.495\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.173 | Acc: 92.654 | correct, total: (95826,103424)\n",
      "##########one 200 batch totally time cost 2.939\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.177 | Acc: 92.473 | correct, total: (190332,205824)\n",
      "##########one 200 batch totally time cost 4.819\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.175 | Acc: 92.536 | correct, total: (285218,308224)\n",
      "##########one 200 batch totally time cost 6.184\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.177 | Acc: 92.517 | correct, total: (379898,410624)\n",
      "##########one 200 batch totally time cost 7.661\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.489 | correct, total: (474491,513024)\n",
      "##########one 200 batch totally time cost 9.042\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.400 | correct, total: (568654,615424)\n",
      "##########one 200 batch totally time cost 10.462\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.181 | Acc: 92.380 | correct, total: (663126,717824)\n",
      "epochIndex 95 |time: 10 | Acc: 92.379 | correct, total: (668392,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.183 | Acc: 92.871 | correct, total: (951,1024)\n",
      "##########one 200 batch totally time cost 1.509\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.173 | Acc: 92.644 | correct, total: (95816,103424)\n",
      "##########one 200 batch totally time cost 3.320\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.178 | Acc: 92.489 | correct, total: (190365,205824)\n",
      "##########one 200 batch totally time cost 4.781\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.179 | Acc: 92.439 | correct, total: (284919,308224)\n",
      "##########one 200 batch totally time cost 6.151\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.470 | correct, total: (379703,410624)\n",
      "##########one 200 batch totally time cost 7.594\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.179 | Acc: 92.422 | correct, total: (474147,513024)\n",
      "##########one 200 batch totally time cost 10.143\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.406 | correct, total: (568689,615424)\n",
      "##########one 200 batch totally time cost 12.197\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.181 | Acc: 92.380 | correct, total: (663124,717824)\n",
      "epochIndex 96 |time: 12 | Acc: 92.375 | correct, total: (668365,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.186 | Acc: 91.406 | correct, total: (936,1024)\n",
      "##########one 200 batch totally time cost 1.480\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.535 | correct, total: (95703,103424)\n",
      "##########one 200 batch totally time cost 2.863\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.176 | Acc: 92.504 | correct, total: (190396,205824)\n",
      "##########one 200 batch totally time cost 4.853\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.180 | Acc: 92.394 | correct, total: (284782,308224)\n",
      "##########one 200 batch totally time cost 6.279\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.180 | Acc: 92.383 | correct, total: (379347,410624)\n",
      "##########one 200 batch totally time cost 8.600\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.180 | Acc: 92.383 | correct, total: (473947,513024)\n",
      "##########one 200 batch totally time cost 10.043\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.377 | correct, total: (568513,615424)\n",
      "##########one 200 batch totally time cost 11.401\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.181 | Acc: 92.346 | correct, total: (662880,717824)\n",
      "epochIndex 97 |time: 11 | Acc: 92.347 | correct, total: (668159,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.064\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.169 | Acc: 92.188 | correct, total: (944,1024)\n",
      "##########one 200 batch totally time cost 1.509\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.179 | Acc: 92.471 | correct, total: (95637,103424)\n",
      "##########one 200 batch totally time cost 3.422\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.182 | Acc: 92.364 | correct, total: (190107,205824)\n",
      "##########one 200 batch totally time cost 4.849\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.181 | Acc: 92.373 | correct, total: (284716,308224)\n",
      "##########one 200 batch totally time cost 6.285\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.179 | Acc: 92.442 | correct, total: (379589,410624)\n",
      "##########one 200 batch totally time cost 7.655\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.181 | Acc: 92.369 | correct, total: (473874,513024)\n",
      "##########one 200 batch totally time cost 9.147\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.181 | Acc: 92.388 | correct, total: (568580,615424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 200 batch totally time cost 10.532\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.181 | Acc: 92.383 | correct, total: (663149,717824)\n",
      "epochIndex 98 |time: 10 | Acc: 92.385 | correct, total: (668437,723532)\n",
      "########################################################################\n",
      "##########one 200 batch totally time cost 0.065\n",
      "batchIndex 1 |trainLen 1414 | Loss: 0.165 | Acc: 92.676 | correct, total: (949,1024)\n",
      "##########one 200 batch totally time cost 1.885\n",
      "batchIndex 201 |trainLen 1414 | Loss: 0.175 | Acc: 92.577 | correct, total: (95747,103424)\n",
      "##########one 200 batch totally time cost 3.308\n",
      "batchIndex 401 |trainLen 1414 | Loss: 0.179 | Acc: 92.421 | correct, total: (190225,205824)\n",
      "##########one 200 batch totally time cost 4.661\n",
      "batchIndex 601 |trainLen 1414 | Loss: 0.179 | Acc: 92.426 | correct, total: (284879,308224)\n",
      "##########one 200 batch totally time cost 6.127\n",
      "batchIndex 801 |trainLen 1414 | Loss: 0.178 | Acc: 92.454 | correct, total: (379640,410624)\n",
      "##########one 200 batch totally time cost 7.510\n",
      "batchIndex 1001 |trainLen 1414 | Loss: 0.178 | Acc: 92.447 | correct, total: (474276,513024)\n",
      "##########one 200 batch totally time cost 9.487\n",
      "batchIndex 1201 |trainLen 1414 | Loss: 0.180 | Acc: 92.394 | correct, total: (568613,615424)\n",
      "##########one 200 batch totally time cost 11.367\n",
      "batchIndex 1401 |trainLen 1414 | Loss: 0.180 | Acc: 92.409 | correct, total: (663331,717824)\n",
      "epochIndex 99 |time: 11 | Acc: 92.401 | correct, total: (668550,723532)\n",
      "########################################################################\n"
     ]
    }
   ],
   "source": [
    "###用于测试csv和mlp\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 五层神经网络\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 200)\n",
    "        self.fc3 = nn.Linear(200, 100)\n",
    "        self.fc4 = nn.Linear(100, num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "\n",
    "mlp = NeuralNet(14,200,4)\n",
    "print(mlp)\n",
    "\n",
    "##############################################读写CSV\n",
    "file1 = \"./trainData/dataAllSim.csv\"\n",
    "##方式1\n",
    "data1=[]\n",
    "csv_reader = csv.reader(open(file1))\n",
    "#for row in csv_reader:\n",
    "#        data1.append(row)\n",
    "#print(data1[0])        \n",
    "\n",
    "##方式2\n",
    "#https://blog.csdn.net/zw__chen/article/details/82806900\n",
    "csvfile = open(file1, 'r')\n",
    "xyData= np.loadtxt(file1,delimiter=',',skiprows=1)\n",
    "x = xyData[:,0:-1]\n",
    "y = xyData[:,-1]\n",
    "print(y.shape )\n",
    "print(x.shape )\n",
    "x1 =torch.from_numpy(x)\n",
    "y1 =torch.from_numpy(y)\n",
    "\n",
    "dataset1 = TensorDataset(x1.float(),y1.long())\n",
    "\n",
    "#train_dataset, test_dataset = random_split(\n",
    "#    dataset=dataset1,\n",
    "#    lengths=[7, 3],\n",
    "#    generator=torch.Generator().manual_seed(0)\n",
    "#)\n",
    "\n",
    "#################################\n",
    "#数据准备：平衡\n",
    "#tmp = y.T[0]\n",
    "#trainratio = np.bincount(tmp.astype(\"int64\"))\n",
    "#train_weights = 1./torch.tensor(trainratio, dtype=torch.float)\n",
    "#train_sampleweights = train_weights[y]\n",
    "#train_sampler = WeightedRandomSampler(weights=train_sampleweights, num_samples = len(train_sampleweights))\n",
    "#train_loader = DataLoader( dataset1, batch_size=4, num_workers=1, sampler=train_sampler)\n",
    "train_loader = DataLoader(dataset=dataset1, batch_size=512, shuffle=True)\n",
    "\n",
    "#准备设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == 'cuda':\n",
    "    mlp = torch.nn.DataParallel(mlp)\n",
    "    cudnn.benchmark = True\n",
    "    mlp =  mlp.to(device)\n",
    "print(device)\n",
    "\n",
    "#准备模型\n",
    "state = {\"net\": mlp.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "modelPathName = \"./trainedModes/\"+\"redTLS.modeparams\"\n",
    "params = torch.load(modelPathName)\n",
    "mlp.load_state_dict(params['net'])\n",
    "optimizer.load_state_dict(params['optimizer'])\n",
    "\n",
    "#################################\n",
    "#训练开始\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mlp.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "running_loss = 0\n",
    "startEpoch = 0\n",
    "epochs = 3000#大概8小时\n",
    "print(\"start training\")\n",
    "\n",
    "for epoch in range(startEpoch, epochs):  # 多批次循环\n",
    "\n",
    "     mlp.train()\n",
    "     time_start = time.time()\n",
    "     total = 0\n",
    "     correct = 0\n",
    "     running_loss = 0.0\n",
    "     \n",
    "     for i, data in enumerate(train_loader, 0):\n",
    "         # 获取输入\n",
    "         #print(epoch,i)\n",
    "         inputs, labels = data\n",
    "         #inputs, labels = inputs.to(device), labels.to(device)\n",
    "         inputs=inputs.type(torch.float32)\n",
    "         labels=labels\n",
    "           \n",
    "         if device == 'cuda':\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "         # 梯度置0\n",
    "         optimizer.zero_grad()\n",
    "\n",
    "         # 正向传播，反向传播，优化a\n",
    "         outputs = mlp(inputs)\n",
    "         #print(\"inputs:\",inputs)\n",
    "         #print(\"###################################\")\n",
    "         #print(\"outputs:\",outputs)\n",
    "         #print(\"labels\",labels)\n",
    "\n",
    "         loss = criterion(outputs, labels)\n",
    "         #print(\"loss:\",loss.item())\n",
    "        \n",
    "         loss.backward()\n",
    "         optimizer.step()\n",
    "\n",
    "         _, predicted = torch.max(outputs.data,1)\n",
    "         total += labels.size(0)\n",
    "         correct += predicted.eq(labels).sum().item()\n",
    "         \n",
    "         #print(\"labels.size(0):\",labels.size(0))\n",
    "         #print(\"predicted:\",predicted)\n",
    "         #print(\"predicted.eq(labels).sum().item():\",predicted.eq(labels).sum().item())\n",
    "         \n",
    "         running_loss += loss.item()\n",
    "         \n",
    "         #os.input()\n",
    "         if i % 200 == 1:  # 每200批次打印一次\n",
    "             time_end = time.time()\n",
    "             print('##########one 200 batch totally time cost %.3f' %(time_end-time_start))\n",
    "             print(\"batchIndex %d |trainLen %d | Loss: %.3f | Acc: %.3f | correct, total: (%d,%d)\" % (\n",
    "                 i, len(train_loader), running_loss/(i+1), 100.*correct/total, correct, total))\n",
    "             \n",
    "     time_end = time.time()\n",
    "     print(\"epochIndex %d |time: %d | Acc: %.3f | correct, total: (%d,%d)\" % (\n",
    "                 epoch, (time_end-time_start), 100.*correct/total, correct, total))\n",
    "     print(\"########################################################################\")\n",
    "     \n",
    "    \n",
    "state = {\"net\": mlp.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "modelPathName = \"./trainedModes/\"+\"redTLS.modeparams\"\n",
    "torch.save(state, modelPathName)\n",
    "params = torch.load(modelPathName)\n",
    "mlp.load_state_dict(params['net'])\n",
    "optimizer.load_state_dict(params['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "422e83c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"net\": mlp.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "modelPathName = \"./trainedModes/\"+\"redTLS.modeparams\"\n",
    "torch.save(state, modelPathName)\n",
    "params = torch.load(modelPathName)\n",
    "mlp.load_state_dict(params['net'])\n",
    "optimizer.load_state_dict(params['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98475bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 5e9094a] 读写csv，MLP训练OK\n",
      " 6 files changed, 2828 insertions(+), 402 deletions(-)\n",
      " rewrite mainNBDT1.ipynb (99%)\n",
      " create mode 100644 mainTestCSVMLP2-Copy1.ipynb\n",
      " create mode 100644 mainTestCSVMLP2.ipynb\n",
      " rewrite trainData/dataAllSim.zip (90%)\n",
      " create mode 100644 trainedModes/redTLS.modeparams\n",
      "Enumerating objects: 27, done.\n",
      "Counting objects: 100% (27/27), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (18/18), done.\n",
      "Writing objects:  85% (17/20), 325.52 MiB | 1.21 MiB/s \r"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m  \"读写csv，MLP训练OK\"\n",
    "!git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
