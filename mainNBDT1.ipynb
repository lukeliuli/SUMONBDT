{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eWSjWG0Qmpdm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/SUMONBDT'\n",
      "/home/pi/SUMONBDT\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cpu\n",
      "tensor([3, 8])\n",
      "tensor([[-0.1330, -0.1507, -0.1077, -0.1944,  0.3642, -0.2358,  0.1663, -0.1099,\n",
      "         -0.1701, -0.6011],\n",
      "        [-0.1036,  0.3211,  0.2554,  0.1841,  0.4085, -0.9025,  0.3620, -0.1193,\n",
      "         -0.1036, -0.4376]], grad_fn=<AddmmBackward0>)\n",
      "tensor([4, 4])\n",
      "#########################################################################\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3585e76a7650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#########################################################################\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute 'input'"
     ]
    }
   ],
   "source": [
    "#mkdir /content/tmp\n",
    "#%cp -r -f -v /content/drive/MyDrive/SUMONBDT /content/tmp\n",
    "\n",
    "%cd /SUMONBDT\n",
    "#%cd  /content/drive/MyDrive/SUMONBDT\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import resnet\n",
    "import os\n",
    "\n",
    "\n",
    "outputNow =torch.Tensor()\n",
    "inputNow =torch.Tensor()\n",
    "fc_weight =torch.Tensor()\n",
    "fc_bias =torch.Tensor()\n",
    "\n",
    "modelPathName = \"/content/drive/MyDrive/SUMONBDT/trainedModes/resnet18End_accuray95.modeparams\"\n",
    "modelPath = \"/content/drive/MyDrive/SUMONBDT/trainedModes\"\n",
    "\n",
    "modelPath = \"/SUMONBDT/trainedModes\"\n",
    "modelPathName = modelPath+\"/resnet18End_accuray95.modeparams\"\n",
    "modelPathName = \"/SUMONBDT/trainedModes/resnet18End_accuray95.modeparams\"\n",
    "\n",
    "def evalCifar(testloader, resnet18, classes):\n",
    "\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  nbdt_total = 0\n",
    "\n",
    "  nbdt_correct = 0\n",
    "  resnet18.eval()\n",
    "  with torch.no_grad():\n",
    "      for data in testloader:\n",
    "          images, labels = data\n",
    "          labels = labels.to(device)\n",
    "          images = images.to(device)\n",
    "          outputs = resnet18(images)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "          os.pause()\n",
    "\n",
    "          myLoss,myLabels,NBDTpredictedLabel = computeLoss(labels)\n",
    "          nbdt_total =  total\n",
    "          nbdt_correct += NBDTpredictedLabel.eq(myLabels).sum().item()\n",
    "          \n",
    "\n",
    "  print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "      100 * correct / total))\n",
    "  \n",
    "  print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "  100 * nbdt_correct / nbdt_total))\n",
    "\n",
    "def hook2(module, input, output):\n",
    "    '''把这层的输出拷贝到features中'''\n",
    "    global inputNow\n",
    "    global outputNow\n",
    "    global fc_weight\n",
    "    global fc_bias\n",
    "    \n",
    "    #print(input[0].shape)\n",
    "    inputNow=input[0].clone()\n",
    "    outputNow=output.clone()\n",
    "    fc_weight=module.weight.clone()\n",
    "    fc_bias=module.bias.clone()\n",
    "    #inputNow =  input\n",
    "    \n",
    "\n",
    "    \n",
    "    #print(output.data)\n",
    "    #print(input[0].data)\n",
    "    #print(input[0].data.size())\n",
    "    #print(module.weight)\n",
    "    #print(module.bias)\n",
    "    #print(inputNow)\n",
    "    #print(outputNow)\n",
    "\n",
    "    #computeLoss()\n",
    "\n",
    "\n",
    "\n",
    "def computeLoss(labels):\n",
    "\n",
    "  global inputNow\n",
    "  global outputNow\n",
    "  global fc_weight\n",
    "  global fc_bias\n",
    "  global myLoss\n",
    "\n",
    "  ###简单的分级识别\n",
    "  #GOD: 1. plane,bird\n",
    "  #     2. deer,dog,horse,cat,frog\n",
    "  #     3. car,truck,ship\n",
    "  #classes = ('plane' 0, 'car' 1, 'bird' 2, 'cat' 3,\n",
    "  #           'deer' 4, 'dog' 5, 'frog' 6, 'horse' 7 , 'ship' 8,  'truck' 9)\n",
    "  #layerA         0 \n",
    "  #layerB      0 (likebird)       1 (likecat)         2(likecar)\n",
    "  #layerC  plane 0,bird2     deer4,dog5,horse7,cat3,frog6        car 1,truck9,ship8\n",
    "  myDict =torch.LongTensor([0,2,0,1,1,1,1,1,2,2])\n",
    "  #print(myDict)\n",
    "  w0 = fc_weight  # 10x512\n",
    "  bias = fc_bias  # 10x512\n",
    "  wA_B = {}\n",
    "  bA_B = {}\n",
    "\n",
    "\n",
    "  wA_B['0_1_likebird'] =  (w0[0]+w0[2])/2\n",
    "  bA_B['0_1_likebird'] = (bias[0]+bias[2])/2\n",
    "\n",
    "\n",
    "  wA_B['0_2_likecat'] = (w0[3]+w0[4]+w0[5]+w0[6]+w0[7])/6\n",
    "  bA_B['0_2_likecat'] = (bias[3]+bias[4]+bias[5]+bias[6]+bias[7])/6\n",
    "\n",
    "  wA_B['0_3_likecar'] = (w0[1]+w0[8]+w0[9])/3\n",
    "  bA_B['0_3_likecar'] = (bias[1]+bias[8]+bias[9])/3\n",
    "  wTmp = wA_B['0_1_likebird'].unsqueeze(1)\n",
    "  s1 =torch.mm(inputNow,wTmp)+bA_B['0_1_likebird']\n",
    "  wTmp = wA_B['0_2_likecat'].unsqueeze(1)\n",
    "  s2 =torch.mm(inputNow,wTmp)+bA_B['0_2_likecat']\n",
    "  wTmp = wA_B['0_3_likecar'].unsqueeze(1)\n",
    "  s3 =torch.mm(inputNow,wTmp)+bA_B['0_3_likecar']\n",
    "\n",
    "  s4 = torch.cat((s1,s2,s3),1)\n",
    "  \n",
    "  _, NBDTpredictedLabel = s4.max(1)\n",
    " \n",
    "  #print(\"s1:\",s1)\n",
    "  #print(\"s2:\",s2)\n",
    "  #print(\"s3:\",s3)\n",
    "  #print(\"s4:\",s4)\n",
    "  #print(\"myPredicted:\",NBDTpredictedLabel)\n",
    "\n",
    "  myLabels = labels.clone().detach()\n",
    "  #print(\"mylabels1:\",myLabels)\n",
    "  for i,data in enumerate(labels):\n",
    "    #tmp = data.numpy()\n",
    "    #print(data)\n",
    "    myLabels[i] = myDict[data]\n",
    "  #print(\"mylabels2:\",myLabels)\n",
    "\n",
    "  myLoss = criterion(s4,myLabels)\n",
    "  #print(\"myLoss:\",myLoss)\n",
    "  return myLoss,myLabels,NBDTpredictedLabel\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "transform1 = transforms.Compose(\n",
    "    [transforms.RandomCrop(32, padding=4),  # 先四周填充0，在吧图像随机裁剪成32*32\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])  # R,G,B每层的归一化用到的均值和方差\n",
    "\n",
    "\n",
    "#transform1 = transforms.Compose(\n",
    "#    [transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])  # R,G,B每层的归一化用到的均值和方差\n",
    "\n",
    "batch_sizeV = 2\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform1)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_sizeV, shuffle=True, num_workers=2)\n",
    "\n",
    "batch_sizeV = 2\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform1)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_sizeV, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "startEpoch = 0\n",
    "\n",
    "#resnet18 = models.resnet18(pretrained=False)#采用torchvision的模型，无法达到94%的正确率，最多88%\n",
    "resnet18 = resnet.resnet18(num_classes=10)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device =\"cpu\"\n",
    "if device == 'cuda':\n",
    "  resnet18 = torch.nn.DataParallel(resnet18)\n",
    "  cudnn.benchmark = True\n",
    "print(device)\n",
    "resnet18 = resnet18.to(device)\n",
    "\n",
    "\n",
    "\n",
    "#params = torch.load(modelPathName, map_location=device)\n",
    "#resnet18.load_state_dict(params[\"net\"])\n",
    "#startEpoch = params[\"epoch\"]\n",
    "#print(params)\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "##基于hook和name_parameters.看输出数据类型和值,网络权值\n",
    "#for name, parameters in resnet18.named_parameters():\n",
    "    #print(name, ':', parameters.size())\n",
    "#    params[name] = parameters.detach()\n",
    "#print(params[\"fc.bias\"])\n",
    "handle = resnet18.fc.register_forward_hook(hook2)\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs = resnet18(images)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print(labels)\n",
    "print(outputs)\n",
    "print(predicted)\n",
    "print(\"#########################################################################\")\n",
    "os.input()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(outputs,labels)\n",
    "myLoss,myLabels,NBDTpredictedLabel = computeLoss(labels)\n",
    "#print(outputs.data.numpy())\n",
    "print(\"inputNow:\",inputNow)\n",
    "print(\"outputNow:\",outputNow)\n",
    "print(\"predicted:\",predicted)\n",
    "print(\"labels:\",labels)\n",
    "print(\"myLabels:\",myLabels)\n",
    "print(\"loss:\",loss)\n",
    "print(\"myLoss:\",myLoss)\n",
    "\n",
    "evalCifar(testloader, resnet18, classes)\n",
    "\n",
    "handle.remove()\n",
    "\n",
    "##########################################################################################\n",
    "###开始训练\n",
    "print(\"##开始训练################################################################################\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device =\"cpu\"\n",
    "if device == 'cuda':\n",
    "  resnet18 = torch.nn.DataParallel(resnet18)\n",
    "  cudnn.benchmark = True\n",
    "print(device)\n",
    "resnet18 = resnet18.to(device)\n",
    "\n",
    "# trainloader\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet18.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "startEpoc = 0\n",
    "epochs = 1000\n",
    "resnet18.train()\n",
    "print(\"start training\")\n",
    "\n",
    "handle = resnet18.fc.register_forward_hook(hook2)\n",
    "\n",
    "for epoch in range(startEpoch, epochs):  # 多批次循环\n",
    "\n",
    "     resnet18.train()\n",
    "     running_loss = 0.0\n",
    "     time_start = time.time()\n",
    "     #learning rate 不变\n",
    "#     #adjust_learning_rate(optimizer, epoch, epochs, trainloader, batch_sizeV)\n",
    "     total = 0\n",
    "     correct = 0\n",
    "\n",
    "     nbdt_total = 0\n",
    "     nbdt_correct = 0\n",
    "     running_nbdtloss = 0.0\n",
    "     for i, data in enumerate(trainloader, 0):\n",
    "         # 获取输入\n",
    "         #print(epoch,i)\n",
    "         inputs, labels = data\n",
    "\n",
    "         inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "         # 梯度置0\n",
    "         optimizer.zero_grad()\n",
    "\n",
    "         # 正向传播，反向传播，优化a\n",
    "         outputs = resnet18(inputs)\n",
    "\n",
    "         loss = criterion(outputs, labels)\n",
    "         os.pause()\n",
    "         ###############\n",
    "         myLoss,myLabels,NBDTpredictedLabel = computeLoss(labels)\n",
    "         loss = loss+0.1*myLoss\n",
    "         loss.backward()\n",
    "         optimizer.step()\n",
    "\n",
    "         _, predicted = outputs.max(1)\n",
    "         total += labels.size(0)\n",
    "         correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        \n",
    "         print(\"outputs:\",outputs)\n",
    "         print(\"labels\",labels)\n",
    "         print(\"labels.size(0):\",labels.size(0))\n",
    "         print(\"predicted:\",predicted)\n",
    "\n",
    "         nbdt_total =  total\n",
    "         nbdt_correct += NBDTpredictedLabel.eq(myLabels).sum().item()\n",
    "         #print(\"myLoss:\",myLoss)\n",
    "         #print(\"myLabels:\",myLabels)\n",
    "         #print(\"Loss:\",loss)\n",
    "         #print(\"labels:\",labels)\n",
    "         #print(\"i,epoch:\",i,epoch)\n",
    "         # 打印状态信息\n",
    "         running_loss += loss.item()\n",
    "         running_nbdtloss += myLoss.item()\n",
    "         if i % 20 == 19:  # 每200批次打印一次\n",
    "             time_end = time.time()\n",
    "             print('##########one 20 batch totally time cost %.3f' %(time_end-time_start))\n",
    "             print(\"batchIndex %d |trainLen %d | Loss: %.3f | Acc: %.3f | correct, total: (%d,%d)\" % (\n",
    "                 i, len(trainloader), running_loss/(i+1), 100.*correct/total, correct, total))\n",
    "             print(\"myLoss: %.3f | nbdt_Acc: %.3f | nbdt_correct, nbdt_total: (%d,%d)\" % (\n",
    "                 running_nbdtloss/(i+1),100.*nbdt_correct/nbdt_total, nbdt_correct, nbdt_total))\n",
    "\n",
    "     time_end = time.time()\n",
    "     \n",
    "\n",
    "     state = {\"net\": resnet18.state_dict(), \"optimizer\": optimizer.state_dict(), \"epoch\": epoch}\n",
    "     \n",
    "     modelPathNameTmp = modelPath+\"/nbdt_resnet18_\"+str(epoch)+\".modeparams\"\n",
    "     print(\"saving \",modelPathNameTmp)\n",
    "     torch.save(state, modelPathNameTmp)\n",
    "     #params = torch.load(modelPathNameTmp)\n",
    "     #resnet18.load_state_dict(params[\"net\"])\n",
    "     #optimizer.load_state_dict(params[\"optimizer\"])\n",
    "     evalCifar(testloader, resnet18, classes)\n",
    "     print('##########epoch %d totally time cost %.3f#####################' % (epoch, time_end-time_start))\n",
    "     print(\"###################################################################\")\n",
    "handle.remove()\n",
    "print('Finished Training')\n",
    "\n",
    "#有两种方法，一种只保存参数，一种全保存，后者简单但存储量大，我用的是前者\n",
    "# # 保存和加载整个模型\n",
    "state = {\"net\": resnet18.state_dict(), \"optimizer\": optimizer.state_dict(), \"epoch\": epoch}\n",
    "\n",
    "modelPathName = modelPath+\"/nbdt_resnet18_End\"+\".modeparams\"\n",
    "torch.save(state, modelPathName)\n",
    "params = torch.load(modelPathName)\n",
    "resnet18.load_state_dict(params['net'])\n",
    "optimizer.load_state_dict(params['optimizer'])\n",
    "\n",
    "# # 仅保存和加载模型参数(推荐使用)\n",
    "#torch.save(resnet18.state_dict(), './trainedModes/resnet18params.pkl')\n",
    "#resnet18.load_state_dict(torch.load('./trainedModes/resnet18params.pkl'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMeD08LEmrBq"
   },
   "outputs": [],
   "source": [
    "print(outputs)\n",
    "print(labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNdOsCudHEfMU1zFa9xoWYi",
   "collapsed_sections": [],
   "mount_file_id": "1si0P8tFT072L1JA6f9OU0NxRgm0PdYdm",
   "name": "Untitled0.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
