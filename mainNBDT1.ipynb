{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1si0P8tFT072L1JA6f9OU0NxRgm0PdYdm",
      "authorship_tag": "ABX9TyPyBgdb3aS6DLu6b7nvZPME",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukeliuli/SUMONBDT/blob/main/mainNBDT1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd  /content/drive/MyDrive/SUMONBDT\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "import time\n",
        "from collections import namedtuple\n",
        "import resnet\n",
        "import os\n",
        "\n",
        "\n",
        "outputNow =torch.Tensor()\n",
        "inputNow =torch.Tensor()\n",
        "fc_weight =torch.Tensor()\n",
        "fc_bias =torch.Tensor()\n",
        "\n",
        "def evalCifar(testloader, resnet18, classes):\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  nbdt_total = 0\n",
        "\n",
        "  nbdt_correct = 0\n",
        "  resnet18.eval()\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data\n",
        "          labels = labels.to(device)\n",
        "          images = images.to(device)\n",
        "          outputs = resnet18(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "          myLoss,myLabels,NBDTpredictedLabel = computeLoss(labels)\n",
        "          nbdt_total =  total\n",
        "          nbdt_correct += NBDTpredictedLabel.eq(myLabels).sum().item()\n",
        "          \n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "      100 * correct / total))\n",
        "  \n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "  100 * nbdt_correct / nbdt_total))\n",
        "\n",
        "def hook2(module, input, output):\n",
        "    '''把这层的输出拷贝到features中'''\n",
        "    global inputNow\n",
        "    global outputNow\n",
        "    global fc_weight\n",
        "    global fc_bias\n",
        "    \n",
        "    #print(input[0].shape)\n",
        "    inputNow=input[0].clone()\n",
        "    outputNow=output.clone()\n",
        "    fc_weight=module.weight.clone()\n",
        "    fc_bias=module.bias.clone()\n",
        "    #inputNow =  input\n",
        "    \n",
        "\n",
        "    \n",
        "    #print(output.data)\n",
        "    #print(input[0].data)\n",
        "    #print(input[0].data.size())\n",
        "    #print(module.weight)\n",
        "    #print(module.bias)\n",
        "    #print(inputNow)\n",
        "    #print(outputNow)\n",
        "\n",
        "    #computeLoss()\n",
        "\n",
        "\n",
        "\n",
        "def computeLoss(labels):\n",
        "\n",
        "  global inputNow\n",
        "  global outputNow\n",
        "  global fc_weight\n",
        "  global fc_bias\n",
        "  global myLoss\n",
        "\n",
        "  ###简单的分级识别\n",
        "  #GOD: 1. plane,bird\n",
        "  #     2. deer,dog,horse,cat,frog\n",
        "  #     3. car,truck,ship\n",
        "  #classes = ('plane' 0, 'car' 1, 'bird' 2, 'cat' 3,\n",
        "  #           'deer' 4, 'dog' 5, 'frog' 6, 'horse' 7 , 'ship' 8,  'truck' 9)\n",
        "  #layerA         0 \n",
        "  #layerB      0 (likebird)       1 (likecat)         2(likecar)\n",
        "  #layerC  plane 0,bird2     deer4,dog5,horse7,cat3,frog6        car 1,truck9,ship8\n",
        "  myDict =torch.LongTensor([0,2,0,1,1,1,1,1,2,2])\n",
        "  #print(myDict)\n",
        "  w0 = fc_weight  # 10x512\n",
        "  bias = fc_bias  # 10x512\n",
        "  wA_B = {}\n",
        "  bA_B = {}\n",
        "\n",
        "\n",
        "  wA_B['0_1_likebird'] =  (w0[0]+w0[2])/2\n",
        "  bA_B['0_1_likebird'] = (bias[0]+bias[2])/2\n",
        "\n",
        "\n",
        "  wA_B['0_2_likecat'] = (w0[3]+w0[4]+w0[5]+w0[6]+w0[7])/6\n",
        "  bA_B['0_2_likecat'] = (bias[3]+bias[4]+bias[5]+bias[6]+bias[7])/6\n",
        "\n",
        "  wA_B['0_3_likecar'] = (w0[1]+w0[8]+w0[9])/3\n",
        "  bA_B['0_3_likecar'] = (bias[1]+bias[8]+bias[9])/3\n",
        "  wTmp = wA_B['0_1_likebird'].unsqueeze(1)\n",
        "  s1 =torch.mm(inputNow,wTmp)+bA_B['0_1_likebird']\n",
        "  wTmp = wA_B['0_2_likecat'].unsqueeze(1)\n",
        "  s2 =torch.mm(inputNow,wTmp)+bA_B['0_2_likecat']\n",
        "  wTmp = wA_B['0_3_likecar'].unsqueeze(1)\n",
        "  s3 =torch.mm(inputNow,wTmp)+bA_B['0_3_likecar']\n",
        "\n",
        "  s4 = torch.cat((s1,s2,s3),1)\n",
        "  \n",
        "  _, NBDTpredictedLabel = s4.max(1)\n",
        " \n",
        "  #print(\"s1:\",s1)\n",
        "  #print(\"s2:\",s2)\n",
        "  #print(\"s3:\",s3)\n",
        "  #print(\"s4:\",s4)\n",
        "  #print(\"myPredicted:\",NBDTpredictedLabel)\n",
        "\n",
        "  myLabels = labels.clone().detach()\n",
        "  #print(\"mylabels1:\",myLabels)\n",
        "  for i,data in enumerate(labels):\n",
        "    #tmp = data.numpy()\n",
        "    #print(data)\n",
        "    myLabels[i] = myDict[data]\n",
        "  #print(\"mylabels2:\",myLabels)\n",
        "\n",
        "  myLoss = criterion(s4,myLabels)\n",
        "  #print(\"myLoss:\",myLoss)\n",
        "  return myLoss,myLabels,NBDTpredictedLabel\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "#########################################################################################\n",
        "\n",
        "transform1 = transforms.Compose(\n",
        "    [transforms.RandomCrop(32, padding=4),  # 先四周填充0，在吧图像随机裁剪成32*32\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])  # R,G,B每层的归一化用到的均值和方差\n",
        "\n",
        "\n",
        "#transform1 = transforms.Compose(\n",
        "#    [transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])  # R,G,B每层的归一化用到的均值和方差\n",
        "\n",
        "batch_sizeV = 512\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform1)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_sizeV, shuffle=True, num_workers=2)\n",
        "\n",
        "batch_sizeV = 512\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform1)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_sizeV, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "startEpoch = 0\n",
        "\n",
        "#resnet18 = models.resnet18(pretrained=False)#采用torchvision的模型，无法达到94%的正确率，最多88%\n",
        "resnet18 = resnet.resnet18(num_classes=10)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device =\"cpu\"\n",
        "if device == 'cuda':\n",
        "  resnet18 = torch.nn.DataParallel(resnet18)\n",
        "  cudnn.benchmark = True\n",
        "print(device)\n",
        "resnet18 = resnet18.to(device)\n",
        "\n",
        "\n",
        "modelPathName = \"/content/drive/MyDrive/SUMONBDT/trainedModes/nbdt_resnet18__433_accuray95.modeparams\"\n",
        "modelPathName = \"/content/drive/MyDrive/SUMONBDT/trainedModes/nbdt_resnet18_433.modeparams\"\n",
        "modelPath = \"/content/drive/MyDrive/SUMONBDT/trainedModes/\"\n",
        "params = torch.load(modelPathName, map_location=device)\n",
        "resnet18.load_state_dict(params[\"net\"])\n",
        "startEpoch = params[\"epoch\"]\n",
        "#print(params)\n",
        "\n",
        "\n",
        "#######################################################################\n",
        "##基于hook和name_parameters.看输出数据类型和值,网络权值\n",
        "for name, parameters in resnet18.named_parameters():\n",
        "    #print(name, ':', parameters.size())\n",
        "    params[name] = parameters.detach()\n",
        "#print(params[\"fc.bias\"])\n",
        "handle = resnet18.fc.register_forward_hook(hook2)\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "outputs = resnet18(images)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(outputs,labels)\n",
        "myLoss,myLabels,NBDTpredictedLabel = computeLoss(labels)\n",
        "#print(outputs.data.numpy())\n",
        "print(\"inputNow:\",inputNow)\n",
        "print(\"outputNow:\",outputNow)\n",
        "print(\"predicted:\",predicted)\n",
        "print(\"labels:\",labels)\n",
        "print(\"myLabels:\",myLabels)\n",
        "print(\"loss:\",loss)\n",
        "print(\"myLoss:\",myLoss)\n",
        "\n",
        "evalCifar(testloader, resnet18, classes)\n",
        "\n",
        "handle.remove()\n",
        "\n",
        "##########################################################################################\n",
        "###开始训练\n",
        "print(\"##开始训练################################################################################\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device =\"cpu\"\n",
        "if device == 'cuda':\n",
        "  resnet18 = torch.nn.DataParallel(resnet18)\n",
        "  cudnn.benchmark = True\n",
        "print(device)\n",
        "resnet18 = resnet18.to(device)\n",
        "\n",
        "# trainloader\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet18.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "startEpoc = 0\n",
        "epochs = 1000\n",
        "resnet18.train()\n",
        "print(\"start training\")\n",
        "\n",
        "handle = resnet18.fc.register_forward_hook(hook2)\n",
        "\n",
        "for epoch in range(startEpoch, epochs):  # 多批次循环\n",
        "\n",
        "     resnet18.train()\n",
        "     running_loss = 0.0\n",
        "     time_start = time.time()\n",
        "     #learning rate 不变\n",
        "#     #adjust_learning_rate(optimizer, epoch, epochs, trainloader, batch_sizeV)\n",
        "     total = 0\n",
        "     correct = 0\n",
        "\n",
        "     nbdt_total = 0\n",
        "     nbdt_correct = 0\n",
        "     running_nbdtloss = 0.0\n",
        "     for i, data in enumerate(trainloader, 0):\n",
        "         # 获取输入\n",
        "         #print(epoch,i)\n",
        "         inputs, labels = data\n",
        "\n",
        "         inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "         # 梯度置0\n",
        "         optimizer.zero_grad()\n",
        "\n",
        "         # 正向传播，反向传播，优化a\n",
        "         outputs = resnet18(inputs)\n",
        "\n",
        "         loss = criterion(outputs, labels)\n",
        "\n",
        "         ###############\n",
        "         myLoss,myLabels,NBDTpredictedLabel = computeLoss(labels)\n",
        "         loss = loss+0.1*myLoss\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "\n",
        "         _, predicted = outputs.max(1)\n",
        "         total += labels.size(0)\n",
        "         correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "         nbdt_total =  total\n",
        "         nbdt_correct += NBDTpredictedLabel.eq(myLabels).sum().item()\n",
        "         #print(\"myLoss:\",myLoss)\n",
        "         #print(\"myLabels:\",myLabels)\n",
        "         #print(\"Loss:\",loss)\n",
        "         #print(\"labels:\",labels)\n",
        "         #print(\"i,epoch:\",i,epoch)\n",
        "         # 打印状态信息\n",
        "         running_loss += loss.item()\n",
        "         running_nbdtloss += myLoss.item()\n",
        "         if i % 20 == 19:  # 每200批次打印一次\n",
        "             time_end = time.time()\n",
        "             print('##########one 20 batch totally time cost %.3f' %(time_end-time_start))\n",
        "             print(\"batchIndex %d |trainLen %d | Loss: %.3f | Acc: %.3f | correct, total: (%d,%d)\" % (\n",
        "                 i, len(trainloader), running_loss/(i+1), 100.*correct/total, correct, total))\n",
        "             print(\"myLoss: %.3f | nbdt_Acc: %.3f | nbdt_correct, nbdt_total: (%d,%d)\" % (\n",
        "                 running_nbdtloss/(i+1),100.*nbdt_correct/nbdt_total, nbdt_correct, nbdt_total))\n",
        "\n",
        "     time_end = time.time()\n",
        "     print('##########epoch %d totally time cost %.3f#####################' % (epoch, time_end-time_start))\n",
        "     print(\"###################################################################\")\n",
        "\n",
        "     state = {\"net\": resnet18.state_dict(), \"optimizer\": optimizer.state_dict(), \"epoch\": epoch}\n",
        "     modelPath = \"/content/drive/MyDrive/SUMONBDT/trainedModes\"\n",
        "     modelPathNameTmp = modelPath+\"/nbdt_resnet18_\"+str(epoch)+\".modeparams\"\n",
        "     torch.save(state, modelPathNameTmp)\n",
        "     #params = torch.load(modelPathNameTmp)\n",
        "     #resnet18.load_state_dict(params[\"net\"])\n",
        "     #optimizer.load_state_dict(params[\"optimizer\"])\n",
        "     evalCifar(testloader, resnet18, classes)\n",
        "handle.remove()\n",
        "print('Finished Training')\n",
        "\n",
        "#有两种方法，一种只保存参数，一种全保存，后者简单但存储量大，我用的是前者\n",
        "# # 保存和加载整个模型\n",
        "state = {\"net\": resnet18.state_dict(), \"optimizer\": optimizer.state_dict(), \"epoch\": epoch}\n",
        "modelPath = \"/content/drive/MyDrive/SUMONBDT/trainedModes\"\n",
        "modelPathName = modelPath+\"/nbdt_resnet18_End\"+\".modeparams\"\n",
        "torch.save(state, modelPathName)\n",
        "params = torch.load(modelPathName)\n",
        "resnet18.load_state_dict(params['net'])\n",
        "optimizer.load_state_dict(params['optimizer'])\n",
        "\n",
        "# # 仅保存和加载模型参数(推荐使用)\n",
        "#torch.save(resnet18.state_dict(), './trainedModes/resnet18params.pkl')\n",
        "#resnet18.load_state_dict(torch.load('./trainedModes/resnet18params.pkl'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWSjWG0Qmpdm",
        "outputId": "8f822949-012e-4e38-f0c0-a77f743473dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SUMONBDT\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "cuda\n",
            "inputNow: tensor([[0.0000e+00, 9.2051e-03, 1.6492e-02,  ..., 0.0000e+00, 7.6941e-02,\n",
            "         2.1872e-04],\n",
            "        [0.0000e+00, 7.2865e-04, 0.0000e+00,  ..., 1.3833e-02, 2.1717e-02,\n",
            "         4.5538e-02],\n",
            "        [0.0000e+00, 0.0000e+00, 8.1566e-04,  ..., 8.5798e-02, 1.8204e-02,\n",
            "         7.6172e-02],\n",
            "        ...,\n",
            "        [2.2493e-03, 1.2862e-03, 1.6938e-02,  ..., 1.0989e-03, 3.3192e-05,\n",
            "         0.0000e+00],\n",
            "        [4.0782e-04, 8.4480e-04, 1.1421e-02,  ..., 0.0000e+00, 3.2732e-03,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 4.9688e-02,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00]], device='cuda:0', grad_fn=<CloneBackward0>)\n",
            "outputNow: tensor([[-4.1338, -3.3543, -3.1331,  ...,  0.7978, -3.2346, -3.2601],\n",
            "        [-1.5412,  2.7103, -2.4189,  ..., -1.6137,  8.6616,  0.6753],\n",
            "        [-1.5994,  4.4569, -2.4911,  ..., -1.7480,  7.2639,  1.3578],\n",
            "        ...,\n",
            "        [-4.2224, -3.4687, -2.8899,  ...,  0.6609, -3.2294, -3.3565],\n",
            "        [-4.4161, -3.5626, -3.5693,  ...,  0.9161, -3.4639, -3.5702],\n",
            "        [-3.9006, -3.0475, -3.0626,  ...,  1.1154, -2.9392, -3.0376]],\n",
            "       device='cuda:0', grad_fn=<CloneBackward0>)\n",
            "predicted: tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 6, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 1,\n",
            "        7, 6, 9, 8, 5, 3, 8, 8, 7, 7, 3, 6, 7, 4, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7, 4, 5, 6, 3, 1, 1, 3, 6, 8, 7, 4, 0, 6, 2, 1, 3, 0, 4, 2, 7,\n",
            "        8, 3, 1, 2, 8, 0, 8, 3, 3, 2, 4, 1, 8, 9, 1, 2, 9, 7, 2, 8, 6, 5, 6, 3,\n",
            "        8, 7, 6, 5, 5, 2, 8, 9, 6, 0, 0, 5, 2, 9, 3, 4, 2, 1, 6, 6, 8, 4, 8, 4,\n",
            "        5, 0, 9, 0, 9, 8, 9, 9, 3, 7, 3, 0, 0, 5, 2, 2, 3, 8, 6, 3, 4, 0, 5, 8,\n",
            "        0, 1, 7, 2, 8, 8, 7, 8, 5, 1, 8, 7, 1, 3, 0, 5, 7, 9, 7, 4, 5, 9, 8, 0,\n",
            "        7, 9, 8, 2, 7, 6, 9, 4, 3, 1, 4, 4, 3, 6, 5, 1, 3, 8, 8, 0, 4, 0, 5, 5,\n",
            "        1, 1, 8, 9, 0, 3, 1, 9, 2, 2, 5, 3, 9, 9, 4, 0, 3, 0, 0, 1, 8, 1, 5, 7,\n",
            "        0, 8, 2, 4, 7, 0, 2, 3, 6, 3, 8, 3, 0, 2, 4, 3, 9, 0, 6, 1, 0, 9, 1, 0,\n",
            "        7, 9, 1, 2, 6, 1, 3, 4, 6, 0, 0, 6, 6, 6, 3, 2, 6, 1, 8, 2, 1, 2, 8, 6,\n",
            "        0, 0, 4, 0, 7, 7, 5, 5, 3, 5, 2, 3, 4, 1, 7, 5, 4, 6, 1, 9, 3, 6, 6, 9,\n",
            "        3, 8, 2, 7, 3, 6, 2, 5, 8, 5, 4, 6, 8, 9, 9, 1, 0, 2, 2, 3, 3, 2, 8, 0,\n",
            "        9, 5, 8, 1, 9, 4, 1, 3, 4, 1, 4, 7, 9, 4, 2, 7, 0, 7, 8, 6, 6, 9, 0, 0,\n",
            "        5, 8, 7, 2, 2, 5, 1, 2, 6, 2, 9, 6, 2, 3, 0, 3, 9, 8, 7, 8, 8, 6, 0, 1,\n",
            "        8, 2, 7, 9, 3, 6, 1, 9, 0, 7, 3, 7, 4, 5, 8, 0, 2, 9, 3, 4, 0, 6, 2, 5,\n",
            "        3, 4, 3, 7, 2, 5, 3, 1, 1, 4, 9, 9, 5, 7, 5, 0, 2, 2, 2, 9, 7, 3, 9, 4,\n",
            "        4, 5, 4, 2, 5, 6, 1, 4, 3, 4, 4, 3, 7, 8, 4, 7, 8, 0, 5, 7, 6, 0, 5, 4,\n",
            "        8, 6, 8, 3, 5, 0, 9, 9, 5, 0, 1, 0, 8, 1, 1, 8, 0, 2, 2, 0, 4, 6, 5, 4,\n",
            "        9, 4, 7, 9, 9, 4, 5, 6], device='cuda:0')\n",
            "labels: tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7, 4, 5, 6, 3, 1, 1, 3, 6, 8, 7, 4, 0, 6, 2, 1, 3, 0, 4, 2, 7,\n",
            "        8, 3, 1, 2, 8, 0, 8, 3, 5, 2, 4, 1, 8, 9, 1, 2, 9, 7, 2, 9, 6, 5, 6, 3,\n",
            "        8, 7, 6, 2, 5, 2, 8, 9, 6, 0, 0, 5, 2, 9, 5, 4, 2, 1, 6, 6, 8, 4, 8, 4,\n",
            "        5, 0, 9, 9, 9, 8, 9, 9, 3, 7, 5, 0, 0, 5, 2, 2, 3, 8, 6, 3, 4, 0, 5, 8,\n",
            "        0, 1, 7, 2, 8, 8, 7, 8, 5, 1, 8, 7, 1, 3, 0, 5, 7, 9, 7, 4, 5, 9, 8, 0,\n",
            "        7, 9, 8, 2, 7, 6, 9, 4, 3, 9, 6, 4, 7, 6, 5, 1, 5, 8, 8, 0, 4, 0, 5, 5,\n",
            "        1, 1, 8, 9, 0, 3, 1, 9, 2, 2, 5, 3, 9, 9, 4, 0, 3, 0, 0, 9, 8, 1, 5, 7,\n",
            "        0, 8, 2, 4, 7, 0, 2, 3, 6, 3, 8, 5, 0, 3, 4, 3, 9, 0, 6, 1, 0, 9, 1, 0,\n",
            "        7, 9, 1, 2, 6, 9, 3, 4, 6, 0, 0, 6, 6, 6, 3, 2, 6, 1, 8, 2, 1, 6, 8, 6,\n",
            "        8, 0, 4, 0, 7, 7, 5, 5, 3, 5, 2, 3, 4, 1, 7, 5, 4, 6, 1, 9, 3, 6, 6, 9,\n",
            "        3, 8, 0, 7, 2, 6, 2, 5, 8, 5, 4, 6, 8, 9, 9, 1, 0, 2, 2, 7, 3, 2, 8, 0,\n",
            "        9, 5, 8, 1, 9, 4, 1, 3, 8, 1, 4, 7, 9, 4, 2, 7, 0, 7, 0, 6, 6, 9, 0, 9,\n",
            "        2, 8, 7, 2, 2, 5, 1, 2, 6, 2, 9, 6, 2, 3, 0, 3, 9, 8, 7, 8, 8, 4, 0, 1,\n",
            "        8, 2, 7, 9, 3, 6, 1, 9, 0, 7, 3, 7, 4, 5, 0, 0, 2, 9, 3, 4, 0, 6, 2, 5,\n",
            "        3, 7, 3, 7, 2, 5, 3, 1, 1, 4, 9, 9, 5, 7, 5, 0, 2, 2, 2, 9, 7, 3, 9, 4,\n",
            "        3, 5, 4, 6, 5, 6, 1, 4, 3, 4, 4, 3, 7, 8, 3, 7, 8, 0, 5, 7, 6, 0, 5, 4,\n",
            "        8, 6, 8, 5, 5, 9, 9, 9, 5, 0, 1, 0, 8, 1, 1, 8, 0, 2, 2, 0, 4, 6, 5, 4,\n",
            "        9, 4, 7, 9, 9, 4, 5, 6], device='cuda:0')\n",
            "myLabels: tensor([1, 2, 2, 0, 1, 1, 2, 1, 1, 2, 0, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 0, 1, 2,\n",
            "        1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 2, 0, 1, 2, 2, 1, 1, 1, 1, 1, 0, 2, 1, 2,\n",
            "        1, 1, 2, 2, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1,\n",
            "        2, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 1, 0, 1, 0, 1, 2, 2, 0, 1, 2, 1, 1, 1,\n",
            "        1, 0, 0, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 0, 1, 0, 2, 1, 0, 1, 0, 1,\n",
            "        2, 1, 2, 0, 2, 0, 2, 1, 1, 0, 1, 2, 2, 2, 2, 0, 2, 1, 0, 2, 1, 1, 1, 1,\n",
            "        2, 1, 1, 0, 1, 0, 2, 2, 1, 0, 0, 1, 0, 2, 1, 1, 0, 2, 1, 1, 2, 1, 2, 1,\n",
            "        1, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 1, 0, 0, 1, 2, 1, 1, 1, 0, 1, 2,\n",
            "        0, 2, 1, 0, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 2, 2, 0,\n",
            "        1, 2, 2, 0, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 0, 1, 0, 1, 1,\n",
            "        2, 2, 2, 2, 0, 1, 2, 2, 0, 0, 1, 1, 2, 2, 1, 0, 1, 0, 0, 2, 2, 2, 1, 1,\n",
            "        0, 2, 0, 1, 1, 0, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 0, 1, 2, 0, 2, 2, 0,\n",
            "        1, 2, 2, 0, 1, 2, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 2, 2, 0, 2, 1, 2, 1,\n",
            "        2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2,\n",
            "        1, 2, 0, 1, 0, 1, 0, 1, 2, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 1, 1, 0, 2, 0,\n",
            "        2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 0, 1, 0, 1, 0, 1, 1, 2, 0, 2,\n",
            "        0, 2, 1, 0, 0, 1, 2, 0, 1, 0, 2, 1, 0, 1, 0, 1, 2, 2, 1, 2, 2, 1, 0, 2,\n",
            "        2, 0, 1, 2, 1, 1, 2, 2, 0, 1, 1, 1, 1, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 1,\n",
            "        1, 1, 1, 1, 0, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 0, 0, 0, 0, 2, 1, 1, 2, 1,\n",
            "        1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 0, 1, 1, 1, 0, 1, 1,\n",
            "        2, 1, 2, 1, 1, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1,\n",
            "        2, 1, 1, 2, 2, 1, 1, 1], device='cuda:0')\n",
            "loss: tensor(0.2778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "myLoss: tensor(0.0969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "Accuracy of the network on the 10000 test images: 96 %\n",
            "##开始训练################################################################################\n",
            "cuda\n",
            "start training\n",
            "##########one 20 batch totally time cost 7.191\n",
            "batchIndex 19 |trainLen 98 | Loss: 0.010 | Acc: 99.785 | correct, total: (10218,10240)\n",
            "myLoss: 0.015 | nbdt_Acc: 99.873 | nbdt_correct, nbdt_total: (10227,10240)\n",
            "##########one 20 batch totally time cost 13.994\n",
            "batchIndex 39 |trainLen 98 | Loss: 0.010 | Acc: 99.771 | correct, total: (20433,20480)\n",
            "myLoss: 0.015 | nbdt_Acc: 99.897 | nbdt_correct, nbdt_total: (20459,20480)\n",
            "##########one 20 batch totally time cost 20.824\n",
            "batchIndex 59 |trainLen 98 | Loss: 0.012 | Acc: 99.704 | correct, total: (30629,30720)\n",
            "myLoss: 0.016 | nbdt_Acc: 99.880 | nbdt_correct, nbdt_total: (30683,30720)\n",
            "##########one 20 batch totally time cost 27.658\n",
            "batchIndex 79 |trainLen 98 | Loss: 0.012 | Acc: 99.705 | correct, total: (40839,40960)\n",
            "myLoss: 0.016 | nbdt_Acc: 99.866 | nbdt_correct, nbdt_total: (40905,40960)\n",
            "##########epoch 433 totally time cost 33.747#####################\n",
            "###################################################################\n",
            "Accuracy of the network on the 10000 test images: 92 %\n",
            "Accuracy of the network on the 10000 test images: 96 %\n",
            "##########one 20 batch totally time cost 7.233\n",
            "batchIndex 19 |trainLen 98 | Loss: 0.012 | Acc: 99.658 | correct, total: (10205,10240)\n",
            "myLoss: 0.016 | nbdt_Acc: 99.873 | nbdt_correct, nbdt_total: (10227,10240)\n",
            "##########one 20 batch totally time cost 14.060\n",
            "batchIndex 39 |trainLen 98 | Loss: 0.012 | Acc: 99.692 | correct, total: (20417,20480)\n",
            "myLoss: 0.017 | nbdt_Acc: 99.863 | nbdt_correct, nbdt_total: (20452,20480)\n",
            "##########one 20 batch totally time cost 20.882\n",
            "batchIndex 59 |trainLen 98 | Loss: 0.013 | Acc: 99.671 | correct, total: (30619,30720)\n",
            "myLoss: 0.017 | nbdt_Acc: 99.844 | nbdt_correct, nbdt_total: (30672,30720)\n",
            "##########one 20 batch totally time cost 27.695\n",
            "batchIndex 79 |trainLen 98 | Loss: 0.013 | Acc: 99.666 | correct, total: (40823,40960)\n",
            "myLoss: 0.018 | nbdt_Acc: 99.832 | nbdt_correct, nbdt_total: (40891,40960)\n",
            "##########epoch 434 totally time cost 33.776#####################\n",
            "###################################################################\n",
            "Accuracy of the network on the 10000 test images: 92 %\n",
            "Accuracy of the network on the 10000 test images: 96 %\n",
            "##########one 20 batch totally time cost 7.241\n",
            "batchIndex 19 |trainLen 98 | Loss: 0.019 | Acc: 99.551 | correct, total: (10194,10240)\n",
            "myLoss: 0.020 | nbdt_Acc: 99.746 | nbdt_correct, nbdt_total: (10214,10240)\n",
            "##########one 20 batch totally time cost 14.100\n",
            "batchIndex 39 |trainLen 98 | Loss: 0.019 | Acc: 99.536 | correct, total: (20385,20480)\n",
            "myLoss: 0.020 | nbdt_Acc: 99.761 | nbdt_correct, nbdt_total: (20431,20480)\n",
            "##########one 20 batch totally time cost 20.940\n",
            "batchIndex 59 |trainLen 98 | Loss: 0.018 | Acc: 99.570 | correct, total: (30588,30720)\n",
            "myLoss: 0.020 | nbdt_Acc: 99.785 | nbdt_correct, nbdt_total: (30654,30720)\n",
            "##########one 20 batch totally time cost 27.786\n",
            "batchIndex 79 |trainLen 98 | Loss: 0.017 | Acc: 99.575 | correct, total: (40786,40960)\n",
            "myLoss: 0.020 | nbdt_Acc: 99.785 | nbdt_correct, nbdt_total: (40872,40960)\n",
            "##########epoch 435 totally time cost 33.889#####################\n",
            "###################################################################\n",
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "Accuracy of the network on the 10000 test images: 96 %\n",
            "##########one 20 batch totally time cost 7.269\n",
            "batchIndex 19 |trainLen 98 | Loss: 0.017 | Acc: 99.551 | correct, total: (10194,10240)\n",
            "myLoss: 0.020 | nbdt_Acc: 99.795 | nbdt_correct, nbdt_total: (10219,10240)\n"
          ]
        }
      ]
    }
  ]
}