{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b5e90",
   "metadata": {
    "id": "48f98b91"
   },
   "outputs": [],
   "source": [
    "#mkdir /content/tmp\n",
    "#%cp -r -f -v /content/drive/MyDrive/SUMONBDT /content/tmp\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#%cd /content/drive/MyDrive/SUMONBDT\n",
    "#%cd /home/liuli/github/SUMONBDT\n",
    "#!nvidia-smi\n",
    "#用于测试oneHot\n",
    "#############################################################也是第一步，读取数据\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "#[2,3,5,9]\n",
    "x1 = [0,0,0,0]\n",
    "x2 = [0,0,0,1]\n",
    "\n",
    "x3 = [1,1,1,2]\n",
    "x4 = [1,1,1,3]\n",
    "x5 = [1,1,2,4]\n",
    "x6 = [1,1,2,5]\n",
    "x7 = [1,2,3,6]\n",
    "x8 = [1,2,3,7]\n",
    "x9 = [1,2,4,8]\n",
    "X = [x1, x2, x3,x4,x5,x6,x7,x8,x9]\n",
    "enc.fit(X)\n",
    "#print(enc.transform(X).toarray())\n",
    "\n",
    "\n",
    "########################读写CSV,并转为oneHot\n",
    "file1 = \"./trainData/dataAllSim10000.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "\n",
    "y = enc.transform(y).toarray()\n",
    "\n",
    "print(\"x.shape:\",x.shape,\"yOneHot.shape:\",y.shape)\n",
    "\n",
    "\n",
    "\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6ef5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "03c551ad",
    "outputId": "e1da57c0-4dd7-440a-bf3f-6194c50c0c1c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "################################################################第二步，训练\n",
    "#1. 核心为keras220不是pytorch\n",
    "#2. 基于hmcnf\n",
    "import model_hmcnf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "#hierarchy = [18, 80, 178, 142, 77, 4]\n",
    "hierarchy = [2,3,5,9]\n",
    "features_size = x.shape[1]\n",
    "label_size = y.shape[1]\n",
    "beta = 0.2\n",
    "dropout_rate=0.1\n",
    "relu_size=384\n",
    "\n",
    "\n",
    "\n",
    "def local_model(num_labels, dropout_rate, relu_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(num_labels, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def global_model(dropout_rate, relu_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    return model\n",
    "\n",
    "\n",
    "def sigmoid_model(label_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(label_size, activation='sigmoid',name=\"global\"))\n",
    "    return model\n",
    "\n",
    "features = layers.Input(shape=(features_size,))\n",
    "global_models = []\n",
    "local_models = []\n",
    "\n",
    "\n",
    "for i in range(len(hierarchy)):\n",
    "    if i == 0:\n",
    "        global_models.append(global_model(dropout_rate, relu_size)(features))\n",
    "    else:\n",
    "        global_models.append(global_model(dropout_rate, relu_size)(layers.concatenate([global_models[i-1], features])))\n",
    "\n",
    "p_glob = sigmoid_model(label_size)(global_models[-1])\n",
    "\n",
    "\n",
    "#显示只有全局模型的情况\n",
    "#modelTmp1 = tf.keras.Model(inputs=[features], outputs=[p_glob])\n",
    "#modelTmp1.summary()#\n",
    "#plot_model(modelTmp1, to_file='Flatten1.png', show_shapes=True)\n",
    "\n",
    "\n",
    "for i in range(len(hierarchy)):\n",
    "    local_models.append(local_model(hierarchy[i], dropout_rate, relu_size)(global_models[i]))\n",
    "    \n",
    "#显示只有局部局模型的情况(部分全局)\n",
    "p_loc = layers.concatenate(local_models)\n",
    "#modelTmp2 = tf.keras.Model(inputs=[features], outputs=[p_loc])\n",
    "#modelTmp2.summary()#\n",
    "#plot_model(modelTmp2, to_file='Flatten2.png', show_shapes=True)\n",
    "p_glob1 = layers.Lambda(lambda x: x*beta,name=\"global\")(p_glob)\n",
    "p_loc1 = layers.Lambda(lambda x: x*(1-beta),name=\"local\")(p_loc)\n",
    "\n",
    "labels = layers.add([p_glob1, p_loc1])\n",
    "\n",
    "model = tf.keras.Model(inputs=[features], outputs=[labels])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_model(model, to_file='FlattenAll.png', show_shapes=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['mae'])\n",
    "model.fit([x],[y],epochs=1000, batch_size=25600*1)\n",
    "model.save(\"hmcnf10000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c5e8680c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d7beeed",
    "outputId": "d6908600-8597-41c2-800f-afc59a088154",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data\n",
      "3.HMCNF预测模型\n",
      "validated hmcnf.h5 , 810146 good out of 844538 samples\n",
      "3.层次预测预测模型\n",
      "validated hmcnf.h5 , 840260 good out of 844538 samples\n",
      "###################################第一层，2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00    552177\n",
      "         1.0       0.99      0.99      0.99    292361\n",
      "\n",
      "    accuracy                           0.99    844538\n",
      "   macro avg       0.99      0.99      0.99    844538\n",
      "weighted avg       0.99      0.99      0.99    844538\n",
      "\n",
      "[[0.994 0.006]\n",
      " [0.007 0.993]]\n",
      "[[0.996 0.012]\n",
      " [0.004 0.988]]\n",
      "################################第二层，3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00    552177\n",
      "         1.0       0.97      0.99      0.98    268796\n",
      "         2.0       0.98      0.76      0.85     23565\n",
      "\n",
      "    accuracy                           0.99    844538\n",
      "   macro avg       0.98      0.92      0.94    844538\n",
      "weighted avg       0.99      0.99      0.99    844538\n",
      "\n",
      "[[0.995 0.005 0.   ]\n",
      " [0.005 0.994 0.001]\n",
      " [0.    0.243 0.757]]\n",
      "[[0.998 0.01  0.   ]\n",
      " [0.002 0.969 0.017]\n",
      " [0.    0.021 0.983]]\n",
      "#############################第三层，5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99    552177\n",
      "         1.0       0.93      0.94      0.93    168572\n",
      "         2.0       0.91      0.85      0.88    100224\n",
      "         3.0       0.96      0.81      0.88     16202\n",
      "         4.0       0.96      0.87      0.91      7363\n",
      "\n",
      "    accuracy                           0.96    844538\n",
      "   macro avg       0.95      0.90      0.92    844538\n",
      "weighted avg       0.96      0.96      0.96    844538\n",
      "\n",
      "[[0.998 0.002 0.001 0.    0.   ]\n",
      " [0.023 0.936 0.04  0.001 0.   ]\n",
      " [0.037 0.106 0.854 0.002 0.001]\n",
      " [0.075 0.042 0.056 0.814 0.013]\n",
      " [0.041 0.023 0.053 0.008 0.875]]\n",
      "[[0.984 0.005 0.005 0.    0.   ]\n",
      " [0.007 0.927 0.071 0.017 0.   ]\n",
      " [0.007 0.062 0.91  0.016 0.01 ]\n",
      " [0.002 0.004 0.01  0.962 0.032]\n",
      " [0.001 0.001 0.004 0.004 0.958]]\n",
      "#############################第四层，9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97    552177\n",
      "         2.0       0.92      0.87      0.90     71797\n",
      "         3.0       0.93      0.84      0.88     96775\n",
      "         4.0       0.91      0.82      0.87     80907\n",
      "         5.0       0.95      0.84      0.89     19317\n",
      "         6.0       0.98      0.80      0.88      9280\n",
      "         7.0       0.90      0.87      0.89      6922\n",
      "         8.0       0.95      0.93      0.94      7363\n",
      "\n",
      "    accuracy                           0.94    844538\n",
      "   macro avg       0.94      0.87      0.90    844538\n",
      "weighted avg       0.94      0.94      0.94    844538\n",
      "\n",
      "[[0.998 0.    0.001 0.001 0.    0.    0.    0.   ]\n",
      " [0.087 0.874 0.019 0.021 0.    0.    0.    0.   ]\n",
      " [0.097 0.025 0.836 0.035 0.001 0.    0.005 0.   ]\n",
      " [0.101 0.031 0.037 0.823 0.005 0.    0.    0.001]\n",
      " [0.108 0.01  0.009 0.028 0.836 0.004 0.001 0.003]\n",
      " [0.088 0.    0.06  0.008 0.019 0.803 0.004 0.018]\n",
      " [0.076 0.    0.016 0.008 0.021 0.    0.875 0.005]\n",
      " [0.043 0.    0.004 0.02  0.    0.    0.006 0.927]]\n",
      "[[0.952 0.001 0.005 0.008 0.    0.    0.    0.   ]\n",
      " [0.011 0.923 0.016 0.02  0.    0.    0.    0.   ]\n",
      " [0.016 0.036 0.934 0.047 0.003 0.001 0.076 0.   ]\n",
      " [0.014 0.037 0.035 0.913 0.024 0.005 0.005 0.016]\n",
      " [0.004 0.003 0.002 0.007 0.953 0.011 0.003 0.009]\n",
      " [0.001 0.    0.006 0.001 0.01  0.983 0.006 0.023]\n",
      " [0.001 0.    0.001 0.001 0.009 0.    0.904 0.005]\n",
      " [0.001 0.    0.    0.002 0.    0.    0.007 0.948]]\n"
     ]
    }
   ],
   "source": [
    "##################################################################第三步，验证\n",
    "#%cd /content/drive/MyDrive/SUMONBDT\n",
    "import model_hmcnf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#######################0.准备onehot\n",
    "enc = OneHotEncoder()\n",
    "#[2,3,5,9]\n",
    "x1 = [0,0,0,0]\n",
    "x2 = [0,0,0,1]\n",
    "\n",
    "x3 = [1,1,1,2]\n",
    "x4 = [1,1,1,3]\n",
    "x5 = [1,1,2,4]\n",
    "x6 = [1,1,2,5]\n",
    "x7 = [1,2,3,6]\n",
    "x8 = [1,2,3,7]\n",
    "x9 = [1,2,4,8]\n",
    "X = [x1, x2, x3,x4,x5,x6,x7,x8,x9]\n",
    "enc.fit(X)\n",
    "\n",
    "#######################2.准备数据\n",
    "        \n",
    "file1 = \"./trainData/dataAllSim10000.csv\"\n",
    "file1 = \"./trainData/dataAllSim.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "ylabel = y\n",
    "y = enc.transform(y).toarray()\n",
    "\n",
    "\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "#######################3.预测模型\n",
    "print(\"3.HMCNF预测模型\")\n",
    "hierarchy = [2,3,5,9]\n",
    "features_size = x.shape[1]\n",
    "label_size = y.shape[1]\n",
    "beta = 0.2\n",
    "\n",
    "model_name =\"hmcnf.h5\" \n",
    "\n",
    "model = keras.models.load_model(model_name)\n",
    "y_out = model.predict([x], batch_size=2560)\n",
    "y_predict = np.where(y_out > 0.5, 1, 0)\n",
    "\n",
    "predict_ok = np.where(np.sum(y_predict - y, axis=1) == 0, 1, 0)\n",
    "\n",
    "\n",
    "print(\"validated {} , {} good out of {} samples\".format(model_name, np.sum(predict_ok), predict_ok.shape[0]))\n",
    "del y_predict #节省内存\n",
    "del predict_ok #节省内存\n",
    "#######################3.层次预测预测模型\n",
    "print(\"3.层次预测预测模型\")\n",
    "y1 = np.where(y_out[:,0:2] > 0.5, 1, 0)\n",
    "y2 = np.where(y_out[:,2:5] > 0.5, 1, 0)\n",
    "y3 = np.where(y_out[:,5:10] > 0.5, 1, 0)\n",
    "y4 = np.where(y_out[:,10:19] > 0.5, 1, 0)\n",
    "for i in range(y4.shape[0]):\n",
    "    tmp1 = y1[i]\n",
    "    tmp2 = y2[i]\n",
    "    tmp3 = y3[i]\n",
    "    tmp4 = y4[i]\n",
    "    if sum(tmp1) == 0:\n",
    "        index=  np.argmax(tmp1)\n",
    "        y1[i,index]=1\n",
    "        \n",
    "    if sum(tmp2) == 0:\n",
    "        index=  np.argmax(tmp2)\n",
    "        y2[i,index]=1\n",
    "        \n",
    "    if sum(tmp3) == 0:\n",
    "        index=  np.argmax(tmp3)\n",
    "        y3[i,index]=1\n",
    "    \n",
    "    if sum(tmp4) == 0:\n",
    "        index=  np.argmax(tmp4)\n",
    "        y4[i,index]=1\n",
    "        #print(i,y4[i],index)\n",
    "y_predict = np.concatenate([y1,y2,y3,y4],axis=1)\n",
    "predict_ok = np.where(np.sum(y_predict - y, axis=1) == 0, 1, 0)\n",
    "print(\"validated {} , {} good out of {} samples\".format(model_name, np.sum(predict_ok), predict_ok.shape[0]))\n",
    "\n",
    "#onehot 2 label\n",
    "ypredict = enc.inverse_transform(y_predict)\n",
    "del y_predict #节省内存\n",
    "del predict_ok #节省内存\n",
    "del y1,y2,y3,y4\n",
    "#######################4.评估层次模型\n",
    "#hierarchy = [2,3,5,9]\n",
    "\n",
    "##第一层，2\n",
    "print(\"###################################第一层，2\")\n",
    "h1_yp = ypredict[:,0]\n",
    "h1_yl = ylabel[:,0]\n",
    "tmp1 = classification_report(h1_yl,h1_yp)\n",
    "tmp2 = confusion_matrix(h1_yl,h1_yp,normalize='true')\n",
    "tmp3 = confusion_matrix(h1_yl,h1_yp,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))\n",
    "\n",
    "\n",
    "##第二层，3\n",
    "print(\"################################第二层，3\")\n",
    "h2_yp = ypredict[:,1]\n",
    "h2_yl = ylabel[:,1]\n",
    "tmp1 = classification_report(h2_yl,h2_yp)\n",
    "tmp2 = confusion_matrix(h2_yl,h2_yp,normalize='true')\n",
    "tmp3 = confusion_matrix(h2_yl,h2_yp,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))\n",
    "\n",
    "\n",
    "\n",
    "##第三层，5\n",
    "print(\"#############################第三层，5\")\n",
    "h3_yp = ypredict[:,2]\n",
    "h3_yl = ylabel[:,2]\n",
    "tmp1 = classification_report(h3_yl,h3_yp)\n",
    "tmp2 = confusion_matrix(h3_yl,h3_yp,normalize='true')\n",
    "tmp3 = confusion_matrix(h3_yl,h3_yp,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))\n",
    "\n",
    "\n",
    "##第四层，9\n",
    "print(\"#############################第四层，9\")\n",
    "h4_yp = ypredict[:,3]\n",
    "h4_yl = ylabel[:,3]\n",
    "tmp1 = classification_report(h4_yl,h4_yp)\n",
    "tmp2 = confusion_matrix(h4_yl,h4_yp,normalize='true')\n",
    "tmp3 = confusion_matrix(h4_yl,h4_yp,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b4c180a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy [0.952, 0.923, 0.934, 0.913]\n",
      "[1000. 1000. 1000. 1000.]\n",
      "[[952.   4.  15.   8.]\n",
      " [ 18. 923.  16.  32.]\n",
      " [ 16.  36. 934.  47.]\n",
      " [ 14.  37.  35. 913.]]\n",
      "最佳合并点和矩阵 2 [0.0515]\n",
      "[[ 952.    4.   23.]\n",
      " [  18.  923.   48.]\n",
      " [  30.   73. 1929.]]\n",
      "最佳合并点和矩阵 1 [0.068]\n",
      "[[ 952.   27.]\n",
      " [  48. 2973.]]\n",
      "[[0.952 0.009]\n",
      " [0.048 0.991]]\n",
      "\n",
      "\n",
      "\n",
      "###################################################\n",
      "\n",
      "\n",
      "\n",
      " 用第5层数据进行分析\n",
      "[[550806    893    478      0      0]\n",
      " [  3880 157781   6680    231      0]\n",
      " [  3716  10625  85590    223     70]\n",
      " [  1221    683    900  13184    214]\n",
      " [   300    168    393     60   6442]]\n",
      "[559923 170150  94041  13698   6726]\n",
      "[[0.984 0.005 0.005 0.    0.   ]\n",
      " [0.007 0.927 0.071 0.017 0.   ]\n",
      " [0.007 0.062 0.91  0.016 0.01 ]\n",
      " [0.002 0.004 0.01  0.962 0.032]\n",
      " [0.001 0.001 0.004 0.004 0.958]]\n",
      "\n",
      "\n",
      "\n",
      "5->4,最佳合并点和矩阵 1 [0.07656029]\n",
      "[[5.50806e+05 1.37100e+03 0.00000e+00 0.00000e+00]\n",
      " [7.59600e+03 2.60676e+05 4.54000e+02 7.00000e+01]\n",
      " [1.22100e+03 1.58300e+03 1.31840e+04 2.14000e+02]\n",
      " [3.00000e+02 5.61000e+02 6.00000e+01 6.44200e+03]]\n",
      "[[0.984 0.005 0.    0.   ]\n",
      " [0.014 0.987 0.033 0.01 ]\n",
      " [0.002 0.006 0.962 0.032]\n",
      " [0.001 0.002 0.004 0.958]]\n",
      "\n",
      "\n",
      "\n",
      "4->3,最佳合并点和矩阵 1 [0.0303554]\n",
      "[[5.50806e+05 1.37100e+03 0.00000e+00]\n",
      " [8.81700e+03 2.75897e+05 2.84000e+02]\n",
      " [3.00000e+02 6.21000e+02 6.44200e+03]]\n",
      "[[0.984 0.005 0.   ]\n",
      " [0.016 0.993 0.042]\n",
      " [0.001 0.002 0.958]]\n",
      "\n",
      "\n",
      "\n",
      "3->2,最佳合并点和矩阵 1 [0.03740717]\n",
      "[[550806.   1371.]\n",
      " [  9117. 283244.]]\n",
      "[[0.984 0.005]\n",
      " [0.016 0.995]]\n"
     ]
    }
   ],
   "source": [
    "#第四步，根据混淆矩阵进行聚类。第一列代表识别为类别1的样本真实的类别分布\n",
    "import numpy as np\n",
    "import copy\n",
    "#########################################手动准备模拟数据\n",
    "mat1 = np.array([[0.952,0.004,0.015,0.008],\n",
    " [0.018,0.923,0.016,0.032],\n",
    " [0.016,0.036,0.934,0.047],\n",
    " [0.014,0.037,0.035,0.913]])\n",
    "accy = [mat1[0,0],mat1[1,1],mat1[2,2],mat1[3,3]]\n",
    "print(\"accuracy\",accy)\n",
    "matT1 = mat1\n",
    "mat1[:,0] = matT1[:,0]*1000\n",
    "mat1[:,1] = matT1[:,1]*1000\n",
    "mat1[:,2] = matT1[:,2]*1000\n",
    "mat1[:,3] = matT1[:,3]*1000\n",
    "sumTmp =  sum(mat1)\n",
    "print(sumTmp)\n",
    "print(mat1)\n",
    "\n",
    "##########################################计算最佳合并位置，根据最大的正确率提高\n",
    "def computeAccuracyDiff(mat1,accy):\n",
    "    h,w = mat1.shape\n",
    "    tmp = np.zeros((h-1,w-1))\n",
    "    matTmp={}\n",
    "    ##从0到最后，行列合并\n",
    "    for index in range(h-1):\n",
    "\n",
    "        tmp = np.zeros((h-1,w))\n",
    "        num = 0\n",
    "        ####行合并\n",
    "        for i in range(h):#行合并\n",
    "            if i == index:\n",
    "                tmp[num]=mat1[i]+mat1[i+1]\n",
    "                num=num+1\n",
    "                continue\n",
    "            if i== index+1:\n",
    "                continue\n",
    "\n",
    "            tmp[num]=mat1[i]\n",
    "            num=num+1\n",
    "\n",
    "        ####列合并   \n",
    "        mat2=tmp\n",
    "        tmp = np.zeros((h-1,w-1))\n",
    "        num = 0\n",
    "        for j in range(w):#列合并\n",
    "            if j == index:\n",
    "                tmp[:,num] = mat2[:,j]+mat2[:,j+1]\n",
    "                num=num+1\n",
    "                continue\n",
    "            if j== index+1:\n",
    "                continue\n",
    "\n",
    "            tmp[:,num] = mat2[:,j]\n",
    "            num=num+1\n",
    "        matTmp[index] = tmp\n",
    "        \n",
    "        #print(\"合并后的所有矩阵\")\n",
    "        #print(index,matTmp[index])#合并后的所有矩阵\n",
    "    matTmp1 = copy.deepcopy(matTmp)\n",
    "   \n",
    "    ##归一化   \n",
    "    maxDiffMat = np.zeros((len(matTmp),1))\n",
    "    for i in range(len(matTmp)):\n",
    "        tmp = matTmp[i]\n",
    "        sumTmp =  sum(tmp)\n",
    "        for j in range(tmp.shape[1]):\n",
    "            tmp[:,j] = tmp[:,j]/(sumTmp[j])\n",
    "\n",
    "        accyNow = tmp[i,i]\n",
    "        maxDiffMat[i]= max(accyNow-accy[i],accyNow-accy[i+1])\n",
    "    maxIndex = np.argmax(maxDiffMat)\n",
    "    maxDiff = max(maxDiffMat)\n",
    "    #print(matTmp1)\n",
    "    return maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1\n",
    "\n",
    "#为了思考，不用for循环，直接一步一步做\n",
    "#4到3\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(matTmp1[maxIndex])\n",
    "\n",
    "#3到2\n",
    "mat3to2=matTmp1[maxIndex]\n",
    "accy3to2 = [matTmp[maxIndex][0,0],matTmp[maxIndex][1,1],matTmp[maxIndex][2,2]]\n",
    "maxIndex3to2,maxDiff3to2,maxDiffMat3to2,matTmp3to2,matTmp3to2Origin =computeAccuracyDiff(mat3to2,accy3to2)\n",
    "chosedMat = matTmp3to2Origin[maxIndex3to2]\n",
    "print(\"最佳合并点和矩阵\",maxIndex3to2,maxDiff3to2)\n",
    "print(matTmp3to2Origin[maxIndex3to2])\n",
    "print(matTmp3to2[maxIndex3to2])\n",
    "\n",
    "\n",
    "#########################################采用数据进行分析\n",
    "print(\"\\n\\n\\n###################################################\")\n",
    "print(\"\\n\\n\\n 用第5层数据进行分析\")\n",
    "h3_yp = ypredict[:,2]\n",
    "h3_yl = ylabel[:,2]\n",
    "mat1 = confusion_matrix(h3_yl,h3_yp)\n",
    "p1 = confusion_matrix(h3_yl,h3_yp,normalize='pred')\n",
    "sumTmp = sum(mat1)\n",
    "print(mat1)\n",
    "print(sumTmp)\n",
    "print(np.around(p1, decimals=3))\n",
    "\n",
    "########5->4\n",
    "accy = [p1[0,0],p1[1,1],p1[2,2],p1[3,3],p1[4,4]]\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n5->4,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(matTmp1[maxIndex])\n",
    "print(np.around(matTmp[maxIndex], decimals=3))\n",
    "\n",
    "########4->3\n",
    "mat1=matTmp1[maxIndex]\n",
    "accy= [matTmp[maxIndex][0,0],matTmp[maxIndex][1,1],matTmp[maxIndex][2,2],matTmp[maxIndex][3,3]]\n",
    "\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n4->3,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(matTmp1[maxIndex])\n",
    "print(np.around(matTmp[maxIndex], decimals=3))\n",
    "\n",
    "\n",
    "########3->2\n",
    "mat1=matTmp1[maxIndex]\n",
    "accy= [matTmp[maxIndex][0,0],matTmp[maxIndex][1,1],matTmp[maxIndex][2,2]]\n",
    "\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n3->2,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(matTmp1[maxIndex])\n",
    "print(np.around(matTmp[maxIndex], decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b0c1c230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[550806    893    478      0      0]\n",
      " [  3880 157781   6680    231      0]\n",
      " [  3716  10625  85590    223     70]\n",
      " [  1221    683    900  13184    214]\n",
      " [   300    168    393     60   6442]]\n",
      "[559923 170150  94041  13698   6726]\n",
      "[[0.984 0.005 0.005 0.    0.   ]\n",
      " [0.007 0.927 0.071 0.017 0.   ]\n",
      " [0.007 0.062 0.91  0.016 0.01 ]\n",
      " [0.002 0.004 0.01  0.962 0.032]\n",
      " [0.001 0.001 0.004 0.004 0.958]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-995cee727ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cls' is not defined"
     ]
    }
   ],
   "source": [
    "h3_yp = ypredict[:,2]\n",
    "h3_yl = ylabel[:,2]\n",
    "o1 = confusion_matrix(h3_yl,h3_yp)\n",
    "p1 = confusion_matrix(h3_yl,h3_yp,normalize='pred')\n",
    "print(o1)\n",
    "print(sum(o1))\n",
    "print(np.around(p1, decimals=3))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mainTestCSVMLP3(hmcnf_keras).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:keras220CpuJupyter]",
   "language": "python",
   "name": "conda-env-keras220CpuJupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
