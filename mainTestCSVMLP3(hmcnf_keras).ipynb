{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d3282",
   "metadata": {
    "id": "48f98b91"
   },
   "outputs": [],
   "source": [
    "#mkdir /content/tmp\n",
    "#%cp -r -f -v /content/drive/MyDrive/SUMONBDT /content/tmp\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#%cd /content/drive/MyDrive/SUMONBDT\n",
    "#%cd /home/liuli/github/SUMONBDT\n",
    "#!nvidia-smi\n",
    "#用于测试oneHot\n",
    "#############################################################也是第一步，读取数据\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "#[2,3,5,9]\n",
    "x1 = [0,0,0,0]\n",
    "x2 = [0,0,0,1]\n",
    "\n",
    "x3 = [1,1,1,2]\n",
    "x4 = [1,1,1,3]\n",
    "x5 = [1,1,2,4]\n",
    "x6 = [1,1,2,5]\n",
    "x7 = [1,2,3,6]\n",
    "x8 = [1,2,3,7]\n",
    "x9 = [1,2,4,8]\n",
    "X = [x1, x2, x3,x4,x5,x6,x7,x8,x9]\n",
    "enc.fit(X)\n",
    "#print(enc.transform(X).toarray())\n",
    "\n",
    "\n",
    "########################读写CSV,并转为oneHot\n",
    "file1 = \"./trainData/dataAllSim1000.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "ylabel = y\n",
    "y = enc.transform(y).toarray()\n",
    "\n",
    "print(\"x.shape:\",x.shape,\"yOneHot.shape:\",y.shape)\n",
    "\n",
    "\n",
    "\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac75196c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "03c551ad",
    "outputId": "e1da57c0-4dd7-440a-bf3f-6194c50c0c1c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "################################################################第二步，训练\n",
    "#1. 核心为keras220不是pytorch\n",
    "#2. 基于hmcnf\n",
    "import model_hmcnf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "#hierarchy = [18, 80, 178, 142, 77, 4]\n",
    "hierarchy = [2,3,5,9]\n",
    "features_size = x.shape[1]\n",
    "label_size = y.shape[1]\n",
    "beta = 0.2\n",
    "dropout_rate=0.1\n",
    "relu_size=384\n",
    "\n",
    "\n",
    "\n",
    "def local_model(num_labels, dropout_rate, relu_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(num_labels, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def global_model(dropout_rate, relu_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    return model\n",
    "\n",
    "\n",
    "def sigmoid_model(label_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(label_size, activation='sigmoid',name=\"global\"))\n",
    "    return model\n",
    "\n",
    "features = layers.Input(shape=(features_size,))\n",
    "global_models = []\n",
    "local_models = []\n",
    "\n",
    "\n",
    "for i in range(len(hierarchy)):\n",
    "    if i == 0:\n",
    "        global_models.append(global_model(dropout_rate, relu_size)(features))\n",
    "    else:\n",
    "        global_models.append(global_model(dropout_rate, relu_size)(layers.concatenate([global_models[i-1], features])))\n",
    "\n",
    "p_glob = sigmoid_model(label_size)(global_models[-1])\n",
    "\n",
    "\n",
    "#显示只有全局模型的情况\n",
    "#modelTmp1 = tf.keras.Model(inputs=[features], outputs=[p_glob])\n",
    "#modelTmp1.summary()#\n",
    "#plot_model(modelTmp1, to_file='Flatten1.png', show_shapes=True)\n",
    "\n",
    "\n",
    "for i in range(len(hierarchy)):\n",
    "    local_models.append(local_model(hierarchy[i], dropout_rate, relu_size)(global_models[i]))\n",
    "    \n",
    "#显示只有局部局模型的情况(部分全局)\n",
    "p_loc = layers.concatenate(local_models)\n",
    "#modelTmp2 = tf.keras.Model(inputs=[features], outputs=[p_loc])\n",
    "#modelTmp2.summary()#\n",
    "#plot_model(modelTmp2, to_file='Flatten2.png', show_shapes=True)\n",
    "p_glob1 = layers.Lambda(lambda x: x*beta,name=\"global\")(p_glob)\n",
    "p_loc1 = layers.Lambda(lambda x: x*(1-beta),name=\"local\")(p_loc)\n",
    "\n",
    "labels = layers.add([p_glob1, p_loc1])\n",
    "\n",
    "model = tf.keras.Model(inputs=[features], outputs=[labels])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_model(model, to_file='FlattenAll.png', show_shapes=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['mae'])\n",
    "model.fit([x],[y],epochs=1000, batch_size=25600*1)\n",
    "model.save(\"hmcnf10000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379775a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d7beeed",
    "outputId": "d6908600-8597-41c2-800f-afc59a088154",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##################################################################第三步，验证\n",
    "#%cd /content/drive/MyDrive/SUMONBDT\n",
    "import model_hmcnf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#######################0.准备onehot\n",
    "enc = OneHotEncoder()\n",
    "#[2,3,5,9]\n",
    "x1 = [0,0,0,0]\n",
    "x2 = [0,0,0,1]\n",
    "\n",
    "x3 = [1,1,1,2]\n",
    "x4 = [1,1,1,3]\n",
    "x5 = [1,1,2,4]\n",
    "x6 = [1,1,2,5]\n",
    "x7 = [1,2,3,6]\n",
    "x8 = [1,2,3,7]\n",
    "x9 = [1,2,4,8]\n",
    "X = [x1, x2, x3,x4,x5,x6,x7,x8,x9]\n",
    "enc.fit(X)\n",
    "\n",
    "#######################2.准备数据\n",
    "        \n",
    "file1 = \"./trainData/dataAllSim10000.csv\"\n",
    "file1 = \"./trainData/dataAllSim.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "ylabel = y\n",
    "y = enc.transform(y).toarray()\n",
    "\n",
    "\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "#######################3.预测模型\n",
    "print(\"3.HMCNF预测模型\")\n",
    "hierarchy = [2,3,5,9]\n",
    "features_size = x.shape[1]\n",
    "label_size = y.shape[1]\n",
    "beta = 0.2\n",
    "\n",
    "model_name =\"hmcnf.h5\" \n",
    "\n",
    "model = keras.models.load_model(model_name)\n",
    "y_out = model.predict([x], batch_size=2560)\n",
    "y_predict = np.where(y_out > 0.5, 1, 0)\n",
    "\n",
    "predict_ok = np.where(np.sum(y_predict - y, axis=1) == 0, 1, 0)\n",
    "\n",
    "\n",
    "print(\"validated {} , {} good out of {} samples\".format(model_name, np.sum(predict_ok), predict_ok.shape[0]))\n",
    "del y_predict #节省内存\n",
    "del predict_ok #节省内存\n",
    "#######################3.层次预测预测模型\n",
    "print(\"3.层次预测预测模型\")\n",
    "y1 = np.where(y_out[:,0:2] > 0.5, 1, 0)\n",
    "y2 = np.where(y_out[:,2:5] > 0.5, 1, 0)\n",
    "y3 = np.where(y_out[:,5:10] > 0.5, 1, 0)\n",
    "y4 = np.where(y_out[:,10:19] > 0.5, 1, 0)\n",
    "for i in range(y4.shape[0]):\n",
    "    tmp1 = y1[i]\n",
    "    tmp2 = y2[i]\n",
    "    tmp3 = y3[i]\n",
    "    tmp4 = y4[i]\n",
    "    if sum(tmp1) == 0:\n",
    "        index=  np.argmax(tmp1)\n",
    "        y1[i,index]=1\n",
    "        \n",
    "    if sum(tmp2) == 0:\n",
    "        index=  np.argmax(tmp2)\n",
    "        y2[i,index]=1\n",
    "        \n",
    "    if sum(tmp3) == 0:\n",
    "        index=  np.argmax(tmp3)\n",
    "        y3[i,index]=1\n",
    "    \n",
    "    if sum(tmp4) == 0:\n",
    "        index=  np.argmax(tmp4)\n",
    "        y4[i,index]=1\n",
    "        #print(i,y4[i],index)\n",
    "y_predict = np.concatenate([y1,y2,y3,y4],axis=1)\n",
    "predict_ok = np.where(np.sum(y_predict - y, axis=1) == 0, 1, 0)\n",
    "print(\"validated {} , {} good out of {} samples\".format(model_name, np.sum(predict_ok), predict_ok.shape[0]))\n",
    "\n",
    "#onehot 2 label\n",
    "ypredict = enc.inverse_transform(y_predict)\n",
    "del y_predict #节省内存\n",
    "del predict_ok #节省内存\n",
    "del y1,y2,y3,y4\n",
    "#######################4.评估层次模型\n",
    "#hierarchy = [2,3,5,9]\n",
    "\n",
    "##第一层，2\n",
    "print(\"###################################第一层，2\")\n",
    "h1_yp = ypredict[:,0]\n",
    "h1_yl = ylabel[:,0]\n",
    "tmp1 = classification_report(h1_yl,h1_yp)\n",
    "tmp2 = confusion_matrix(h1_yl,h1_yp,normalize='true')\n",
    "tmp3 = confusion_matrix(h1_yl,h1_yp,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))\n",
    "\n",
    "\n",
    "##第二层，3\n",
    "print(\"################################第二层，3\")\n",
    "h2_yp = ypredict[:,1]\n",
    "h2_yl = ylabel[:,1]\n",
    "tmp1 = classification_report(h2_yl,h2_yp)\n",
    "tmp2 = confusion_matrix(h2_yl,h2_yp,normalize='true')\n",
    "tmp3 = confusion_matrix(h2_yl,h2_yp,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))\n",
    "\n",
    "\n",
    "\n",
    "##第三层，5\n",
    "print(\"#############################第三层，5\")\n",
    "h3_yp = ypredict[:,2]\n",
    "h3_yl = ylabel[:,2]\n",
    "tmp1 = classification_report(h3_yl,h3_yp)\n",
    "tmp2 = confusion_matrix(h3_yl,h3_yp,normalize='true')\n",
    "tmp3 = confusion_matrix(h3_yl,h3_yp,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))\n",
    "\n",
    "\n",
    "##第四层，9\n",
    "print(\"#############################第四层，9\")\n",
    "h4_yp = ypredict[:,3]\n",
    "h4_yl = ylabel[:,3]\n",
    "tmp1 = classification_report(h4_yl,h4_yp)\n",
    "tmp2 = confusion_matrix(h4_yl,h4_yp,normalize='true')\n",
    "tmp3 = confusion_matrix(h4_yl,h4_yp,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第四步，根据混淆矩阵进行聚类。第一列代表识别为类别1的样本真实的类别分布\n",
    "import numpy as np\n",
    "import copy\n",
    "#########################################手动准备模拟数据\n",
    "mat1 = np.array([[0.952,0.004,0.015,0.008],\n",
    " [0.018,0.923,0.016,0.032],\n",
    " [0.016,0.036,0.934,0.047],\n",
    " [0.014,0.037,0.035,0.913]])\n",
    "accy = [mat1[0,0],mat1[1,1],mat1[2,2],mat1[3,3]]\n",
    "print(\"accuracy\",accy)\n",
    "matT1 = mat1\n",
    "mat1[:,0] = matT1[:,0]*1000\n",
    "mat1[:,1] = matT1[:,1]*1000\n",
    "mat1[:,2] = matT1[:,2]*1000\n",
    "mat1[:,3] = matT1[:,3]*1000\n",
    "sumTmp =  sum(mat1)\n",
    "print(sumTmp)\n",
    "print(mat1)\n",
    "\n",
    "##########################################计算最佳合并位置，根据最大的正确率提高\n",
    "def computeAccuracyDiff(mat1,accy):\n",
    "    h,w = mat1.shape\n",
    "    tmp = np.zeros((h-1,w-1))\n",
    "    matTmp={}\n",
    "    ##从0到最后，行列合并\n",
    "    for index in range(h-1):\n",
    "\n",
    "        tmp = np.zeros((h-1,w))\n",
    "        num = 0\n",
    "        ####行合并\n",
    "        for i in range(h):#行合并\n",
    "            if i == index:\n",
    "                tmp[num]=mat1[i]+mat1[i+1]\n",
    "                num=num+1\n",
    "                continue\n",
    "            if i== index+1:\n",
    "                continue\n",
    "\n",
    "            tmp[num]=mat1[i]\n",
    "            num=num+1\n",
    "\n",
    "        ####列合并   \n",
    "        mat2=tmp\n",
    "        tmp = np.zeros((h-1,w-1))\n",
    "        num = 0\n",
    "        for j in range(w):#列合并\n",
    "            if j == index:\n",
    "                tmp[:,num] = mat2[:,j]+mat2[:,j+1]\n",
    "                num=num+1\n",
    "                continue\n",
    "            if j== index+1:\n",
    "                continue\n",
    "\n",
    "            tmp[:,num] = mat2[:,j]\n",
    "            num=num+1\n",
    "        matTmp[index] = tmp\n",
    "        \n",
    "        #print(\"合并后的所有矩阵\")\n",
    "        #print(index,matTmp[index])#合并后的所有矩阵\n",
    "    matTmp1 = copy.deepcopy(matTmp)\n",
    "   \n",
    "    ##归一化   \n",
    "    maxDiffMat = np.zeros((len(matTmp),1))\n",
    "    for i in range(len(matTmp)):\n",
    "        tmp = matTmp[i]\n",
    "        sumTmp =  sum(tmp)\n",
    "        for j in range(tmp.shape[1]):\n",
    "            tmp[:,j] = tmp[:,j]/(sumTmp[j])\n",
    "\n",
    "        accyNow = tmp[i,i]\n",
    "        maxDiffMat[i]= max(accyNow-accy[i],accyNow-accy[i+1])\n",
    "    maxIndex = np.argmax(maxDiffMat)\n",
    "    maxDiff = max(maxDiffMat)\n",
    "    #print(matTmp1)\n",
    "    return maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1\n",
    "\n",
    "#为了思考，不用for循环，直接一步一步做\n",
    "#4到3\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(matTmp1[maxIndex])\n",
    "\n",
    "#3到2\n",
    "mat3to2=matTmp1[maxIndex]\n",
    "accy3to2 = [matTmp[maxIndex][0,0],matTmp[maxIndex][1,1],matTmp[maxIndex][2,2]]\n",
    "maxIndex3to2,maxDiff3to2,maxDiffMat3to2,matTmp3to2,matTmp3to2Origin =computeAccuracyDiff(mat3to2,accy3to2)\n",
    "chosedMat = matTmp3to2Origin[maxIndex3to2]\n",
    "print(\"最佳合并点和矩阵\",maxIndex3to2,maxDiff3to2)\n",
    "print(matTmp3to2Origin[maxIndex3to2])\n",
    "print(matTmp3to2[maxIndex3to2])\n",
    "\n",
    "\n",
    "#########################################采用数据进行分析\n",
    "print(\"\\n\\n\\n###################################################\")\n",
    "print(\"\\n\\n\\n 用第5层数据进行分析\")\n",
    "h3_yp = ypredict[:,2]\n",
    "h3_yl = ylabel[:,2]\n",
    "mat1 = confusion_matrix(h3_yl,h3_yp)\n",
    "p1 = confusion_matrix(h3_yl,h3_yp,normalize='pred')\n",
    "sumTmp = sum(mat1)\n",
    "print(mat1)\n",
    "print(sumTmp)\n",
    "print(np.around(p1, decimals=3))\n",
    "\n",
    "########5->4\n",
    "accy = [p1[0,0],p1[1,1],p1[2,2],p1[3,3],p1[4,4]]\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n5->4,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(matTmp1[maxIndex])\n",
    "print(np.around(matTmp[maxIndex], decimals=3))\n",
    "\n",
    "########4->3\n",
    "mat1=matTmp1[maxIndex]\n",
    "accy= [matTmp[maxIndex][0,0],matTmp[maxIndex][1,1],matTmp[maxIndex][2,2],matTmp[maxIndex][3,3]]\n",
    "\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n4->3,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(matTmp1[maxIndex])\n",
    "print(np.around(matTmp[maxIndex], decimals=3))\n",
    "\n",
    "\n",
    "########3->2\n",
    "mat1=matTmp1[maxIndex]\n",
    "accy= [matTmp[maxIndex][0,0],matTmp[maxIndex][1,1],matTmp[maxIndex][2,2]]\n",
    "\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n3->2,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(matTmp1[maxIndex])\n",
    "print(np.around(matTmp[maxIndex], decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "##测试最简注意力机制，Attention Channel ,SEAttention\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils.vis_utils import plot_model\n",
    "np.random.seed(1337)  # for reproducibility\n",
    " \n",
    "from keras.models import *\n",
    "from keras.layers import Input, Dense,Multiply,Activation\n",
    " \n",
    "input_dim = 4\n",
    "\n",
    "\n",
    "def get_data(n, input_dim, attention_column=1):\n",
    "\n",
    "    x = np.random.standard_normal(size=(n, input_dim))\n",
    "    y = np.random.randint(low=0, high=2, size=(n, 1))\n",
    "    x[:, attention_column] = y[:, 0]\n",
    "    return x, y\n",
    "\n",
    " \n",
    " \n",
    "def Att(att_dim,inputs,name):\n",
    "    V = inputs\n",
    "    QK = Dense(att_dim,bias=None)(inputs)\n",
    "    QK = Activation(\"softmax\",name=name)(QK)\n",
    "    MV = Multiply()([V, QK])\n",
    "    return(MV)\n",
    " \n",
    " \n",
    "def build_model():\n",
    "    inputs = Input(shape=(input_dim,))\n",
    " \n",
    "    atts1 = Att(input_dim,inputs,\"attention_vec\")\n",
    " \n",
    "    x = Dense(16)(atts1)\n",
    "    atts2 = Att(16,x,\"attention_vec1\")\n",
    " \n",
    " \n",
    "    output = Dense(1, activation='sigmoid')(atts2)\n",
    "    model = Model(input=inputs, output=output)\n",
    "    return model\n",
    "\n",
    "N = 10000\n",
    "inputs_1, outputs = get_data(N, input_dim) \n",
    "print(inputs_1)\n",
    " \n",
    "m = build_model()\n",
    "plot_model(m, to_file='attMap.png', show_shapes=True)\n",
    "#m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#print(m.summary())\n",
    "#m.fit(inputs_1, outputs, epochs=20, batch_size=128, validation_split=0.2)testing_inputs_1, testing_outputs = get_data(1, input_dim)\n",
    "\n",
    "\n",
    "#原文链接：https://blog.csdn.net/xiaosongshine/article/details/90579679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ae673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://blog.csdn.net/SKIp121whats112/article/details/122265766\n",
    "#https://scikit-learn.org/stable/modules/tree.html\n",
    "##############测试决策树\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "Input= x\n",
    "Output = ylabel[:,2]\n",
    "print(x)\n",
    "print(Output)\n",
    "dt = tree.DecisionTreeClassifier(max_depth=5,min_samples_split=100,min_samples_leaf=100,min_impurity_decrease=0.001)\n",
    "dt = dt.fit(Input, Output)\n",
    "tree.plot_tree(dt)\n",
    "data=tree.export_graphviz(dt, out_file=None,class_names=['0','1','2','3','4'],filled=True) \n",
    "graph = graphviz.Source(data)\n",
    "graph.render(\"now\")\n",
    "\n",
    "data=tree.export_graphviz(dt, out_file=None,class_names=['0','1','2','3','4'],filled=True,proportion=True) \n",
    "graph = graphviz.Source(data)\n",
    "graph.render(\"nowPercent\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "OutPredict = dt.predict(Input)\n",
    "\n",
    "tmp1 = classification_report(Output,OutPredict )\n",
    "tmp2 = confusion_matrix(Output,OutPredict ,normalize='true')\n",
    "tmp3 = confusion_matrix(Output,OutPredict ,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31034f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试决策树的特征\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "###测试权重\n",
    "nSamples =5000\n",
    "input_dim = 10\n",
    "#x = np.random.standard_normal(size=(nSamples, input_dim))\n",
    "x = np.random.randint(low=0, high=10, size=(nSamples, input_dim))\n",
    "y1 = np.zeros((nSamples, 1))#>50\n",
    "y1A = np.zeros((nSamples, 1))#>50 and <60\n",
    "y1B = np.zeros((nSamples, 1))#>=60\n",
    "sumX = np.sum(x,axis=1)\n",
    "index=np.where(sumX>40)\n",
    "y1[index]=1\n",
    "index=np.where((sumX>50)& (sumX<70))\n",
    "y1A[index]=1\n",
    "index=np.where(sumX>=70)\n",
    "y1B[index]=1\n",
    "\n",
    "##数据来源2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "file1 = \"./trainData/dataAllSim1000.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "xyData = np.array(xyDataTmp)\n",
    "nSamples, nDims= xyData.shape\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "ylabel = y\n",
    "y1= y[:,0]\n",
    "\n",
    "\n",
    "##################################################################\n",
    "#测试决策树\n",
    "def dtFitAndSave(x,y,class_names1,saveName):\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=7,min_samples_split=100,min_samples_leaf=100,min_impurity_split=0.06,ccp_alpha=0.001)\n",
    "    dt = dt.fit(x, y)\n",
    "    tree.plot_tree(dt)\n",
    "    data=tree.export_graphviz(dt, out_file=None,class_names=class_names1,filled=True) \n",
    "    graph = graphviz.Source(data)\n",
    "    graph.render(saveName)\n",
    "    \n",
    "    yPredict = dt.predict(x)\n",
    "    tmp1 = classification_report(y,yPredict)\n",
    "    print(tmp1)\n",
    "    text_representation = tree.export_text(dt)\n",
    "    #print(text_representation)\n",
    "    #yPredict = dt.predict_proba(x)\n",
    "    #index = np.where((yPredict[:,1]<0.98)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.90)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.80)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.70)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    \n",
    "    yPredict = dt.predict_proba(x[0:3,:])\n",
    "    print(yPredict[:,1])\n",
    "    d_path = dt.decision_path(x[0:3,:]).todense()\n",
    "    print(d_path)\n",
    "    print(\"impurity\",dt.tree_.impurity)\n",
    "    print(\"feature\",dt.tree_.feature)\n",
    "    print(\"threshold\",dt.tree_.threshold)\n",
    "    \n",
    "    #左节点编号  :  clf.tree_.children_left\n",
    "    #右节点编号  :  clf.tree_.children_right\n",
    "    #分割的变量  :  clf.tree_.feature\n",
    "    #分割的阈值  :  clf.tree_.threshold\n",
    "    #不纯度(gini) :  clf.tree_.impurity\n",
    "    #样本个数      :  clf.tree_.n_node_samples\n",
    "    #样本分布      :  clf.tree_.value\n",
    "    #https://blog.csdn.net/ywj_1991/article/details/122985778\n",
    "    #https://www.javaroad.cn/questions/54003\n",
    "\n",
    "    w,h = d_path.shape\n",
    "    for i in range(h):\n",
    "       path = d_path[i]\n",
    "       v,ind = np.where(path>0)\n",
    "       xtmp = x[i]\n",
    "       #print(\"path\",path,ind,np.array(ind)[-1])\n",
    "    \n",
    "       print(\"\\n index\",index)\n",
    "       print(\"impurity\",dt.tree_.impurity[ind])\n",
    "       print(\"feature\",dt.tree_.feature[ind])\n",
    "       print(\"threshold\",dt.tree_.threshold[ind])\n",
    "       print(\"x[index]\",xtmp[ind])\n",
    "       \n",
    "      \n",
    "       print(\"the leaf node:\",np.array(ind)[-1],\"the simplest rule is\")\n",
    "       for jj in ind:\n",
    "           if dt.tree_.feature[jj] == -2:\n",
    "                print(\"label,proba is\",yPredict[i,0],yPredict[i,1])\n",
    "                break\n",
    "                \n",
    "           if xtmp[jj]<=dt.tree_.threshold[jj]:\n",
    "              print(\" x[%d]<=%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "           else:\n",
    "              print(\" x[%d]>%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "                    \n",
    "       finalPos = np.array(ind)[-1]\n",
    "       print(dt.tree_.impurity[finalPos])\n",
    "       print(dt.tree_.feature[finalPos])\n",
    "       print(dt.tree_.threshold[finalPos])\n",
    "\n",
    "dtFitAndSave(x,y1,[\"0\",\"1\"],\"bigger\")\n",
    "\n",
    "###################################################################################\n",
    "#测试神经网络\n",
    "def kerasFitAndSave(x,y,num_labels):\n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 384\n",
    "    dropout_rate =0.1\n",
    "    models=[]\n",
    "    \n",
    "    build_model = tf.keras.Sequential()\n",
    "   \n",
    "    build_model.add(layers.Dense(relu_size, activation='relu',name=\"layer1\",input_shape=(features_size,)))\n",
    "    build_model.add(layers.Dropout(dropout_rate,name=\"Dropout1-2\"))\n",
    "    build_model.add(layers.Dense(num_labels, activation='sigmoid',name=\"layer2\"))\n",
    "    \n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    plot_model(build_model, to_file='AKeras.png', show_shapes=True)\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(y)  \n",
    "    yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    build_model.fit([x],[yOnehot],epochs=100, batch_size=80000*1)\n",
    "    build_model.save(\"Akeras.h5\")\n",
    "    plot_model(build_model, to_file='AKeras.png', show_shapes=True)\n",
    "    \n",
    "    return build_model,models\n",
    "\n",
    "def kerasFitAndSaveSimple(x,y,num_labels):\n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 382\n",
    "    models=[]\n",
    "    \n",
    "    build_model = tf.keras.Sequential()\n",
    "    build_model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    build_model.add(layers.Dropout(dropout_rate))\n",
    "    build_model.add(layers.Dense(num_labels, activation='sigmoid'))\n",
    "    build_model.add(layers.Dense(num_labels, activation='sigmoid',name=\"layer1\",input_shape=(features_size,)))\n",
    "    \n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    plot_model(build_model, to_file='AKerasSimple.png', show_shapes=True)\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(y)  \n",
    "    yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    build_model.fit([x],[yOnehot],epochs=10000, batch_size=80000*1)\n",
    "    build_model.save(\"Akeras.h5\")\n",
    "    plot_model(build_model, to_file='AKeras.png', show_shapes=True)\n",
    "    \n",
    "    return build_model,models\n",
    "\n",
    "y1 = np.array(y1)\n",
    "y1= y1.reshape(nSamples,-1)\n",
    "print(y1)\n",
    "#kerasFitAndSave(x,y1,2)\n",
    "#kerasFitAndSaveSimple(x,y1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d5dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################融合决策树和多层神经网络###########################################################\n",
    "\n",
    "#######################################第一步读取数据\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "file1 = \"./trainData/dataAllSim1000.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "xyData = np.array(xyDataTmp)\n",
    "nSamples, nDims= xyData.shape\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "ylabel = y\n",
    "y1Level= y[:,0]#01\n",
    "y2Level= y[:,1]#012\n",
    "y3Level= y[:,2]#01234\n",
    "\n",
    "print(\"x.shape:\",x.shape,\"y.shape:\",y.shape)\n",
    "\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5757ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################融合决策树和多层神经网络###########################################################\n",
    "\n",
    "#######################################第二步基于神经网络训练，这里采用简单神经网络，RESNET类似和HNCF三种方法进行训练\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "###简单模型1，没有隐藏层\n",
    "def kerasFitAndSaveSimple1(x,yOneHot,num_labels):\n",
    "    nSamples,features_size = x.shape\n",
    "    build_model = tf.keras.Sequential()\n",
    "    build_model.add(layers.Dense(num_labels, activation='sigmoid',name=\"layer1\",input_shape=(features_size,)))\n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    \n",
    "    #enc = OneHotEncoder()\n",
    "    #enc.fit(y)  \n",
    "    #yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    build_model.fit([x],[yOneHot],epochs=10000, batch_size=80000*1)\n",
    "    build_model.save(\"kerasSimple1.h5\")\n",
    "    plot_model(build_model, to_file='KerasSimple1_noHiddenLayer.png', show_shapes=True)\n",
    "    return build_model\n",
    "\n",
    "###简单模型2，有隐藏层\n",
    "def kerasFitAndSaveSimple2(x,yOneHot,num_labels):\n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 512\n",
    "    dropout_rate = 0.05\n",
    "    build_model = tf.keras.Sequential()\n",
    "    build_model.add(layers.Dense(relu_size, activation='relu',name=\"layer1\",input_shape=(features_size,)))\n",
    "    build_model.add(layers.Dropout(dropout_rate,name=\"Dropout1-2\"))\n",
    "    build_model.add(layers.Dense(relu_size/2, activation='relu',name=\"layer2\"))\n",
    "    build_model.add(layers.Dropout(dropout_rate,name=\"Dropout2-3\"))\n",
    "    build_model.add(layers.Dense(num_labels, activation='sigmoid',name=\"layer3\"))\n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    #enc = OneHotEncoder()\n",
    "    #enc.fit(y)  \n",
    "    #yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    build_model.fit([x],[yOneHot],epochs=10000, batch_size=80000*1)\n",
    "    build_model.save(\"kerasSimple2.h5\")\n",
    "    plot_model(build_model, to_file='KerasSimple2_HiddenLayer.png', show_shapes=True)\n",
    "    return build_model\n",
    "\n",
    "###简单模型3，resnet_like\n",
    "def global_model(dropout_rate, relu_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    return model\n",
    "\n",
    "def sigmoid_model(label_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(label_size, activation='sigmoid',name=\"global\"))\n",
    "    return model\n",
    "\n",
    "def kerasFitAndSaveSimple3LikeResnet(x,yOneHot,num_labels):\n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 512\n",
    "    dropout_rate = 0.05\n",
    "    hierarchy = [1,1,1]\n",
    "    global_models = []\n",
    "    features = layers.Input(shape=(features_size,))\n",
    "    for i in range(len(hierarchy)):\n",
    "        if i == 0:\n",
    "            global_models.append(global_model(dropout_rate, relu_size)(features))\n",
    "        else:\n",
    "            global_models.append(global_model(dropout_rate, relu_size)(layers.concatenate([global_models[i-1], features])))\n",
    "\n",
    "    p_glob = sigmoid_model(label_size)(global_models[-1])\n",
    "    build_model = tf.keras.Model(inputs=[features], outputs=[p_glob])\n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    #enc = OneHotEncoder()\n",
    "    #enc.fit(y)  \n",
    "    #yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    build_model.fit([x],[yOneHot],epochs=10000, batch_size=80000*1)\n",
    "    build_model.save(\"KerasSimple3_likeResnet.h5\")\n",
    "    plot_model(build_model, to_file='KerasSimple3_likeResnet.png', show_shapes=True)\n",
    "    return build_model\n",
    "    print(\"HMCNF is not implemented\")\n",
    "    return False\n",
    "\n",
    "nSamples,features_size = x.shape\n",
    "num_labels = 5\n",
    "enc = OneHotEncoder()\n",
    "y3Level = np.array(y3Level)\n",
    "y3Level= y3Level.reshape(nSamples,-1)\n",
    "print(y3Level)\n",
    "enc.fit(y3Level)  \n",
    "\n",
    "###开始训练\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y3Level, test_size = 0.5)\n",
    "\n",
    "\n",
    "x = x_train\n",
    "yOneHot=enc.transform(y_train).toarray()\n",
    "print(yOneHot)\n",
    "#simpleMode1 = kerasFitAndSaveSimple1(x,yOneHot,num_labels)\n",
    "simpleMode2 = kerasFitAndSaveSimple2(x,yOneHot,num_labels)\n",
    "#simpleMode3 = kerasFitAndSaveSimple3(x,yOneHot,num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ee305",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################融合决策树和多层神经网络###########################################################\n",
    "#######################################第三步根据识别结果，进行聚类聚类\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "import copy\n",
    "\n",
    "####################################################################\n",
    "file1 = \"./trainData/dataAllSim1000.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "ylabel = y\n",
    "print(\"x.shape:\",x.shape,\"y.shape:\",y.shape)\n",
    "\n",
    "\n",
    "\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "#################################################################\n",
    "\n",
    "if 0:#采用keras\n",
    "    model_name =\"kerasSimple2.h5\" \n",
    "    model = keras.models.load_model(model_name)\n",
    "    yP5= model.predict([x], batch_size=2560)\n",
    "\n",
    "    ###需要将预测出的值，转换01整数,并转为数字式\n",
    "    for i in range(yP5.shape[0]):\n",
    "        tmp = yP5[i]\n",
    "        index=  np.argmax(tmp)\n",
    "        yP5[i] = [0,0,0,0,0]\n",
    "        yP5[i,index]=1\n",
    "    print(yP5)\n",
    "\n",
    "    ###\n",
    "    enc = OneHotEncoder()\n",
    "    yl5= y[:,2]#01234\n",
    "    yl5 = np.array(yl5)\n",
    "    yl5= yl5.reshape(nSamples,-1)\n",
    "    print(yl5)\n",
    "    enc.fit(yl5)\n",
    "\n",
    "    yP5= enc.inverse_transform(yP5)\n",
    "    yP5= yP5.reshape(-1,nSamples)[0]\n",
    "    ########\n",
    "\n",
    "\n",
    "\n",
    "    print(yP5)\n",
    "    print(yP5.shape)\n",
    "\n",
    "    print(yl5)\n",
    "    print(yl5.shape)\n",
    "\n",
    "if 1:#采用决策树\n",
    "    yl5= y[:,2]#01234\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=10,min_samples_leaf=100)\n",
    "    dt = dt.fit(x, yl5)\n",
    "    yPredict = dt.predict(x)\n",
    "    tmp1 = classification_report(yl5,yPredict)\n",
    "    print(tmp1)\n",
    "    mat1num = confusion_matrix(yl5,yPredict)\n",
    "    mat2acc = confusion_matrix(yl5,yPredict,normalize='pred')\n",
    "    print(mat1num)\n",
    "    print(np.around(mat2acc , decimals=3))\n",
    "    yP5 = yPredict\n",
    "\n",
    "###################################开始合并\n",
    "hierachFloor = dict()\n",
    "hierachFloor ['input'] = x\n",
    "hierachFloor ['output'] = y\n",
    "\n",
    "                               \n",
    "                                    \n",
    "                                    \n",
    "#0层为原始输入层\n",
    "mat1num = confusion_matrix(yl5 ,yP5)\n",
    "mat2acc = confusion_matrix(yl5,yP5,normalize='pred')\n",
    "print(mat1num)\n",
    "print(np.around(mat2acc , decimals=3))\n",
    "hierachFloor ['floor0'] = {'label':['0','1','2','3','4'],'num_mat': mat1num,'prob_mat': mat2acc}\n",
    "                                    \n",
    "\n",
    "def computeAccuracyDiff(mat1,accy):\n",
    "    h,w = mat1.shape\n",
    "    tmp = np.zeros((h-1,w-1))\n",
    "    matTmp={}\n",
    "    ##从0到最后，行列合并\n",
    "    for index in range(h-1):\n",
    "\n",
    "        tmp = np.zeros((h-1,w))\n",
    "        num = 0\n",
    "        ####行合并\n",
    "        for i in range(h):#行合并\n",
    "            if i == index:\n",
    "                tmp[num]=mat1[i]+mat1[i+1]\n",
    "                num=num+1\n",
    "                continue\n",
    "            if i== index+1:\n",
    "                continue\n",
    "\n",
    "            tmp[num]=mat1[i]\n",
    "            num=num+1\n",
    "\n",
    "        ####列合并   \n",
    "        mat2=tmp\n",
    "        tmp = np.zeros((h-1,w-1))\n",
    "        num = 0\n",
    "        for j in range(w):#列合并\n",
    "            if j == index:\n",
    "                tmp[:,num] = mat2[:,j]+mat2[:,j+1]\n",
    "                num=num+1\n",
    "                continue\n",
    "            if j== index+1:\n",
    "                continue\n",
    "\n",
    "            tmp[:,num] = mat2[:,j]\n",
    "            num=num+1\n",
    "        matTmp[index] = tmp\n",
    "        \n",
    "        #print(\"合并后的所有矩阵\")\n",
    "        #print(index,matTmp[index])#合并后的所有矩阵\n",
    "    matTmp1 = copy.deepcopy(matTmp)\n",
    "   \n",
    "    ##归一化   \n",
    "    maxDiffMat = np.zeros((len(matTmp),1))\n",
    "    for i in range(len(matTmp)):\n",
    "        tmp = matTmp[i]\n",
    "        sumTmp =  sum(tmp)\n",
    "        for j in range(tmp.shape[1]):\n",
    "            tmp[:,j] = tmp[:,j]/(sumTmp[j])\n",
    "\n",
    "        accyNow = tmp[i,i]\n",
    "        maxDiffMat[i]= max(accyNow-accy[i],accyNow-accy[i+1])\n",
    "    maxIndex = np.argmax(maxDiffMat)\n",
    "    maxDiff = max(maxDiffMat)\n",
    "    #print(matTmp1)\n",
    "    return maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1\n",
    "#print(\"最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "#print(“所有合并后的所有矩阵，数目和概率\",matTmp,matTmp1)\n",
    "#print(“各个点合并后的正确率提升矩阵\",maxDiffMat)\n",
    "\n",
    "print(\"\\n\\n\\n###################################################\")\n",
    "print(\"\\n\\n\\n 用数据进行分析\")\n",
    "\n",
    "#1层为5到4层\n",
    "accy = [mat2acc[0,0],mat2acc[1,1],mat2acc[2,2],mat2acc[3,3],mat2acc[4,4]]\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1num,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n5->4,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(maxDiffMat)\n",
    "print(\"数目矩阵\\n\",matTmp1[maxIndex])\n",
    "print(\"概率矩阵\\n\",np.around(matTmp[maxIndex], decimals=3))\n",
    "hierachFloor ['floor1'] = {'num_mat': matTmp1,'prob_mat': matTmp,'mergeIndex':maxIndex,'mergediffMat':maxDiffMat}\n",
    "\n",
    "###2层4->3\n",
    "mat1num=matTmp1[maxIndex]\n",
    "mat2acc= [matTmp[maxIndex][0,0],matTmp[maxIndex][1,1],matTmp[maxIndex][2,2],matTmp[maxIndex][3,3]]\n",
    "\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1num,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n4->3,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(maxDiffMat)\n",
    "print(\"数目矩阵\\n\",matTmp1[maxIndex])\n",
    "print(\"概率矩阵\\n\",np.around(matTmp[maxIndex], decimals=3))\n",
    "      \n",
    "hierachFloor ['floor2'] = {'num_mat': matTmp1,'prob_mat': matTmp,'mergeIndex':maxIndex,'mergediffMat':maxDiffMat}\n",
    " \n",
    "###3层3->2\n",
    "mat1num=matTmp1[maxIndex]\n",
    "mat2acc= [matTmp[maxIndex][0,0],matTmp[maxIndex][1,1],matTmp[maxIndex][2,2]]\n",
    "\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1num,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n3->2,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(maxDiffMat)\n",
    "print(\"数目矩阵\\n\",matTmp1[maxIndex])\n",
    "print(\"概率矩阵\\n\",np.around(matTmp[maxIndex], decimals=3))\n",
    "      \n",
    "hierachFloor['floor3'] = {'num_mat': matTmp1,'prob_mat': matTmp,'mergeIndex':maxIndex,'mergediffMat':maxDiffMat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1038f031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data\n",
      "x.shape: (844538, 22) y.shape: (844538, 4)\n",
      "x.shape: (844538, 22) yl5.shape: (844538,)\n",
      "x.shape: (844538, 22) y.shape: (844538,) y.type: <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-57-880209cf23e6>, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-57-880209cf23e6>\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    return\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "########################################融合决策树和多层神经网络###########################################################\n",
    "#######################################第四步根据聚类和识别结果，开始微调\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "import copy\n",
    "\n",
    "\n",
    "##################\n",
    "file1 = \"./trainData/dataAllSim1000.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "ylabel = y\n",
    "print(\"x.shape:\",x.shape,\"y.shape:\",y.shape)\n",
    "\n",
    "yl5= y[:,2]#01234\n",
    "print(\"x.shape:\",x.shape,\"yl5.shape:\",yl5.shape)\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "\n",
    "print(\"x.shape:\",x.shape,\"y.shape:\",yl5.shape,\"y.type:\", type(yl5) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "\n",
    "\n",
    "def getKerasModeFloors(x,y,saveName):\n",
    "    model_name = saveName \n",
    "    model = keras.models.load_model(model_name)\n",
    "    yP5= model.predict([x], batch_size=2560)\n",
    "    nSamples = yP5.shape[0]\n",
    "     ###需要将预测出的值，转换01整数,并转为数字式\n",
    "    for i in range(yP5.shape[0]):\n",
    "        tmp = yP5[i]\n",
    "        index=  np.argmax(tmp)\n",
    "        yP5[i] = [0,0,0,0,0]\n",
    "        yP5[i,index]=1\n",
    "   \n",
    "\n",
    "    ###\n",
    "    enc = OneHotEncoder()\n",
    "    yl5= y[:,2]#01234\n",
    "    yl5 = np.array(yl5)\n",
    "    yl5= yl5.reshape(nSamples,-1)\n",
    "    print(yl5)\n",
    "    enc.fit(yl5)\n",
    "\n",
    "    yP5= enc.inverse_transform(yP5)\n",
    "    yP5= yP5.reshape(-1,nSamples)[0]\n",
    "    \n",
    "    yP4 = np.zeros((yP5.shape[0],1))\n",
    "    yP3 = np.zeros((yP5.shape[0],1))\n",
    "    yP2 = np.zeros((yP5.shape[0],1))\n",
    "\n",
    "    for i in range(yP5.shape[0]):\n",
    "        if(yP5[i]== 2) or (yP5[i]== 1):\n",
    "             yP4[i] = 21\n",
    "        else:\n",
    "             yP4[i] = yP5[i]\n",
    "                \n",
    "        if(yP5[i]== 2) or (yP5[i]== 1) or (yP5[i]== 0):\n",
    "             yP3[i] = 210\n",
    "        else:\n",
    "             yP3[i] = yP5[i]\n",
    "                \n",
    "        if(yP5[i]== 2) or (yP5[i]== 1) or (yP5[i]== 0) or (yP5[i]== 3):\n",
    "             yP2[i] = 3210\n",
    "        else:\n",
    "             yP2[i] = yP5[i]\n",
    "    \n",
    "    return model,yP5,yP4,yP3,yP2\n",
    "\n",
    "#分层决策树\n",
    "def dtFitAndSave(x,y,saveName):\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=10,min_samples_leaf=1000)\n",
    "    dt = dt.fit(x, y)\n",
    "    tree.plot_tree(dt)\n",
    "    data=tree.export_graphviz(dt, out_file=None,class_names=None,filled=True) \n",
    "    graph = graphviz.Source(data)\n",
    "    graph.render(saveName)\n",
    "    \n",
    "    yPredict = dt.predict(x)\n",
    "    tmp1 = classification_report(y,yPredict)\n",
    "    print(tmp1)\n",
    "    mat1num = confusion_matrix(y,yPredict)\n",
    "    mat2acc = confusion_matrix(y,yPredict,normalize='pred')\n",
    "    print(mat1num)\n",
    "    print(np.around(mat2acc , decimals=3))\n",
    "    #text_representation = tree.export_text(dt)\n",
    "    #print(text_representation)\n",
    "    #yPredict = dt.predict_proba(x)\n",
    "    #index = np.where((yPredict[:,1]<0.98)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.90)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.80)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.70)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    return dt\n",
    "\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "def getDTSamplesInfo(x,dt):\n",
    "    yPredict = dt.predict_proba(x)\n",
    "    #print(\"\\n\\n getDTSamplesInfo yPredict\",yPredict)\n",
    "    d_path = dt.decision_path(x).todense()\n",
    "    #print(\"\\n\\n d_path\",d_path)\n",
    "    #print(\"impurity\",dt.tree_.impurity)\n",
    "    #print(\"feature\",dt.tree_.feature)\n",
    "    #print(\"threshold\",dt.tree_.threshold)\n",
    "    \n",
    "    #左节点编号  :  clf.tree_.children_left\n",
    "    #右节点编号  :  clf.tree_.children_right\n",
    "    #分割的变量  :  clf.tree_.feature\n",
    "    #分割的阈值  :  clf.tree_.threshold\n",
    "    #不纯度(gini) :  clf.tree_.impurity\n",
    "    #样本个数      :  clf.tree_.n_node_samples\n",
    "    #样本分布      :  clf.tree_.value\n",
    "    #https://blog.csdn.net/ywj_1991/article/details/122985778\n",
    "    #https://www.javaroad.cn/questions/54003\n",
    "    \n",
    "    h,w = d_path.shape\n",
    "    gini =np.zeros((h,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(h):\n",
    "       path = d_path[i]\n",
    "       v,ind = np.where(path>0)\n",
    "       xtmp = x[i]\n",
    "       #print(\"path\",path,ind,np.array(ind)[-1])\n",
    "    \n",
    "       #print(\"\\n index\",index)\n",
    "       #print(\"impurity\",dt.tree_.impurity[ind])\n",
    "       #print(\"feature\",dt.tree_.feature[ind])\n",
    "       #print(\"threshold\",dt.tree_.threshold[ind])\n",
    "       #print(\"x[index]\",xtmp[ind])\n",
    "       \n",
    "      \n",
    "       #print(\"the leaf node:\",np.array(ind)[-1],\"the simplest rule is\")\n",
    "       #for jj in ind:\n",
    "       #    if dt.tree_.feature[jj] == -2:\n",
    "       #         print(\"label,proba is\",yPredict[i,0],yPredict[i,1])\n",
    "       #         break\n",
    "                \n",
    "       #    if xtmp[jj]<=dt.tree_.threshold[jj]:\n",
    "       #       print(\" x[%d]<=%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "       #    else:\n",
    "       #       print(\" x[%d]>%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "                    \n",
    "       finalPos = np.array(ind)[-1]\n",
    "       gini[i] = dt.tree_.impurity[finalPos]\n",
    "       \n",
    "       #print(\"d_path\",i,path,dt.tree_.impurity[finalPos])\n",
    "       #print(dt.tree_.feature[finalPos])\n",
    "       #print(dt.tree_.threshold[finalPos])\n",
    "       #print(dt.tree_.n_node_samples[finalPos])\n",
    "\n",
    "    \n",
    "    return gini,yPredict\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "\n",
    "index = np.where((yl5 == 2) | (yl5 == 1))\n",
    "yl4 = yl5.copy()\n",
    "yl4[index]=21\n",
    "print(yl4)\n",
    "\n",
    "\n",
    "index = np.where((yl5 == 2) | (yl5 == 1) | (yl5 == 0))\n",
    "yl3 = yl5.copy()\n",
    "yl3[index]=210\n",
    "print(yl3)\n",
    "\n",
    "\n",
    "\n",
    "index = np.where( (yl5 == 3)|(yl5 == 2) | (yl5 == 1) | (yl5 == 0))\n",
    "yl2 = yl5.copy()\n",
    "yl2[index]=3210\n",
    "print(yl2)\n",
    "\n",
    "hierachFloor['floor3'][\"dt\"] = dtFitAndSave(x,yl2,\"Floo3_2\")\n",
    "hierachFloor['floor2'][\"dt\"] = dtFitAndSave(x,yl3,\"Floo2_3\")\n",
    "hierachFloor['floor1'][\"dt\"] = dtFitAndSave(x,yl4,\"Floor1_4\")\n",
    "hierachFloor['floor0'][\"dt\"] = dtFitAndSave(x,yl5,\"Floor0_5\")\n",
    "\n",
    "#giniFloor0,yPredictProFloor0 = getDTSamplesInfo(x,hierachFloor['floor0'][\"dt\"])\n",
    "#giniFloor1,yPredictProFloor1 = getDTSamplesInfo(x,hierachFloor['floor1'][\"dt\"])\n",
    "#giniFloor2,yPredictProFloor2 = getDTSamplesInfo(x,hierachFloor['floor2'][\"dt\"])\n",
    "#giniFloor3,yPredictProFloor3 = getDTSamplesInfo(x,hierachFloor['floor3'][\"dt\"])\n",
    "\n",
    "kerasFloors,yKerasP5,yKerasP4,yKerasP3,yKerasP2=getKerasModeFloors(x,y,'kerasSimple2.h5')\n",
    "##############开始混合检测\n",
    "\n",
    "###0层，5标签\n",
    "\n",
    "'''\n",
    "nSamples,feturesNume  = x.shape\n",
    "yHyLabelFloor0 = np.zeros((nSamples,1))\n",
    "hyCounter = 0\n",
    "for i in range(nSamples):\n",
    "    print(i)\n",
    "    xtmp = x[i]\n",
    "    dt = hierachFloor['floor0'][\"dt\"]\n",
    "    giniFloor0,yPredictProFloor0 = getDTSamplesInfo([xtmp],dt)\n",
    "    giniTmp = giniFloor0[0]\n",
    "    yPredictProFloor0Tmp = yPredictProFloor0[0]\n",
    "    #print('gini',giniTmp )\n",
    "    #print('probPredict',yPredictProFloor0Tmp  )\n",
    "    if giniTmp >0.05 or max(yPredictProFloor0Tmp)<0.98:\n",
    "        yHyLabelFloor0[i] = yKerasP5[i]\n",
    "    else:\n",
    "        yHyLabelFloor0[i] = np.argmax(yPredictProFloor0)\n",
    "        hyCounter = hyCounter+1\n",
    "  \n",
    "print('O层5标签hyCounter',hyCounter)    \n",
    "\n",
    "\n",
    "tmp1 = classification_report(yl5,yHyLabelFloor0)\n",
    "print('hybrid\\n',tmp1)\n",
    "tmp1 = classification_report( yKerasP5,yHyLabelFloor0)\n",
    "print('keras\\n',tmp1)\n",
    "mat1num = confusion_matrix(yl5,yHyLabelFloor0)\n",
    "mat2acc = confusion_matrix(yl5,yHyLabelFloor0,normalize='pred')\n",
    "print('mat1num\\n',mat1num)\n",
    "print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "'''\n",
    "\n",
    "'''\n",
    "#############1层，4标签\n",
    "nSamples,feturesNume  = x.shape\n",
    "yHyLabelFloor1 = np.zeros((nSamples,1))\n",
    "hyCounter = 0\n",
    "for i in range(nSamples):\n",
    "    print(i)\n",
    "    xtmp = x[i]\n",
    "    dt = hierachFloor['floor1'][\"dt\"]\n",
    "    giniFloor1,yPredictProFloor1 = getDTSamplesInfo([xtmp],dt)\n",
    "    giniTmp = giniFloor1[0]\n",
    "    yPredictProFloor1Tmp = yPredictProFloor1[0]\n",
    "    #print('gini',giniTmp )\n",
    "    #print('probPredict',yPredictProFloor0Tmp  )\n",
    "    if giniTmp >0.05 or max(yPredictProFloor1Tmp)<0.98:\n",
    "        yHyLabelFloor1[i] = yKerasP4[i]\n",
    "    else:\n",
    "        tmp0= [0,3,4,21]\n",
    "        index = np.argmax(yPredictProFloor1)\n",
    "        yHyLabelFloor1[i] = tmp0[index]\n",
    "        hyCounter = hyCounter+1\n",
    "print('O层4标签hyCounter',hyCounter)    \n",
    "\n",
    "\n",
    "tmp1 = classification_report(yl4,yHyLabelFloor1)\n",
    "print('hybrid\\n',tmp1)\n",
    "tmp1 = classification_report( yKerasP4,yHyLabelFloor1)\n",
    "print('keras\\n',tmp1)\n",
    "mat1num = confusion_matrix(yl4,yHyLabelFloor1)\n",
    "mat2acc = confusion_matrix(yl4,yHyLabelFloor1,normalize='pred')\n",
    "print('mat1num\\n',mat1num)\n",
    "print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "'''\n",
    "\n",
    "\n",
    "def computeAndCompareHybridMode(x,y,dt,kerasPLabel,floorLabel):\n",
    "    nSamples,feturesNume  = x.shape\n",
    "    yHyLabel  = np.zeros((nSamples,1))\n",
    "    hyCounter = 0\n",
    "    for i in range(nSamples):\n",
    "        print(i)\n",
    "        xtmp = x[i]\n",
    "        giniFloor,yPredictProFloor = getDTSamplesInfo([xtmp],dt)\n",
    "        giniTmp = giniFloor[0]\n",
    "        yPredictProFloorTmp = yPredictProFloor[0]\n",
    "        #print('gini',giniTmp )\n",
    "        #print('probPredict',yPredictProFloor0Tmp  )\n",
    "        if giniTmp >0.05 or max(yPredictProFloorTmp)<0.98:\n",
    "            yHyLabel[i] = kerasPLabel[i]\n",
    "        else:\n",
    "            #floorLabel= [3,4,210]\n",
    "            index = np.argmax(yPredictProFloorTmp)\n",
    "            yHyLabel[i] = floorLabel[index]\n",
    "            hyCounter = hyCounter+1\n",
    "    print('floorLabel\\n',floorLabel) \n",
    "    print('hyCounter\\n',hyCounter)    \n",
    "\n",
    "\n",
    "    tmp1 = classification_report(y,yHyLabel)\n",
    "    print('hybrid\\n',tmp1)\n",
    "    tmp1 = classification_report(kerasPLabel,yHyLabel)\n",
    "    print('keras\\n',tmp1)\n",
    "    mat1num = confusion_matrix(y,yHyLabel)\n",
    "    mat2acc = confusion_matrix(y,yHyLabel,normalize='pred')\n",
    "    print('mat1num\\n',mat1num)\n",
    "    print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "    return\n",
    "\n",
    "#floor=2 ,label=3\n",
    "#dt = hierachFloor['floor2'][\"dt\"]\n",
    "#floorLabel= [3,4,210] \n",
    "#computeAndCompareHybridMode(x,yl3,dt,yKerasP3,floorLabel)\n",
    "\n",
    "#floor=3 ,label=2\n",
    "dt = hierachFloor['floor3'][\"dt\"]\n",
    "floorLabel= [4,3210] \n",
    "computeAndCompareHybridMode(x,yl2,dt,yKerasP2,floorLabel)\n",
    "\n",
    "return\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "'''\n",
    "for i in range(nSamples):\n",
    "    for j in range(4)\n",
    "         input1 = x[i,:]\n",
    "         label =  ylabel[i,j]\n",
    "         output1 = Floor[j][\"dt\"].predict_proba(input)\n",
    "         output_gini,output_num =getDT_Info(input)\n",
    "    \n",
    "        if max(output1)<0.95 or output_gini>0.2\n",
    "            output1 =  Floor[j][\"keras\"].predict(input)\n",
    "        \n",
    "        loss=loss+(output1-label)\n",
    "                           \n",
    "                           \n",
    "def getDT_SamplesInfo(x)\n",
    "    yPredict = dt.predict_proba(x[0:3,:])\n",
    "    print(yPredict[:,1])\n",
    "    d_path = dt.decision_path(x[0:3,:]).todense()\n",
    "    print(d_path)\n",
    "    print(\"impurity\",dt.tree_.impurity)\n",
    "    print(\"feature\",dt.tree_.feature)\n",
    "    print(\"threshold\",dt.tree_.threshold)\n",
    "    \n",
    "    #左节点编号  :  clf.tree_.children_left\n",
    "    #右节点编号  :  clf.tree_.children_right\n",
    "    #分割的变量  :  clf.tree_.feature\n",
    "    #分割的阈值  :  clf.tree_.threshold\n",
    "    #不纯度(gini) :  clf.tree_.impurity\n",
    "    #样本个数      :  clf.tree_.n_node_samples\n",
    "    #样本分布      :  clf.tree_.value\n",
    "    #https://blog.csdn.net/ywj_1991/article/details/122985778\n",
    "    #https://www.javaroad.cn/questions/54003\n",
    "\n",
    "    w,h = d_path.shape\n",
    "    for i in range(h):\n",
    "       path = d_path[i]\n",
    "       v,ind = np.where(path>0)\n",
    "       xtmp = x[i]\n",
    "       #print(\"path\",path,ind,np.array(ind)[-1])\n",
    "    \n",
    "       print(\"\\n index\",index)\n",
    "       print(\"impurity\",dt.tree_.impurity[ind])\n",
    "       print(\"feature\",dt.tree_.feature[ind])\n",
    "       print(\"threshold\",dt.tree_.threshold[ind])\n",
    "       print(\"x[index]\",xtmp[ind])\n",
    "       \n",
    "      \n",
    "       print(\"the leaf node:\",np.array(ind)[-1],\"the simplest rule is\")\n",
    "       for jj in ind:\n",
    "           if dt.tree_.feature[jj] == -2:\n",
    "                print(\"label,proba is\",yPredict[i,0],yPredict[i,1])\n",
    "                break\n",
    "                \n",
    "           if xtmp[jj]<=dt.tree_.threshold[jj]:\n",
    "              print(\" x[%d]<=%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "           else:\n",
    "              print(\" x[%d]>%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "                    \n",
    "       finalPos = np.array(ind)[-1]\n",
    "       print(dt.tree_.impurity[finalPos])\n",
    "       print(dt.tree_.feature[finalPos])\n",
    "       print(dt.tree_.threshold[finalPos])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b9e7feaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data france\n",
      "x.shape: (71998, 22) y.shape: (71998,) y.type: <class 'numpy.ndarray'>\n",
      "reading data\n",
      "x.shape: (71998, 22) yl5.shape: (916536, 1)\n",
      "x.shape: (916536, 22) y.shape: (916536,) y.type: <class 'numpy.ndarray'>\n",
      "[[21]\n",
      " [21]\n",
      " [21]\n",
      " ...\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]]\n",
      "[[210]\n",
      " [210]\n",
      " [210]\n",
      " ...\n",
      " [210]\n",
      " [210]\n",
      " [210]]\n",
      "[[3210]\n",
      " [3210]\n",
      " [3210]\n",
      " ...\n",
      " [3210]\n",
      " [3210]\n",
      " [3210]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98    615146\n",
      "           1       0.72      0.91      0.80    171521\n",
      "           2       0.69      0.50      0.58    101577\n",
      "           3       0.65      0.19      0.29     17906\n",
      "           4       0.58      0.48      0.52     10386\n",
      "\n",
      "    accuracy                           0.89    916536\n",
      "   macro avg       0.73      0.61      0.64    916536\n",
      "weighted avg       0.89      0.89      0.89    916536\n",
      "\n",
      "[[605816   8957     16      0    357]\n",
      " [  4331 155255  11805      0    130]\n",
      " [  2788  45708  50526   1342   1213]\n",
      " [  1028   4118   7476   3377   1907]\n",
      " [  1073    718   3201    438   4956]]\n",
      "[[0.985 0.042 0.    0.    0.042]\n",
      " [0.007 0.723 0.162 0.    0.015]\n",
      " [0.005 0.213 0.692 0.26  0.142]\n",
      " [0.002 0.019 0.102 0.655 0.223]\n",
      " [0.002 0.003 0.044 0.085 0.579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 916536/916536 [00:02<00:00, 438304.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "floorLabel\n",
      " [4, 3210]\n",
      "hyCounter\n",
      " 507199\n",
      "hybrid\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       0.89      0.86      0.88     10386\n",
      "        3210       1.00      1.00      1.00    906150\n",
      "\n",
      "    accuracy                           1.00    916536\n",
      "   macro avg       0.95      0.93      0.94    916536\n",
      "weighted avg       1.00      1.00      1.00    916536\n",
      "\n",
      "keras\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       0.89      0.86      0.87     10386\n",
      "        3210       1.00      1.00      1.00    906150\n",
      "\n",
      "    accuracy                           1.00    916536\n",
      "   macro avg       0.94      0.93      0.94    916536\n",
      "weighted avg       1.00      1.00      1.00    916536\n",
      "\n",
      "mat1num\n",
      " [[  8937   1449]\n",
      " [  1082 905068]]\n",
      "mat2acc\n",
      " [[0.892 0.002]\n",
      " [0.108 0.998]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "\n",
    "\n",
    "def getKerasModeFloors2(x,enc,saveName):\n",
    "    model_name = saveName \n",
    "    model = keras.models.load_model(model_name)\n",
    "    yP5= model.predict([x], batch_size=2560)\n",
    "    nSamples = yP5.shape[0]\n",
    "     ###需要将预测出的值，转换01整数,并转为数字式\n",
    "    for i in range(yP5.shape[0]):\n",
    "        tmp = yP5[i]\n",
    "        index=  np.argmax(tmp)\n",
    "        yP5[i] = [0,0,0,0,0]\n",
    "        yP5[i,index]=1\n",
    "   \n",
    "\n",
    "    ###  \n",
    "    yP5= enc.inverse_transform(yP5)\n",
    "    yP5= yP5.reshape(-1,nSamples)[0]\n",
    "    \n",
    "    yP4 = np.zeros((yP5.shape[0],1))\n",
    "    yP3 = np.zeros((yP5.shape[0],1))\n",
    "    yP2 = np.zeros((yP5.shape[0],1))\n",
    "\n",
    "    for i in range(yP5.shape[0]):\n",
    "        if(yP5[i]== 2) or (yP5[i]== 1):\n",
    "             yP4[i] = 21\n",
    "        else:\n",
    "             yP4[i] = yP5[i]\n",
    "                \n",
    "        if(yP5[i]== 2) or (yP5[i]== 1) or (yP5[i]== 0):\n",
    "             yP3[i] = 210\n",
    "        else:\n",
    "             yP3[i] = yP5[i]\n",
    "                \n",
    "        if(yP5[i]== 2) or (yP5[i]== 1) or (yP5[i]== 0) or (yP5[i]== 3):\n",
    "             yP2[i] = 3210\n",
    "        else:\n",
    "             yP2[i] = yP5[i]\n",
    "    \n",
    "    return model,yP5,yP4,yP3,yP2\n",
    "\n",
    "#分层决策树\n",
    "def dtFitAndSave(x,y,saveName):\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=7,min_samples_leaf=1000)\n",
    "    dt = dt.fit(x, y)\n",
    "    tree.plot_tree(dt)\n",
    "    data=tree.export_graphviz(dt, out_file=None,class_names=None,filled=True) \n",
    "    graph = graphviz.Source(data)\n",
    "    graph.render(saveName)\n",
    "    \n",
    "    yPredict = dt.predict(x)\n",
    "    tmp1 = classification_report(y,yPredict)\n",
    "    print(tmp1)\n",
    "    mat1num = confusion_matrix(y,yPredict)\n",
    "    mat2acc = confusion_matrix(y,yPredict,normalize='pred')\n",
    "    print(mat1num)\n",
    "    print(np.around(mat2acc , decimals=3))\n",
    "    #text_representation = tree.export_text(dt)\n",
    "    #print(text_representation)\n",
    "    #yPredict = dt.predict_proba(x)\n",
    "    #index = np.where((yPredict[:,1]<0.98)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.90)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.80)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.70)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    return dt\n",
    "\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "def getDTSamplesInfo(x,dt):\n",
    "    yPredict = dt.predict_proba(x)\n",
    "    #print(\"\\n\\n getDTSamplesInfo yPredict\",yPredict)\n",
    "    d_path = dt.decision_path(x).todense()\n",
    "    #print(\"\\n\\n d_path\",d_path)\n",
    "    #print(\"impurity\",dt.tree_.impurity)\n",
    "    #print(\"feature\",dt.tree_.feature)\n",
    "    #print(\"threshold\",dt.tree_.threshold)\n",
    "    \n",
    "    #左节点编号  :  clf.tree_.children_left\n",
    "    #右节点编号  :  clf.tree_.children_right\n",
    "    #分割的变量  :  clf.tree_.feature\n",
    "    #分割的阈值  :  clf.tree_.threshold\n",
    "    #不纯度(gini) :  clf.tree_.impurity\n",
    "    #样本个数      :  clf.tree_.n_node_samples\n",
    "    #样本分布      :  clf.tree_.value\n",
    "    #https://blog.csdn.net/ywj_1991/article/details/122985778\n",
    "    #https://www.javaroad.cn/questions/54003\n",
    "    \n",
    "    h,w = d_path.shape\n",
    "    gini =np.zeros((h,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(h):\n",
    "       path = d_path[i]\n",
    "       v,ind = np.where(path>0)\n",
    "       xtmp = x[i]\n",
    "       #print(\"path\",path,ind,np.array(ind)[-1])\n",
    "    \n",
    "       #print(\"\\n index\",index)\n",
    "       #print(\"impurity\",dt.tree_.impurity[ind])\n",
    "       #print(\"feature\",dt.tree_.feature[ind])\n",
    "       #print(\"threshold\",dt.tree_.threshold[ind])\n",
    "       #print(\"x[index]\",xtmp[ind])\n",
    "       \n",
    "      \n",
    "       #print(\"the leaf node:\",np.array(ind)[-1],\"the simplest rule is\")\n",
    "       #for jj in ind:\n",
    "       #    if dt.tree_.feature[jj] == -2:\n",
    "       #         print(\"label,proba is\",yPredict[i,0],yPredict[i,1])\n",
    "       #         break\n",
    "                \n",
    "       #    if xtmp[jj]<=dt.tree_.threshold[jj]:\n",
    "       #       print(\" x[%d]<=%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "       #    else:\n",
    "       #       print(\" x[%d]>%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "                    \n",
    "       finalPos = np.array(ind)[-1]\n",
    "       gini[i] = dt.tree_.impurity[finalPos]\n",
    "       \n",
    "       #print(\"d_path\",i,path,dt.tree_.impurity[finalPos])\n",
    "       #print(dt.tree_.feature[finalPos])\n",
    "       #print(dt.tree_.threshold[finalPos])\n",
    "       #print(dt.tree_.n_node_samples[finalPos])\n",
    "\n",
    "    \n",
    "       return gini,yPredict\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "from tqdm import tqdm\n",
    "def computeAndCompareHybridMode(x,y,dt,kerasPLabel,floorLabel):\n",
    "    nSamples,feturesNume  = x.shape\n",
    "    yHyLabel  = np.zeros((nSamples,1))\n",
    "    giniFloor,yPredictProFloor = getDTSamplesInfo(x,dt)\n",
    "    prdictMax = np.max(yPredictProFloor,axis=1)\n",
    "    \n",
    "    \n",
    "    index1 = np.argmax(yPredictProFloor, axis = 1)\n",
    "    index1 = index1.astype('int64')\n",
    "    hyCounter = nSamples\n",
    "    for i in tqdm(range(nSamples)):\n",
    "        yHyLabel[i] = floorLabel[index1[i]]\n",
    "        giniTmp = giniFloor[i]\n",
    "        probaTmp = prdictMax[i]\n",
    "        if giniTmp>0.1 or probaTmp<0.95:\n",
    "            yHyLabel[i] = kerasPLabel[i]\n",
    "            hyCounter = hyCounter-1\n",
    "        \n",
    "\n",
    "\n",
    "    print('floorLabel\\n',floorLabel) \n",
    "    print('hyCounter\\n',hyCounter)    \n",
    "\n",
    "\n",
    "    tmp1 = classification_report(y,yHyLabel)\n",
    "    print('hybrid\\n',tmp1)\n",
    "    tmp1 = classification_report(y,kerasPLabel)\n",
    "    print('keras\\n',tmp1)\n",
    "    mat1num = confusion_matrix(y,yHyLabel)\n",
    "    mat2acc = confusion_matrix(y,yHyLabel,normalize='pred')\n",
    "    print('mat1num\\n',mat1num)\n",
    "    print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "    return\n",
    "'''\n",
    "from tqdm import tqdm\n",
    "\n",
    "def computeAndCompareHybridMode(x,y,dt,kerasPLabel,floorLabel):\n",
    "    nSamples,feturesNume  = x.shape\n",
    "    yHyLabel  = np.zeros((nSamples,1))\n",
    "    hyCounter = 0\n",
    "    for i in tqdm(range(nSamples)):\n",
    "        #print(i)\n",
    "        xtmp = x[i]\n",
    "        giniFloor,yPredictProFloor = getDTSamplesInfo([xtmp],dt)\n",
    "        giniTmp = giniFloor[0]\n",
    "        yPredictProFloorTmp = yPredictProFloor[0]\n",
    "        #print('gini',giniTmp )\n",
    "        #print('probPredict',yPredictProFloor0Tmp  )\n",
    "        if giniTmp >0.05 or max(yPredictProFloorTmp)<0.98:\n",
    "            yHyLabel[i] = kerasPLabel[i]\n",
    "        else:\n",
    "            #floorLabel= [3,4,210]\n",
    "            index = np.argmax(yPredictProFloorTmp)\n",
    "            yHyLabel[i] = floorLabel[index]\n",
    "            hyCounter = hyCounter+1\n",
    "    print('floorLabel\\n',floorLabel) \n",
    "    print('hyCounter\\n',hyCounter)    \n",
    "\n",
    "\n",
    "    tmp1 = classification_report(y,yHyLabel)\n",
    "    print('hybrid\\n',tmp1)\n",
    "    tmp1 = classification_report(y,kerasPLabel)\n",
    "    print('keras\\n',tmp1)\n",
    "    mat1num = confusion_matrix(y,yHyLabel)\n",
    "    mat2acc = confusion_matrix(y,yHyLabel,normalize='pred')\n",
    "    print('mat1num\\n',mat1num)\n",
    "    print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "    return\n",
    "'''\n",
    "##########################################################################\n",
    "###简单模型2，有隐藏层\n",
    "def kerasFitAndSaveSimple2(x,yOneHot,num_labels):\n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 512\n",
    "    dropout_rate = 0.05\n",
    "    build_model = tf.keras.Sequential()\n",
    "    build_model.add(layers.Dense(relu_size, activation='relu',name=\"layer1\",input_shape=(features_size,)))\n",
    "    build_model.add(layers.Dropout(dropout_rate,name=\"Dropout1-2\"))\n",
    "    build_model.add(layers.Dense(relu_size/2, activation='relu',name=\"layer2\"))\n",
    "    build_model.add(layers.Dropout(dropout_rate,name=\"Dropout2-3\"))\n",
    "    build_model.add(layers.Dense(num_labels, activation='sigmoid',name=\"layer3\"))\n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    #enc = OneHotEncoder()\n",
    "    #enc.fit(y)  \n",
    "    #yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    build_model.fit([x],[yOneHot],epochs=10000, batch_size=80000*1)\n",
    "    #build_model.fit(x,yOneHot,epochs=1000, batch_size=80000*1)\n",
    "    build_model.save(\"kerasSimple2.h5\")\n",
    "    plot_model(build_model, to_file='KerasSimple2_HiddenLayer.png', show_shapes=True)\n",
    "    return build_model\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####用法国数据进行验证\n",
    "file1 = \"./trainData/france_0_allSamples.csv\"\n",
    "print(\"reading data france\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "h,w = xyData.shape\n",
    "x = xyData[:,1:23]#简单处理与SUMO数据库一致\n",
    "y = xyData[:,w-1]\n",
    "y= y.astype('int64')\n",
    "\n",
    "print(\"x.shape:\",x.shape,\"y.shape:\",y.shape,\"y.type:\", type(y) )\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "\n",
    "####\n",
    "file1 = \"./trainData/dataAllSim1000.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "\n",
    "xSumo = xyData[:,0:22]\n",
    "ySumo = xyData[:,22:26]\n",
    "ySumo= ySumo[:,2]#01234\n",
    "ySumo= ySumo.astype('int64')\n",
    "\n",
    "print(\"x.shape:\",x.shape,\"yl5.shape:\",yl5.shape)\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "\n",
    "\n",
    "x = np.concatenate((xSumo,x))\n",
    "y = np.concatenate((ySumo,y))\n",
    "yl5 = y\n",
    "print(\"x.shape:\",x.shape,\"y.shape:\",yl5.shape,\"y.type:\", type(yl5) )\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "###keras拟合,oneHot\n",
    "nSamples,nFeatures =  x.shape\n",
    "enc = OneHotEncoder()\n",
    "yl5= yl5.reshape(nSamples,-1)\n",
    "enc.fit(yl5)  \n",
    "\n",
    "##keras拟合\n",
    "if 0:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, yl5, test_size = 0.8)\n",
    "    yOneHot=enc.transform(y_train).toarray()\n",
    "    num_labels = 5\n",
    "    simpleMode2 = kerasFitAndSaveSimple2(x_train,yOneHot,num_labels)\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "index = np.where((yl5 == 2) | (yl5 == 1))\n",
    "yl4 = yl5.copy()\n",
    "yl4[index]=21\n",
    "print(yl4)\n",
    "\n",
    "\n",
    "index = np.where((yl5 == 2) | (yl5 == 1) | (yl5 == 0))\n",
    "yl3 = yl5.copy()\n",
    "yl3[index]=210\n",
    "print(yl3)\n",
    "\n",
    "\n",
    "\n",
    "index = np.where( (yl5 == 3)|(yl5 == 2) | (yl5 == 1) | (yl5 == 0))\n",
    "yl2 = yl5.copy()\n",
    "yl2[index]=3210\n",
    "print(yl2)\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "#hierachFloor['floor3'][\"dt\"] = dtFitAndSave(x,yl2,\"Floo3_2\")\n",
    "#hierachFloor['floor2'][\"dt\"] = dtFitAndSave(x,yl3,\"Floo2_3\")\n",
    "#hierachFloor['floor1'][\"dt\"] = dtFitAndSave(x,yl4,\"Floor1_4\")\n",
    "#hierachFloor['floor0'][\"dt\"] = dtFitAndSave(x,yl5,\"Floor0_5\")\n",
    "dt_floor0_label5 = dtFitAndSave(x,yl5,\"Floor0_5\")\n",
    "\n",
    "kerasFloors,yKerasP5,yKerasP4,yKerasP3,yKerasP2=getKerasModeFloors2(x,enc,'kerasSimple2.h5')\n",
    "\n",
    "\n",
    "#floor=3 ,label=2\n",
    "dt = hierachFloor['floor3'][\"dt\"]\n",
    "floorLabel= [4,3210] \n",
    "computeAndCompareHybridMode(x,yl2,dt,yKerasP2,floorLabel)\n",
    "\n",
    "\n",
    "\n",
    "#dt =dt_floor0_label5\n",
    "#floorLabel= [0,1,2,3,4] \n",
    "#computeAndCompareHybridMode(x,yl5,dt,yKerasP5,floorLabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f428d4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 890 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/liuli/miniconda3/envs/keras220CpuJupyter/lib/python3.6/site-packages (from importlib-resources->tqdm) (3.6.0)\n",
      "Installing collected packages: importlib-resources, tqdm\n",
      "Successfully installed importlib-resources-5.4.0 tqdm-4.64.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mainTestCSVMLP3(hmcnf_keras).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:keras220CpuJupyter]",
   "language": "python",
   "name": "conda-env-keras220CpuJupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
