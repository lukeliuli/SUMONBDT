{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e950e1a2",
   "metadata": {
    "id": "48f98b91"
   },
   "outputs": [],
   "source": [
    "#mkdir /content/tmp\n",
    "#%cp -r -f -v /content/drive/MyDrive/SUMONBDT /content/tmp\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#%cd /content/drive/MyDrive/SUMONBDT\n",
    "#%cd /home/liuli/github/SUMONBDT\n",
    "#!nvidia-smi\n",
    "#用于测试oneHot\n",
    "#############################################################也是第一步，读取数据\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "#[2,3,5,9]\n",
    "x1 = [0,0,0,0]\n",
    "x2 = [0,0,0,1]\n",
    "\n",
    "x3 = [1,1,1,2]\n",
    "x4 = [1,1,1,3]\n",
    "x5 = [1,1,2,4]\n",
    "x6 = [1,1,2,5]\n",
    "x7 = [1,2,3,6]\n",
    "x8 = [1,2,3,7]\n",
    "x9 = [1,2,4,8]\n",
    "X = [x1, x2, x3,x4,x5,x6,x7,x8,x9]\n",
    "enc.fit(X)\n",
    "#print(enc.transform(X).toarray())\n",
    "\n",
    "\n",
    "########################读写CSV,并转为oneHot\n",
    "file1 = \"./trainData/dataAllSim1000.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "ylabel = y\n",
    "y = enc.transform(y).toarray()\n",
    "\n",
    "print(\"x.shape:\",x.shape,\"yOneHot.shape:\",y.shape)\n",
    "\n",
    "\n",
    "\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2455b3d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "03c551ad",
    "outputId": "e1da57c0-4dd7-440a-bf3f-6194c50c0c1c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "################################################################第二步，训练\n",
    "#1. 核心为keras220不是pytorch\n",
    "#2. 基于hmcnf\n",
    "import model_hmcnf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "#hierarchy = [18, 80, 178, 142, 77, 4]\n",
    "hierarchy = [2,3,5,9]\n",
    "features_size = x.shape[1]\n",
    "label_size = y.shape[1]\n",
    "beta = 0.2\n",
    "dropout_rate=0.1\n",
    "relu_size=384\n",
    "\n",
    "\n",
    "\n",
    "def local_model(num_labels, dropout_rate, relu_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(num_labels, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def global_model(dropout_rate, relu_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    return model\n",
    "\n",
    "\n",
    "def sigmoid_model(label_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(label_size, activation='sigmoid',name=\"global\"))\n",
    "    return model\n",
    "\n",
    "features = layers.Input(shape=(features_size,))\n",
    "global_models = []\n",
    "local_models = []\n",
    "\n",
    "\n",
    "for i in range(len(hierarchy)):\n",
    "    if i == 0:\n",
    "        global_models.append(global_model(dropout_rate, relu_size)(features))\n",
    "    else:\n",
    "        global_models.append(global_model(dropout_rate, relu_size)(layers.concatenate([global_models[i-1], features])))\n",
    "\n",
    "p_glob = sigmoid_model(label_size)(global_models[-1])\n",
    "\n",
    "\n",
    "#显示只有全局模型的情况\n",
    "#modelTmp1 = tf.keras.Model(inputs=[features], outputs=[p_glob])\n",
    "#modelTmp1.summary()#\n",
    "#plot_model(modelTmp1, to_file='Flatten1.png', show_shapes=True)\n",
    "\n",
    "\n",
    "for i in range(len(hierarchy)):\n",
    "    local_models.append(local_model(hierarchy[i], dropout_rate, relu_size)(global_models[i]))\n",
    "    \n",
    "#显示只有局部局模型的情况(部分全局)\n",
    "p_loc = layers.concatenate(local_models)\n",
    "#modelTmp2 = tf.keras.Model(inputs=[features], outputs=[p_loc])\n",
    "#modelTmp2.summary()#\n",
    "#plot_model(modelTmp2, to_file='Flatten2.png', show_shapes=True)\n",
    "p_glob1 = layers.Lambda(lambda x: x*beta,name=\"global\")(p_glob)\n",
    "p_loc1 = layers.Lambda(lambda x: x*(1-beta),name=\"local\")(p_loc)\n",
    "\n",
    "labels = layers.add([p_glob1, p_loc1])\n",
    "\n",
    "model = tf.keras.Model(inputs=[features], outputs=[labels])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_model(model, to_file='FlattenAll.png', show_shapes=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['mae'])\n",
    "model.fit([x],[y],epochs=1000, batch_size=25600*1)\n",
    "model.save(\"hmcnf10000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c796642",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d7beeed",
    "outputId": "d6908600-8597-41c2-800f-afc59a088154"
   },
   "outputs": [],
   "source": [
    "##################################################################第三步，验证\n",
    "#%cd /content/drive/MyDrive/SUMONBDT\n",
    "import model_hmcnf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#######################0.准备onehot\n",
    "enc = OneHotEncoder()\n",
    "#[2,3,5,9]\n",
    "x1 = [0,0,0,0]\n",
    "x2 = [0,0,0,1]\n",
    "\n",
    "x3 = [1,1,1,2]\n",
    "x4 = [1,1,1,3]\n",
    "x5 = [1,1,2,4]\n",
    "x6 = [1,1,2,5]\n",
    "x7 = [1,2,3,6]\n",
    "x8 = [1,2,3,7]\n",
    "x9 = [1,2,4,8]\n",
    "X = [x1, x2, x3,x4,x5,x6,x7,x8,x9]\n",
    "enc.fit(X)\n",
    "\n",
    "#######################2.准备数据\n",
    "        \n",
    "file1 = \"./trainData/dataAllSim10000.csv\"\n",
    "file1 = \"./trainData/dataAllSim.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "ylabel = y\n",
    "y = enc.transform(y).toarray()\n",
    "\n",
    "\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "#######################3.预测模型\n",
    "print(\"3.HMCNF预测模型\")\n",
    "hierarchy = [2,3,5,9]\n",
    "features_size = x.shape[1]\n",
    "label_size = y.shape[1]\n",
    "beta = 0.2\n",
    "\n",
    "model_name =\"hmcnf.h5\" \n",
    "\n",
    "model = keras.models.load_model(model_name)\n",
    "y_out = model.predict([x], batch_size=2560)\n",
    "y_predict = np.where(y_out > 0.5, 1, 0)\n",
    "\n",
    "predict_ok = np.where(np.sum(y_predict - y, axis=1) == 0, 1, 0)\n",
    "\n",
    "\n",
    "print(\"validated {} , {} good out of {} samples\".format(model_name, np.sum(predict_ok), predict_ok.shape[0]))\n",
    "del y_predict #节省内存\n",
    "del predict_ok #节省内存\n",
    "#######################3.层次预测预测模型\n",
    "print(\"3.层次预测预测模型\")\n",
    "y1 = np.where(y_out[:,0:2] > 0.5, 1, 0)\n",
    "y2 = np.where(y_out[:,2:5] > 0.5, 1, 0)\n",
    "y3 = np.where(y_out[:,5:10] > 0.5, 1, 0)\n",
    "y4 = np.where(y_out[:,10:19] > 0.5, 1, 0)\n",
    "for i in range(y4.shape[0]):\n",
    "    tmp1 = y1[i]\n",
    "    tmp2 = y2[i]\n",
    "    tmp3 = y3[i]\n",
    "    tmp4 = y4[i]\n",
    "    if sum(tmp1) == 0:\n",
    "        index=  np.argmax(tmp1)\n",
    "        y1[i,index]=1\n",
    "        \n",
    "    if sum(tmp2) == 0:\n",
    "        index=  np.argmax(tmp2)\n",
    "        y2[i,index]=1\n",
    "        \n",
    "    if sum(tmp3) == 0:\n",
    "        index=  np.argmax(tmp3)\n",
    "        y3[i,index]=1\n",
    "    \n",
    "    if sum(tmp4) == 0:\n",
    "        index=  np.argmax(tmp4)\n",
    "        y4[i,index]=1\n",
    "        #print(i,y4[i],index)\n",
    "y_predict = np.concatenate([y1,y2,y3,y4],axis=1)\n",
    "predict_ok = np.where(np.sum(y_predict - y, axis=1) == 0, 1, 0)\n",
    "print(\"validated {} , {} good out of {} samples\".format(model_name, np.sum(predict_ok), predict_ok.shape[0]))\n",
    "\n",
    "#onehot 2 label\n",
    "ypredict = enc.inverse_transform(y_predict)\n",
    "del y_predict #节省内存\n",
    "del predict_ok #节省内存\n",
    "del y1,y2,y3,y4\n",
    "#######################4.评估层次模型\n",
    "#hierarchy = [2,3,5,9]\n",
    "\n",
    "##第一层，2\n",
    "print(\"###################################第一层，2\")\n",
    "h1_yp = ypredict[:,0]\n",
    "h1_yl = ylabel[:,0]\n",
    "tmp1 = classification_report(h1_yl,h1_yp)\n",
    "tmp2 = confusion_matrix(h1_yl,h1_yp,normalize='true')\n",
    "tmp3 = confusion_matrix(h1_yl,h1_yp,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))\n",
    "\n",
    "\n",
    "##第二层，3\n",
    "print(\"################################第二层，3\")\n",
    "h2_yp = ypredict[:,1]\n",
    "h2_yl = ylabel[:,1]\n",
    "tmp1 = classification_report(h2_yl,h2_yp)\n",
    "tmp2 = confusion_matrix(h2_yl,h2_yp,normalize='true')\n",
    "tmp3 = confusion_matrix(h2_yl,h2_yp,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))\n",
    "\n",
    "\n",
    "\n",
    "##第三层，5\n",
    "print(\"#############################第三层，5\")\n",
    "h3_yp = ypredict[:,2]\n",
    "h3_yl = ylabel[:,2]\n",
    "tmp1 = classification_report(h3_yl,h3_yp)\n",
    "tmp2 = confusion_matrix(h3_yl,h3_yp,normalize='true')\n",
    "tmp3 = confusion_matrix(h3_yl,h3_yp,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))\n",
    "\n",
    "\n",
    "##第四层，9\n",
    "print(\"#############################第四层，9\")\n",
    "h4_yp = ypredict[:,3]\n",
    "h4_yl = ylabel[:,3]\n",
    "tmp1 = classification_report(h4_yl,h4_yp)\n",
    "tmp2 = confusion_matrix(h4_yl,h4_yp,normalize='true')\n",
    "tmp3 = confusion_matrix(h4_yl,h4_yp,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640419ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第四步，根据混淆矩阵进行聚类。第一列代表识别为类别1的样本真实的类别分布\n",
    "import numpy as np\n",
    "import copy\n",
    "#########################################手动准备模拟数据\n",
    "mat1 = np.array([[0.952,0.004,0.015,0.008],\n",
    " [0.018,0.923,0.016,0.032],\n",
    " [0.016,0.036,0.934,0.047],\n",
    " [0.014,0.037,0.035,0.913]])\n",
    "accy = [mat1[0,0],mat1[1,1],mat1[2,2],mat1[3,3]]\n",
    "print(\"accuracy\",accy)\n",
    "matT1 = mat1\n",
    "mat1[:,0] = matT1[:,0]*1000\n",
    "mat1[:,1] = matT1[:,1]*1000\n",
    "mat1[:,2] = matT1[:,2]*1000\n",
    "mat1[:,3] = matT1[:,3]*1000\n",
    "sumTmp =  sum(mat1)\n",
    "print(sumTmp)\n",
    "print(mat1)\n",
    "\n",
    "##########################################计算最佳合并位置，根据最大的正确率提高\n",
    "def computeAccuracyDiff(mat1,accy):\n",
    "    h,w = mat1.shape\n",
    "    tmp = np.zeros((h-1,w-1))\n",
    "    matTmp={}\n",
    "    ##从0到最后，行列合并\n",
    "    for index in range(h-1):\n",
    "\n",
    "        tmp = np.zeros((h-1,w))\n",
    "        num = 0\n",
    "        ####行合并\n",
    "        for i in range(h):#行合并\n",
    "            if i == index:\n",
    "                tmp[num]=mat1[i]+mat1[i+1]\n",
    "                num=num+1\n",
    "                continue\n",
    "            if i== index+1:\n",
    "                continue\n",
    "\n",
    "            tmp[num]=mat1[i]\n",
    "            num=num+1\n",
    "\n",
    "        ####列合并   \n",
    "        mat2=tmp\n",
    "        tmp = np.zeros((h-1,w-1))\n",
    "        num = 0\n",
    "        for j in range(w):#列合并\n",
    "            if j == index:\n",
    "                tmp[:,num] = mat2[:,j]+mat2[:,j+1]\n",
    "                num=num+1\n",
    "                continue\n",
    "            if j== index+1:\n",
    "                continue\n",
    "\n",
    "            tmp[:,num] = mat2[:,j]\n",
    "            num=num+1\n",
    "        matTmp[index] = tmp\n",
    "        \n",
    "        #print(\"合并后的所有矩阵\")\n",
    "        #print(index,matTmp[index])#合并后的所有矩阵\n",
    "    matTmp1 = copy.deepcopy(matTmp)\n",
    "   \n",
    "    ##归一化   \n",
    "    maxDiffMat = np.zeros((len(matTmp),1))\n",
    "    for i in range(len(matTmp)):\n",
    "        tmp = matTmp[i]\n",
    "        sumTmp =  sum(tmp)\n",
    "        for j in range(tmp.shape[1]):\n",
    "            tmp[:,j] = tmp[:,j]/(sumTmp[j])\n",
    "\n",
    "        accyNow = tmp[i,i]\n",
    "        maxDiffMat[i]= max(accyNow-accy[i],accyNow-accy[i+1])\n",
    "    maxIndex = np.argmax(maxDiffMat)\n",
    "    maxDiff = max(maxDiffMat)\n",
    "    #print(matTmp1)\n",
    "    return maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1\n",
    "\n",
    "#为了思考，不用for循环，直接一步一步做\n",
    "#4到3\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(matTmp1[maxIndex])\n",
    "\n",
    "#3到2\n",
    "mat3to2=matTmp1[maxIndex]\n",
    "accy3to2 = [matTmp[maxIndex][0,0],matTmp[maxIndex][1,1],matTmp[maxIndex][2,2]]\n",
    "maxIndex3to2,maxDiff3to2,maxDiffMat3to2,matTmp3to2,matTmp3to2Origin =computeAccuracyDiff(mat3to2,accy3to2)\n",
    "chosedMat = matTmp3to2Origin[maxIndex3to2]\n",
    "print(\"最佳合并点和矩阵\",maxIndex3to2,maxDiff3to2)\n",
    "print(matTmp3to2Origin[maxIndex3to2])\n",
    "print(matTmp3to2[maxIndex3to2])\n",
    "\n",
    "\n",
    "#########################################采用数据进行分析\n",
    "print(\"\\n\\n\\n###################################################\")\n",
    "print(\"\\n\\n\\n 用第5层数据进行分析\")\n",
    "h3_yp = ypredict[:,2]\n",
    "h3_yl = ylabel[:,2]\n",
    "mat1 = confusion_matrix(h3_yl,h3_yp)\n",
    "p1 = confusion_matrix(h3_yl,h3_yp,normalize='pred')\n",
    "sumTmp = sum(mat1)\n",
    "print(mat1)\n",
    "print(sumTmp)\n",
    "print(np.around(p1, decimals=3))\n",
    "\n",
    "########5->4\n",
    "accy = [p1[0,0],p1[1,1],p1[2,2],p1[3,3],p1[4,4]]\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n5->4,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(matTmp1[maxIndex])\n",
    "print(np.around(matTmp[maxIndex], decimals=3))\n",
    "\n",
    "########4->3\n",
    "mat1=matTmp1[maxIndex]\n",
    "accy= [matTmp[maxIndex][0,0],matTmp[maxIndex][1,1],matTmp[maxIndex][2,2],matTmp[maxIndex][3,3]]\n",
    "\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n4->3,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(matTmp1[maxIndex])\n",
    "print(np.around(matTmp[maxIndex], decimals=3))\n",
    "\n",
    "\n",
    "########3->2\n",
    "mat1=matTmp1[maxIndex]\n",
    "accy= [matTmp[maxIndex][0,0],matTmp[maxIndex][1,1],matTmp[maxIndex][2,2]]\n",
    "\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n3->2,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(matTmp1[maxIndex])\n",
    "print(np.around(matTmp[maxIndex], decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c03564",
   "metadata": {},
   "outputs": [],
   "source": [
    "##测试最简注意力机制，Attention Channel ,SEAttention\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils.vis_utils import plot_model\n",
    "np.random.seed(1337)  # for reproducibility\n",
    " \n",
    "from keras.models import *\n",
    "from keras.layers import Input, Dense,Multiply,Activation\n",
    " \n",
    "input_dim = 4\n",
    "\n",
    "\n",
    "def get_data(n, input_dim, attention_column=1):\n",
    "\n",
    "    x = np.random.standard_normal(size=(n, input_dim))\n",
    "    y = np.random.randint(low=0, high=2, size=(n, 1))\n",
    "    x[:, attention_column] = y[:, 0]\n",
    "    return x, y\n",
    "\n",
    " \n",
    " \n",
    "def Att(att_dim,inputs,name):\n",
    "    V = inputs\n",
    "    QK = Dense(att_dim,bias=None)(inputs)\n",
    "    QK = Activation(\"softmax\",name=name)(QK)\n",
    "    MV = Multiply()([V, QK])\n",
    "    return(MV)\n",
    " \n",
    " \n",
    "def build_model():\n",
    "    inputs = Input(shape=(input_dim,))\n",
    " \n",
    "    atts1 = Att(input_dim,inputs,\"attention_vec\")\n",
    " \n",
    "    x = Dense(16)(atts1)\n",
    "    atts2 = Att(16,x,\"attention_vec1\")\n",
    " \n",
    " \n",
    "    output = Dense(1, activation='sigmoid')(atts2)\n",
    "    model = Model(input=inputs, output=output)\n",
    "    return model\n",
    "\n",
    "N = 10000\n",
    "inputs_1, outputs = get_data(N, input_dim) \n",
    "print(inputs_1)\n",
    " \n",
    "m = build_model()\n",
    "plot_model(m, to_file='attMap.png', show_shapes=True)\n",
    "#m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#print(m.summary())\n",
    "#m.fit(inputs_1, outputs, epochs=20, batch_size=128, validation_split=0.2)testing_inputs_1, testing_outputs = get_data(1, input_dim)\n",
    "\n",
    "\n",
    "#原文链接：https://blog.csdn.net/xiaosongshine/article/details/90579679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://blog.csdn.net/SKIp121whats112/article/details/122265766\n",
    "#https://scikit-learn.org/stable/modules/tree.html\n",
    "##############测试决策树\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "Input= x\n",
    "Output = ylabel[:,2]\n",
    "print(x)\n",
    "print(Output)\n",
    "dt = tree.DecisionTreeClassifier(max_depth=5,min_samples_split=100,min_samples_leaf=100,min_impurity_decrease=0.001)\n",
    "dt = dt.fit(Input, Output)\n",
    "tree.plot_tree(dt)\n",
    "data=tree.export_graphviz(dt, out_file=None,class_names=['0','1','2','3','4'],filled=True) \n",
    "graph = graphviz.Source(data)\n",
    "graph.render(\"now\")\n",
    "\n",
    "data=tree.export_graphviz(dt, out_file=None,class_names=['0','1','2','3','4'],filled=True,proportion=True) \n",
    "graph = graphviz.Source(data)\n",
    "graph.render(\"nowPercent\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "OutPredict = dt.predict(Input)\n",
    "\n",
    "tmp1 = classification_report(Output,OutPredict )\n",
    "tmp2 = confusion_matrix(Output,OutPredict ,normalize='true')\n",
    "tmp3 = confusion_matrix(Output,OutPredict ,normalize='pred')\n",
    "print(tmp1)\n",
    "print(np.around(tmp2, decimals=3))\n",
    "print(np.around(tmp3, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a7996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试决策树的特征\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "###测试权重\n",
    "nSamples =5000\n",
    "input_dim = 10\n",
    "#x = np.random.standard_normal(size=(nSamples, input_dim))\n",
    "x = np.random.randint(low=0, high=10, size=(nSamples, input_dim))\n",
    "y1 = np.zeros((nSamples, 1))#>50\n",
    "y1A = np.zeros((nSamples, 1))#>50 and <60\n",
    "y1B = np.zeros((nSamples, 1))#>=60\n",
    "sumX = np.sum(x,axis=1)\n",
    "index=np.where(sumX>40)\n",
    "y1[index]=1\n",
    "index=np.where((sumX>50)& (sumX<70))\n",
    "y1A[index]=1\n",
    "index=np.where(sumX>=70)\n",
    "y1B[index]=1\n",
    "\n",
    "##数据来源2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "file1 = \"./trainData/dataAllSim1000.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "xyData = np.array(xyDataTmp)\n",
    "nSamples, nDims= xyData.shape\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "ylabel = y\n",
    "y1= y[:,0]\n",
    "\n",
    "\n",
    "##################################################################\n",
    "#测试决策树\n",
    "def dtFitAndSave(x,y,class_names1,saveName):\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=7,min_samples_split=100,min_samples_leaf=100,min_impurity_split=0.06,ccp_alpha=0.001)\n",
    "    dt = dt.fit(x, y)\n",
    "    tree.plot_tree(dt)\n",
    "    data=tree.export_graphviz(dt, out_file=None,class_names=class_names1,filled=True) \n",
    "    graph = graphviz.Source(data)\n",
    "    graph.render(saveName)\n",
    "    \n",
    "    yPredict = dt.predict(x)\n",
    "    tmp1 = classification_report(y,yPredict)\n",
    "    print(tmp1)\n",
    "    text_representation = tree.export_text(dt)\n",
    "    #print(text_representation)\n",
    "    #yPredict = dt.predict_proba(x)\n",
    "    #index = np.where((yPredict[:,1]<0.98)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.90)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.80)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.70)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    \n",
    "    yPredict = dt.predict_proba(x[0:3,:])\n",
    "    print(yPredict[:,1])\n",
    "    d_path = dt.decision_path(x[0:3,:]).todense()\n",
    "    print(d_path)\n",
    "    print(\"impurity\",dt.tree_.impurity)\n",
    "    print(\"feature\",dt.tree_.feature)\n",
    "    print(\"threshold\",dt.tree_.threshold)\n",
    "    \n",
    "    #左节点编号  :  clf.tree_.children_left\n",
    "    #右节点编号  :  clf.tree_.children_right\n",
    "    #分割的变量  :  clf.tree_.feature\n",
    "    #分割的阈值  :  clf.tree_.threshold\n",
    "    #不纯度(gini) :  clf.tree_.impurity\n",
    "    #样本个数      :  clf.tree_.n_node_samples\n",
    "    #样本分布      :  clf.tree_.value\n",
    "    #https://blog.csdn.net/ywj_1991/article/details/122985778\n",
    "    #https://www.javaroad.cn/questions/54003\n",
    "\n",
    "    w,h = d_path.shape\n",
    "    for i in range(h):\n",
    "       path = d_path[i]\n",
    "       v,ind = np.where(path>0)\n",
    "       xtmp = x[i]\n",
    "       #print(\"path\",path,ind,np.array(ind)[-1])\n",
    "    \n",
    "       print(\"\\n index\",index)\n",
    "       print(\"impurity\",dt.tree_.impurity[ind])\n",
    "       print(\"feature\",dt.tree_.feature[ind])\n",
    "       print(\"threshold\",dt.tree_.threshold[ind])\n",
    "       print(\"x[index]\",xtmp[ind])\n",
    "       \n",
    "      \n",
    "       print(\"the leaf node:\",np.array(ind)[-1],\"the simplest rule is\")\n",
    "       for jj in ind:\n",
    "           if dt.tree_.feature[jj] == -2:\n",
    "                print(\"label,proba is\",yPredict[i,0],yPredict[i,1])\n",
    "                break\n",
    "                \n",
    "           if xtmp[jj]<=dt.tree_.threshold[jj]:\n",
    "              print(\" x[%d]<=%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "           else:\n",
    "              print(\" x[%d]>%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "                    \n",
    "       finalPos = np.array(ind)[-1]\n",
    "       print(dt.tree_.impurity[finalPos])\n",
    "       print(dt.tree_.feature[finalPos])\n",
    "       print(dt.tree_.threshold[finalPos])\n",
    "\n",
    "dtFitAndSave(x,y1,[\"0\",\"1\"],\"bigger\")\n",
    "\n",
    "###################################################################################\n",
    "#测试神经网络\n",
    "def kerasFitAndSave(x,y,num_labels):\n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 384\n",
    "    dropout_rate =0.1\n",
    "    models=[]\n",
    "    \n",
    "    build_model = tf.keras.Sequential()\n",
    "   \n",
    "    build_model.add(layers.Dense(relu_size, activation='relu',name=\"layer1\",input_shape=(features_size,)))\n",
    "    build_model.add(layers.Dropout(dropout_rate,name=\"Dropout1-2\"))\n",
    "    build_model.add(layers.Dense(num_labels, activation='sigmoid',name=\"layer2\"))\n",
    "    \n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    plot_model(build_model, to_file='AKeras.png', show_shapes=True)\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(y)  \n",
    "    yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    build_model.fit([x],[yOnehot],epochs=100, batch_size=80000*1)\n",
    "    build_model.save(\"Akeras.h5\")\n",
    "    plot_model(build_model, to_file='AKeras.png', show_shapes=True)\n",
    "    \n",
    "    return build_model,models\n",
    "\n",
    "def kerasFitAndSaveSimple(x,y,num_labels):\n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 382\n",
    "    models=[]\n",
    "    \n",
    "    build_model = tf.keras.Sequential()\n",
    "    build_model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    build_model.add(layers.Dropout(dropout_rate))\n",
    "    build_model.add(layers.Dense(num_labels, activation='sigmoid'))\n",
    "    build_model.add(layers.Dense(num_labels, activation='sigmoid',name=\"layer1\",input_shape=(features_size,)))\n",
    "    \n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    plot_model(build_model, to_file='AKerasSimple.png', show_shapes=True)\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(y)  \n",
    "    yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    build_model.fit([x],[yOnehot],epochs=10000, batch_size=80000*1)\n",
    "    build_model.save(\"Akeras.h5\")\n",
    "    plot_model(build_model, to_file='AKeras.png', show_shapes=True)\n",
    "    \n",
    "    return build_model,models\n",
    "\n",
    "y1 = np.array(y1)\n",
    "y1= y1.reshape(nSamples,-1)\n",
    "print(y1)\n",
    "#kerasFitAndSave(x,y1,2)\n",
    "#kerasFitAndSaveSimple(x,y1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################融合决策树和多层神经网络###########################################################\n",
    "\n",
    "#######################################第一步读取数据\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "file1 = \"./trainData/dataAllSim1000.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "xyData = np.array(xyDataTmp)\n",
    "nSamples, nDims= xyData.shape\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "ylabel = y\n",
    "y1Level= y[:,0]#01\n",
    "y2Level= y[:,1]#012\n",
    "y3Level= y[:,2]#01234\n",
    "\n",
    "print(\"x.shape:\",x.shape,\"y.shape:\",y.shape)\n",
    "\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d03be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################融合决策树和多层神经网络###########################################################\n",
    "\n",
    "#######################################第二步基于神经网络训练，这里采用简单神经网络，RESNET类似和HNCF三种方法进行训练\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "###简单模型1，没有隐藏层\n",
    "def kerasFitAndSaveSimple1(x,yOneHot,num_labels):\n",
    "    nSamples,features_size = x.shape\n",
    "    build_model = tf.keras.Sequential()\n",
    "    build_model.add(layers.Dense(num_labels, activation='sigmoid',name=\"layer1\",input_shape=(features_size,)))\n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    \n",
    "    #enc = OneHotEncoder()\n",
    "    #enc.fit(y)  \n",
    "    #yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    build_model.fit([x],[yOneHot],epochs=10000, batch_size=80000*1)\n",
    "    build_model.save(\"kerasSimple1.h5\")\n",
    "    plot_model(build_model, to_file='KerasSimple1_noHiddenLayer.png', show_shapes=True)\n",
    "    return build_model\n",
    "\n",
    "###简单模型2，有隐藏层\n",
    "def kerasFitAndSaveSimple2(x,yOneHot,num_labels):\n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 512\n",
    "    dropout_rate = 0.05\n",
    "    build_model = tf.keras.Sequential()\n",
    "    build_model.add(layers.Dense(relu_size, activation='relu',name=\"layer1\",input_shape=(features_size,)))\n",
    "    build_model.add(layers.Dropout(dropout_rate,name=\"Dropout1-2\"))\n",
    "    build_model.add(layers.Dense(relu_size/2, activation='relu',name=\"layer2\"))\n",
    "    build_model.add(layers.Dropout(dropout_rate,name=\"Dropout2-3\"))\n",
    "    build_model.add(layers.Dense(num_labels, activation='sigmoid',name=\"layer3\"))\n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    #enc = OneHotEncoder()\n",
    "    #enc.fit(y)  \n",
    "    #yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    build_model.fit([x],[yOneHot],epochs=10000, batch_size=80000*1)\n",
    "    build_model.save(\"kerasSimple2.h5\")\n",
    "    plot_model(build_model, to_file='KerasSimple2_HiddenLayer.png', show_shapes=True)\n",
    "    return build_model\n",
    "\n",
    "###简单模型3，resnet_like\n",
    "def global_model(dropout_rate, relu_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    return model\n",
    "\n",
    "def sigmoid_model(label_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(label_size, activation='sigmoid',name=\"global\"))\n",
    "    return model\n",
    "\n",
    "def kerasFitAndSaveSimple3LikeResnet(x,yOneHot,num_labels):\n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 512\n",
    "    dropout_rate = 0.05\n",
    "    hierarchy = [1,1,1]\n",
    "    global_models = []\n",
    "    features = layers.Input(shape=(features_size,))\n",
    "    for i in range(len(hierarchy)):\n",
    "        if i == 0:\n",
    "            global_models.append(global_model(dropout_rate, relu_size)(features))\n",
    "        else:\n",
    "            global_models.append(global_model(dropout_rate, relu_size)(layers.concatenate([global_models[i-1], features])))\n",
    "\n",
    "    p_glob = sigmoid_model(label_size)(global_models[-1])\n",
    "    build_model = tf.keras.Model(inputs=[features], outputs=[p_glob])\n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    #enc = OneHotEncoder()\n",
    "    #enc.fit(y)  \n",
    "    #yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    build_model.fit([x],[yOneHot],epochs=10000, batch_size=80000*1)\n",
    "    build_model.save(\"KerasSimple3_likeResnet.h5\")\n",
    "    plot_model(build_model, to_file='KerasSimple3_likeResnet.png', show_shapes=True)\n",
    "    return build_model\n",
    "    print(\"HMCNF is not implemented\")\n",
    "    return False\n",
    "\n",
    "nSamples,features_size = x.shape\n",
    "num_labels = 5\n",
    "enc = OneHotEncoder()\n",
    "y3Level = np.array(y3Level)\n",
    "y3Level= y3Level.reshape(nSamples,-1)\n",
    "print(y3Level)\n",
    "enc.fit(y3Level)  \n",
    "\n",
    "###开始训练\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y3Level, test_size = 0.5)\n",
    "\n",
    "\n",
    "x = x_train\n",
    "yOneHot=enc.transform(y_train).toarray()\n",
    "print(yOneHot)\n",
    "#simpleMode1 = kerasFitAndSaveSimple1(x,yOneHot,num_labels)\n",
    "simpleMode2 = kerasFitAndSaveSimple2(x,yOneHot,num_labels)\n",
    "#simpleMode3 = kerasFitAndSaveSimple3(x,yOneHot,num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################融合决策树和多层神经网络###########################################################\n",
    "#######################################第三步根据识别结果，进行聚类聚类\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "import copy\n",
    "\n",
    "####################################################################\n",
    "file1 = \"./trainData/dataAllSim1000.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "ylabel = y\n",
    "print(\"x.shape:\",x.shape,\"y.shape:\",y.shape)\n",
    "\n",
    "\n",
    "\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "#################################################################\n",
    "\n",
    "if 0:#采用keras\n",
    "    model_name =\"kerasSimple2.h5\" \n",
    "    model = keras.models.load_model(model_name)\n",
    "    yP5= model.predict([x], batch_size=2560)\n",
    "\n",
    "    ###需要将预测出的值，转换01整数,并转为数字式\n",
    "    for i in range(yP5.shape[0]):\n",
    "        tmp = yP5[i]\n",
    "        index=  np.argmax(tmp)\n",
    "        yP5[i] = [0,0,0,0,0]\n",
    "        yP5[i,index]=1\n",
    "    print(yP5)\n",
    "\n",
    "    ###\n",
    "    enc = OneHotEncoder()\n",
    "    yl5= y[:,2]#01234\n",
    "    yl5 = np.array(yl5)\n",
    "    yl5= yl5.reshape(nSamples,-1)\n",
    "    print(yl5)\n",
    "    enc.fit(yl5)\n",
    "\n",
    "    yP5= enc.inverse_transform(yP5)\n",
    "    yP5= yP5.reshape(-1,nSamples)[0]\n",
    "    ########\n",
    "\n",
    "\n",
    "\n",
    "    print(yP5)\n",
    "    print(yP5.shape)\n",
    "\n",
    "    print(yl5)\n",
    "    print(yl5.shape)\n",
    "\n",
    "if 1:#采用决策树\n",
    "    yl5= y[:,2]#01234\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=10,min_samples_leaf=100)\n",
    "    dt = dt.fit(x, yl5)\n",
    "    yPredict = dt.predict(x)\n",
    "    tmp1 = classification_report(yl5,yPredict)\n",
    "    print(tmp1)\n",
    "    mat1num = confusion_matrix(yl5,yPredict)\n",
    "    mat2acc = confusion_matrix(yl5,yPredict,normalize='pred')\n",
    "    print(mat1num)\n",
    "    print(np.around(mat2acc , decimals=3))\n",
    "    yP5 = yPredict\n",
    "\n",
    "###################################开始合并\n",
    "hierachFloor = dict()\n",
    "hierachFloor ['input'] = x\n",
    "hierachFloor ['output'] = y\n",
    "\n",
    "                               \n",
    "                                    \n",
    "                                    \n",
    "#0层为原始输入层\n",
    "mat1num = confusion_matrix(yl5 ,yP5)\n",
    "mat2acc = confusion_matrix(yl5,yP5,normalize='pred')\n",
    "print(mat1num)\n",
    "print(np.around(mat2acc , decimals=3))\n",
    "hierachFloor ['floor0'] = {'label':['0','1','2','3','4'],'num_mat': mat1num,'prob_mat': mat2acc}\n",
    "                                    \n",
    "\n",
    "def computeAccuracyDiff(mat1,accy):\n",
    "    h,w = mat1.shape\n",
    "    tmp = np.zeros((h-1,w-1))\n",
    "    matTmp={}\n",
    "    ##从0到最后，行列合并\n",
    "    for index in range(h-1):\n",
    "\n",
    "        tmp = np.zeros((h-1,w))\n",
    "        num = 0\n",
    "        ####行合并\n",
    "        for i in range(h):#行合并\n",
    "            if i == index:\n",
    "                tmp[num]=mat1[i]+mat1[i+1]\n",
    "                num=num+1\n",
    "                continue\n",
    "            if i== index+1:\n",
    "                continue\n",
    "\n",
    "            tmp[num]=mat1[i]\n",
    "            num=num+1\n",
    "\n",
    "        ####列合并   \n",
    "        mat2=tmp\n",
    "        tmp = np.zeros((h-1,w-1))\n",
    "        num = 0\n",
    "        for j in range(w):#列合并\n",
    "            if j == index:\n",
    "                tmp[:,num] = mat2[:,j]+mat2[:,j+1]\n",
    "                num=num+1\n",
    "                continue\n",
    "            if j== index+1:\n",
    "                continue\n",
    "\n",
    "            tmp[:,num] = mat2[:,j]\n",
    "            num=num+1\n",
    "        matTmp[index] = tmp\n",
    "        \n",
    "        #print(\"合并后的所有矩阵\")\n",
    "        #print(index,matTmp[index])#合并后的所有矩阵\n",
    "    matTmp1 = copy.deepcopy(matTmp)\n",
    "   \n",
    "    ##归一化   \n",
    "    maxDiffMat = np.zeros((len(matTmp),1))\n",
    "    for i in range(len(matTmp)):\n",
    "        tmp = matTmp[i]\n",
    "        sumTmp =  sum(tmp)\n",
    "        for j in range(tmp.shape[1]):\n",
    "            tmp[:,j] = tmp[:,j]/(sumTmp[j])\n",
    "\n",
    "        accyNow = tmp[i,i]\n",
    "        maxDiffMat[i]= max(accyNow-accy[i],accyNow-accy[i+1])\n",
    "    maxIndex = np.argmax(maxDiffMat)\n",
    "    maxDiff = max(maxDiffMat)\n",
    "    #print(matTmp1)\n",
    "    return maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1\n",
    "#print(\"最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "#print(“所有合并后的所有矩阵，数目和概率\",matTmp,matTmp1)\n",
    "#print(“各个点合并后的正确率提升矩阵\",maxDiffMat)\n",
    "\n",
    "print(\"\\n\\n\\n###################################################\")\n",
    "print(\"\\n\\n\\n 用数据进行分析\")\n",
    "\n",
    "#1层为5到4层\n",
    "accy = [mat2acc[0,0],mat2acc[1,1],mat2acc[2,2],mat2acc[3,3],mat2acc[4,4]]\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1num,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n5->4,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(maxDiffMat)\n",
    "print(\"数目矩阵\\n\",matTmp1[maxIndex])\n",
    "print(\"概率矩阵\\n\",np.around(matTmp[maxIndex], decimals=3))\n",
    "hierachFloor ['floor1'] = {'num_mat': matTmp1,'prob_mat': matTmp,'mergeIndex':maxIndex,'mergediffMat':maxDiffMat}\n",
    "\n",
    "###2层4->3\n",
    "mat1num=matTmp1[maxIndex]\n",
    "mat2acc= [matTmp[maxIndex][0,0],matTmp[maxIndex][1,1],matTmp[maxIndex][2,2],matTmp[maxIndex][3,3]]\n",
    "\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1num,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n4->3,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(maxDiffMat)\n",
    "print(\"数目矩阵\\n\",matTmp1[maxIndex])\n",
    "print(\"概率矩阵\\n\",np.around(matTmp[maxIndex], decimals=3))\n",
    "      \n",
    "hierachFloor ['floor2'] = {'num_mat': matTmp1,'prob_mat': matTmp,'mergeIndex':maxIndex,'mergediffMat':maxDiffMat}\n",
    " \n",
    "###3层3->2\n",
    "mat1num=matTmp1[maxIndex]\n",
    "mat2acc= [matTmp[maxIndex][0,0],matTmp[maxIndex][1,1],matTmp[maxIndex][2,2]]\n",
    "\n",
    "maxIndex,maxDiff,maxDiffMat,matTmp,matTmp1 =computeAccuracyDiff(mat1num,accy)\n",
    "chosedMat =  matTmp1[maxIndex]\n",
    "print(\"\\n\\n\\n3->2,最佳合并点和矩阵\",maxIndex,maxDiff)\n",
    "print(maxDiffMat)\n",
    "print(\"数目矩阵\\n\",matTmp1[maxIndex])\n",
    "print(\"概率矩阵\\n\",np.around(matTmp[maxIndex], decimals=3))\n",
    "      \n",
    "hierachFloor['floor3'] = {'num_mat': matTmp1,'prob_mat': matTmp,'mergeIndex':maxIndex,'mergediffMat':maxDiffMat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a13cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################融合决策树和多层神经网络###########################################################\n",
    "#######################################第四步根据聚类和识别结果，开始微调\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "import copy\n",
    "\n",
    "\n",
    "##################\n",
    "file1 = \"./trainData/dataAllSim1000.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "\n",
    "x = xyData[:,0:22]\n",
    "y = xyData[:,22:26]\n",
    "ylabel = y\n",
    "print(\"x.shape:\",x.shape,\"y.shape:\",y.shape)\n",
    "\n",
    "yl5= y[:,2]#01234\n",
    "print(\"x.shape:\",x.shape,\"yl5.shape:\",yl5.shape)\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "\n",
    "print(\"x.shape:\",x.shape,\"y.shape:\",yl5.shape,\"y.type:\", type(yl5) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "\n",
    "\n",
    "def getKerasModeFloors(x,y,saveName):\n",
    "    model_name = saveName \n",
    "    model = keras.models.load_model(model_name)\n",
    "    yP5= model.predict([x], batch_size=2560)\n",
    "    nSamples = yP5.shape[0]\n",
    "     ###需要将预测出的值，转换01整数,并转为数字式\n",
    "    for i in range(yP5.shape[0]):\n",
    "        tmp = yP5[i]\n",
    "        index=  np.argmax(tmp)\n",
    "        yP5[i] = [0,0,0,0,0]\n",
    "        yP5[i,index]=1\n",
    "   \n",
    "\n",
    "    ###\n",
    "    enc = OneHotEncoder()\n",
    "    yl5= y[:,2]#01234\n",
    "    yl5 = np.array(yl5)\n",
    "    yl5= yl5.reshape(nSamples,-1)\n",
    "    print(yl5)\n",
    "    enc.fit(yl5)\n",
    "\n",
    "    yP5= enc.inverse_transform(yP5)\n",
    "    yP5= yP5.reshape(-1,nSamples)[0]\n",
    "    \n",
    "    yP4 = np.zeros((yP5.shape[0],1))\n",
    "    yP3 = np.zeros((yP5.shape[0],1))\n",
    "    yP2 = np.zeros((yP5.shape[0],1))\n",
    "\n",
    "    for i in range(yP5.shape[0]):\n",
    "        if(yP5[i]== 2) or (yP5[i]== 1):\n",
    "             yP4[i] = 21\n",
    "        else:\n",
    "             yP4[i] = yP5[i]\n",
    "                \n",
    "        if(yP5[i]== 2) or (yP5[i]== 1) or (yP5[i]== 0):\n",
    "             yP3[i] = 210\n",
    "        else:\n",
    "             yP3[i] = yP5[i]\n",
    "                \n",
    "        if(yP5[i]== 2) or (yP5[i]== 1) or (yP5[i]== 0) or (yP5[i]== 3):\n",
    "             yP2[i] = 3210\n",
    "        else:\n",
    "             yP2[i] = yP5[i]\n",
    "    \n",
    "    return model,yP5,yP4,yP3,yP2\n",
    "\n",
    "#分层决策树\n",
    "def dtFitAndSave(x,y,saveName):\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=10,min_samples_leaf=1000)\n",
    "    dt = dt.fit(x, y)\n",
    "    tree.plot_tree(dt)\n",
    "    data=tree.export_graphviz(dt, out_file=None,class_names=None,filled=True) \n",
    "    graph = graphviz.Source(data)\n",
    "    graph.render(saveName)\n",
    "    \n",
    "    yPredict = dt.predict(x)\n",
    "    tmp1 = classification_report(y,yPredict)\n",
    "    print(tmp1)\n",
    "    mat1num = confusion_matrix(y,yPredict)\n",
    "    mat2acc = confusion_matrix(y,yPredict,normalize='pred')\n",
    "    print(mat1num)\n",
    "    print(np.around(mat2acc , decimals=3))\n",
    "    #text_representation = tree.export_text(dt)\n",
    "    #print(text_representation)\n",
    "    #yPredict = dt.predict_proba(x)\n",
    "    #index = np.where((yPredict[:,1]<0.98)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.90)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.80)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.70)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    return dt\n",
    "\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "def getDTSamplesInfo(x,dt):\n",
    "    yPredict = dt.predict_proba(x)\n",
    "    #print(\"\\n\\n getDTSamplesInfo yPredict\",yPredict)\n",
    "    d_path = dt.decision_path(x).todense()\n",
    "    #print(\"\\n\\n d_path\",d_path)\n",
    "    #print(\"impurity\",dt.tree_.impurity)\n",
    "    #print(\"feature\",dt.tree_.feature)\n",
    "    #print(\"threshold\",dt.tree_.threshold)\n",
    "    \n",
    "    #左节点编号  :  clf.tree_.children_left\n",
    "    #右节点编号  :  clf.tree_.children_right\n",
    "    #分割的变量  :  clf.tree_.feature\n",
    "    #分割的阈值  :  clf.tree_.threshold\n",
    "    #不纯度(gini) :  clf.tree_.impurity\n",
    "    #样本个数      :  clf.tree_.n_node_samples\n",
    "    #样本分布      :  clf.tree_.value\n",
    "    #https://blog.csdn.net/ywj_1991/article/details/122985778\n",
    "    #https://www.javaroad.cn/questions/54003\n",
    "    \n",
    "    h,w = d_path.shape\n",
    "    gini =np.zeros((h,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(h):\n",
    "       path = d_path[i]\n",
    "       v,ind = np.where(path>0)\n",
    "       xtmp = x[i]\n",
    "       #print(\"path\",path,ind,np.array(ind)[-1])\n",
    "    \n",
    "       #print(\"\\n index\",index)\n",
    "       #print(\"impurity\",dt.tree_.impurity[ind])\n",
    "       #print(\"feature\",dt.tree_.feature[ind])\n",
    "       #print(\"threshold\",dt.tree_.threshold[ind])\n",
    "       #print(\"x[index]\",xtmp[ind])\n",
    "       \n",
    "      \n",
    "       #print(\"the leaf node:\",np.array(ind)[-1],\"the simplest rule is\")\n",
    "       #for jj in ind:\n",
    "       #    if dt.tree_.feature[jj] == -2:\n",
    "       #         print(\"label,proba is\",yPredict[i,0],yPredict[i,1])\n",
    "       #         break\n",
    "                \n",
    "       #    if xtmp[jj]<=dt.tree_.threshold[jj]:\n",
    "       #       print(\" x[%d]<=%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "       #    else:\n",
    "       #       print(\" x[%d]>%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "                    \n",
    "       finalPos = np.array(ind)[-1]\n",
    "       gini[i] = dt.tree_.impurity[finalPos]\n",
    "       \n",
    "       #print(\"d_path\",i,path,dt.tree_.impurity[finalPos])\n",
    "       #print(dt.tree_.feature[finalPos])\n",
    "       #print(dt.tree_.threshold[finalPos])\n",
    "       #print(dt.tree_.n_node_samples[finalPos])\n",
    "\n",
    "    \n",
    "    return gini,yPredict\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "\n",
    "index = np.where((yl5 == 2) | (yl5 == 1))\n",
    "yl4 = yl5.copy()\n",
    "yl4[index]=21\n",
    "print(yl4)\n",
    "\n",
    "\n",
    "index = np.where((yl5 == 2) | (yl5 == 1) | (yl5 == 0))\n",
    "yl3 = yl5.copy()\n",
    "yl3[index]=210\n",
    "print(yl3)\n",
    "\n",
    "\n",
    "\n",
    "index = np.where( (yl5 == 3)|(yl5 == 2) | (yl5 == 1) | (yl5 == 0))\n",
    "yl2 = yl5.copy()\n",
    "yl2[index]=3210\n",
    "print(yl2)\n",
    "\n",
    "hierachFloor['floor3'][\"dt\"] = dtFitAndSave(x,yl2,\"Floo3_2\")\n",
    "hierachFloor['floor2'][\"dt\"] = dtFitAndSave(x,yl3,\"Floo2_3\")\n",
    "hierachFloor['floor1'][\"dt\"] = dtFitAndSave(x,yl4,\"Floor1_4\")\n",
    "hierachFloor['floor0'][\"dt\"] = dtFitAndSave(x,yl5,\"Floor0_5\")\n",
    "\n",
    "#giniFloor0,yPredictProFloor0 = getDTSamplesInfo(x,hierachFloor['floor0'][\"dt\"])\n",
    "#giniFloor1,yPredictProFloor1 = getDTSamplesInfo(x,hierachFloor['floor1'][\"dt\"])\n",
    "#giniFloor2,yPredictProFloor2 = getDTSamplesInfo(x,hierachFloor['floor2'][\"dt\"])\n",
    "#giniFloor3,yPredictProFloor3 = getDTSamplesInfo(x,hierachFloor['floor3'][\"dt\"])\n",
    "\n",
    "kerasFloors,yKerasP5,yKerasP4,yKerasP3,yKerasP2=getKerasModeFloors(x,y,'kerasSimple2.h5')\n",
    "##############开始混合检测\n",
    "\n",
    "###0层，5标签\n",
    "\n",
    "'''\n",
    "nSamples,feturesNume  = x.shape\n",
    "yHyLabelFloor0 = np.zeros((nSamples,1))\n",
    "hyCounter = 0\n",
    "for i in range(nSamples):\n",
    "    print(i)\n",
    "    xtmp = x[i]\n",
    "    dt = hierachFloor['floor0'][\"dt\"]\n",
    "    giniFloor0,yPredictProFloor0 = getDTSamplesInfo([xtmp],dt)\n",
    "    giniTmp = giniFloor0[0]\n",
    "    yPredictProFloor0Tmp = yPredictProFloor0[0]\n",
    "    #print('gini',giniTmp )\n",
    "    #print('probPredict',yPredictProFloor0Tmp  )\n",
    "    if giniTmp >0.05 or max(yPredictProFloor0Tmp)<0.98:\n",
    "        yHyLabelFloor0[i] = yKerasP5[i]\n",
    "    else:\n",
    "        yHyLabelFloor0[i] = np.argmax(yPredictProFloor0)\n",
    "        hyCounter = hyCounter+1\n",
    "  \n",
    "print('O层5标签hyCounter',hyCounter)    \n",
    "\n",
    "\n",
    "tmp1 = classification_report(yl5,yHyLabelFloor0)\n",
    "print('hybrid\\n',tmp1)\n",
    "tmp1 = classification_report( yKerasP5,yHyLabelFloor0)\n",
    "print('keras\\n',tmp1)\n",
    "mat1num = confusion_matrix(yl5,yHyLabelFloor0)\n",
    "mat2acc = confusion_matrix(yl5,yHyLabelFloor0,normalize='pred')\n",
    "print('mat1num\\n',mat1num)\n",
    "print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "'''\n",
    "\n",
    "'''\n",
    "#############1层，4标签\n",
    "nSamples,feturesNume  = x.shape\n",
    "yHyLabelFloor1 = np.zeros((nSamples,1))\n",
    "hyCounter = 0\n",
    "for i in range(nSamples):\n",
    "    print(i)\n",
    "    xtmp = x[i]\n",
    "    dt = hierachFloor['floor1'][\"dt\"]\n",
    "    giniFloor1,yPredictProFloor1 = getDTSamplesInfo([xtmp],dt)\n",
    "    giniTmp = giniFloor1[0]\n",
    "    yPredictProFloor1Tmp = yPredictProFloor1[0]\n",
    "    #print('gini',giniTmp )\n",
    "    #print('probPredict',yPredictProFloor0Tmp  )\n",
    "    if giniTmp >0.05 or max(yPredictProFloor1Tmp)<0.98:\n",
    "        yHyLabelFloor1[i] = yKerasP4[i]\n",
    "    else:\n",
    "        tmp0= [0,3,4,21]\n",
    "        index = np.argmax(yPredictProFloor1)\n",
    "        yHyLabelFloor1[i] = tmp0[index]\n",
    "        hyCounter = hyCounter+1\n",
    "print('O层4标签hyCounter',hyCounter)    \n",
    "\n",
    "\n",
    "tmp1 = classification_report(yl4,yHyLabelFloor1)\n",
    "print('hybrid\\n',tmp1)\n",
    "tmp1 = classification_report( yKerasP4,yHyLabelFloor1)\n",
    "print('keras\\n',tmp1)\n",
    "mat1num = confusion_matrix(yl4,yHyLabelFloor1)\n",
    "mat2acc = confusion_matrix(yl4,yHyLabelFloor1,normalize='pred')\n",
    "print('mat1num\\n',mat1num)\n",
    "print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "'''\n",
    "\n",
    "\n",
    "def computeAndCompareHybridMode(x,y,dt,kerasPLabel,floorLabel):\n",
    "    nSamples,feturesNume  = x.shape\n",
    "    yHyLabel  = np.zeros((nSamples,1))\n",
    "    hyCounter = 0\n",
    "    for i in range(nSamples):\n",
    "        print(i)\n",
    "        xtmp = x[i]\n",
    "        giniFloor,yPredictProFloor = getDTSamplesInfo([xtmp],dt)\n",
    "        giniTmp = giniFloor[0]\n",
    "        yPredictProFloorTmp = yPredictProFloor[0]\n",
    "        #print('gini',giniTmp )\n",
    "        #print('probPredict',yPredictProFloor0Tmp  )\n",
    "        if giniTmp >0.05 or max(yPredictProFloorTmp)<0.98:\n",
    "            yHyLabel[i] = kerasPLabel[i]\n",
    "        else:\n",
    "            #floorLabel= [3,4,210]\n",
    "            index = np.argmax(yPredictProFloorTmp)\n",
    "            yHyLabel[i] = floorLabel[index]\n",
    "            hyCounter = hyCounter+1\n",
    "    print('floorLabel\\n',floorLabel) \n",
    "    print('hyCounter\\n',hyCounter)    \n",
    "\n",
    "\n",
    "    tmp1 = classification_report(y,yHyLabel)\n",
    "    print('hybrid\\n',tmp1)\n",
    "    tmp1 = classification_report(kerasPLabel,yHyLabel)\n",
    "    print('keras\\n',tmp1)\n",
    "    mat1num = confusion_matrix(y,yHyLabel)\n",
    "    mat2acc = confusion_matrix(y,yHyLabel,normalize='pred')\n",
    "    print('mat1num\\n',mat1num)\n",
    "    print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "    return\n",
    "\n",
    "#floor=2 ,label=3\n",
    "#dt = hierachFloor['floor2'][\"dt\"]\n",
    "#floorLabel= [3,4,210] \n",
    "#computeAndCompareHybridMode(x,yl3,dt,yKerasP3,floorLabel)\n",
    "\n",
    "#floor=3 ,label=2\n",
    "dt = hierachFloor['floor3'][\"dt\"]\n",
    "floorLabel= [4,3210] \n",
    "computeAndCompareHybridMode(x,yl2,dt,yKerasP2,floorLabel)\n",
    "\n",
    "return\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "'''\n",
    "for i in range(nSamples):\n",
    "    for j in range(4)\n",
    "         input1 = x[i,:]\n",
    "         label =  ylabel[i,j]\n",
    "         output1 = Floor[j][\"dt\"].predict_proba(input)\n",
    "         output_gini,output_num =getDT_Info(input)\n",
    "    \n",
    "        if max(output1)<0.95 or output_gini>0.2\n",
    "            output1 =  Floor[j][\"keras\"].predict(input)\n",
    "        \n",
    "        loss=loss+(output1-label)\n",
    "                           \n",
    "                           \n",
    "def getDT_SamplesInfo(x)\n",
    "    yPredict = dt.predict_proba(x[0:3,:])\n",
    "    print(yPredict[:,1])\n",
    "    d_path = dt.decision_path(x[0:3,:]).todense()\n",
    "    print(d_path)\n",
    "    print(\"impurity\",dt.tree_.impurity)\n",
    "    print(\"feature\",dt.tree_.feature)\n",
    "    print(\"threshold\",dt.tree_.threshold)\n",
    "    \n",
    "    #左节点编号  :  clf.tree_.children_left\n",
    "    #右节点编号  :  clf.tree_.children_right\n",
    "    #分割的变量  :  clf.tree_.feature\n",
    "    #分割的阈值  :  clf.tree_.threshold\n",
    "    #不纯度(gini) :  clf.tree_.impurity\n",
    "    #样本个数      :  clf.tree_.n_node_samples\n",
    "    #样本分布      :  clf.tree_.value\n",
    "    #https://blog.csdn.net/ywj_1991/article/details/122985778\n",
    "    #https://www.javaroad.cn/questions/54003\n",
    "\n",
    "    w,h = d_path.shape\n",
    "    for i in range(h):\n",
    "       path = d_path[i]\n",
    "       v,ind = np.where(path>0)\n",
    "       xtmp = x[i]\n",
    "       #print(\"path\",path,ind,np.array(ind)[-1])\n",
    "    \n",
    "       print(\"\\n index\",index)\n",
    "       print(\"impurity\",dt.tree_.impurity[ind])\n",
    "       print(\"feature\",dt.tree_.feature[ind])\n",
    "       print(\"threshold\",dt.tree_.threshold[ind])\n",
    "       print(\"x[index]\",xtmp[ind])\n",
    "       \n",
    "      \n",
    "       print(\"the leaf node:\",np.array(ind)[-1],\"the simplest rule is\")\n",
    "       for jj in ind:\n",
    "           if dt.tree_.feature[jj] == -2:\n",
    "                print(\"label,proba is\",yPredict[i,0],yPredict[i,1])\n",
    "                break\n",
    "                \n",
    "           if xtmp[jj]<=dt.tree_.threshold[jj]:\n",
    "              print(\" x[%d]<=%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "           else:\n",
    "              print(\" x[%d]>%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "                    \n",
    "       finalPos = np.array(ind)[-1]\n",
    "       print(dt.tree_.impurity[finalPos])\n",
    "       print(dt.tree_.feature[finalPos])\n",
    "       print(dt.tree_.threshold[finalPos])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f9ead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "print(\"建立多层独立决策树混合模型\")\n",
    "#############################################################\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "#import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "\n",
    "\n",
    "def getKerasModeFloors2(x,enc,saveName):\n",
    "    model_name = saveName \n",
    "    model = keras.models.load_model(model_name)\n",
    "    yP5= model.predict([x], batch_size=2560)\n",
    "    nSamples = yP5.shape[0]\n",
    "     ###需要将预测出的值，转换01整数,并转为数字式\n",
    "    for i in range(yP5.shape[0]):\n",
    "        tmp = yP5[i]\n",
    "        index=  np.argmax(tmp)\n",
    "        yP5[i] = [0,0,0,0,0]\n",
    "        yP5[i,index]=1\n",
    "   \n",
    "\n",
    "    ###  \n",
    "    yP5= enc.inverse_transform(yP5)\n",
    "    yP5= yP5.reshape(-1,nSamples)[0]\n",
    "    \n",
    "    yP4 = np.zeros((yP5.shape[0],1))\n",
    "    yP3 = np.zeros((yP5.shape[0],1))\n",
    "    yP2 = np.zeros((yP5.shape[0],1))\n",
    "\n",
    "    for i in range(yP5.shape[0]):\n",
    "        if(yP5[i]== 2) or (yP5[i]== 1):\n",
    "             yP4[i] = 21\n",
    "        else:\n",
    "             yP4[i] = yP5[i]\n",
    "                \n",
    "        if(yP5[i]== 2) or (yP5[i]== 1) or (yP5[i]== 0):\n",
    "             yP3[i] = 210\n",
    "        else:\n",
    "             yP3[i] = yP5[i]\n",
    "                \n",
    "        if(yP5[i]== 2) or (yP5[i]== 1) or (yP5[i]== 0) or (yP5[i]== 3):\n",
    "             yP2[i] = 3210\n",
    "        else:\n",
    "             yP2[i] = yP5[i]\n",
    "    \n",
    "    return model,yP5,yP4,yP3,yP2\n",
    "\n",
    "#分层决策树\n",
    "def dtFitAndSave(x,y,saveName):\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=7,min_samples_leaf=100)\n",
    "    dt = dt.fit(x, y)\n",
    "    #tree.plot_tree(dt)\n",
    "    #data=tree.export_graphviz(dt, out_file=None,class_names=None,filled=True) \n",
    "    #graph = graphviz.Source(data)\n",
    "    #graph.render(saveName)\n",
    "    \n",
    "    yPredict = dt.predict(x)\n",
    "    tmp1 = classification_report(y,yPredict)\n",
    "    print(\"纯决策树的识别\\n\",tmp1)\n",
    "    mat1num = confusion_matrix(y,yPredict)\n",
    "    mat2acc = confusion_matrix(y,yPredict,normalize='pred')\n",
    "    print(mat1num)\n",
    "    print(np.around(mat2acc , decimals=3))\n",
    "    #text_representation = tree.export_text(dt)\n",
    "    #print(text_representation)\n",
    "    #yPredict = dt.predict_proba(x)\n",
    "    #index = np.where((yPredict[:,1]<0.98)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.90)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.80)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.70)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    return dt\n",
    "\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "def getDTSamplesInfo(x,dt):\n",
    "    yPredict = dt.predict_proba(x)\n",
    "    #print(\"\\n\\n getDTSamplesInfo yPredict\",yPredict)\n",
    "    d_path = dt.decision_path(x).todense()\n",
    "    #print(\"\\n\\n d_path\",d_path)\n",
    "    #print(\"impurity\",dt.tree_.impurity)\n",
    "    #print(\"feature\",dt.tree_.feature)\n",
    "    #print(\"threshold\",dt.tree_.threshold)\n",
    "    \n",
    "    #左节点编号  :  clf.tree_.children_left\n",
    "    #右节点编号  :  clf.tree_.children_right\n",
    "    #分割的变量  :  clf.tree_.feature\n",
    "    #分割的阈值  :  clf.tree_.threshold\n",
    "    #不纯度(gini) :  clf.tree_.impurity\n",
    "    #样本个数      :  clf.tree_.n_node_samples\n",
    "    #样本分布      :  clf.tree_.value\n",
    "    #https://blog.csdn.net/ywj_1991/article/details/122985778\n",
    "    #https://www.javaroad.cn/questions/54003\n",
    "    \n",
    "    h,w = d_path.shape\n",
    "    gini =np.zeros((h,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(h):\n",
    "       path = d_path[i]\n",
    "       v,ind = np.where(path>0)\n",
    "       xtmp = x[i]\n",
    "       #print(\"path\",path,ind,np.array(ind)[-1])\n",
    "    \n",
    "       #print(\"\\n index\",index)\n",
    "       #print(\"impurity\",dt.tree_.impurity[ind])\n",
    "       #print(\"feature\",dt.tree_.feature[ind])\n",
    "       #print(\"threshold\",dt.tree_.threshold[ind])\n",
    "       #print(\"x[index]\",xtmp[ind])\n",
    "       \n",
    "      \n",
    "       #print(\"the leaf node:\",np.array(ind)[-1],\"the simplest rule is\")\n",
    "       #for jj in ind:\n",
    "       #    if dt.tree_.feature[jj] == -2:\n",
    "       #         print(\"label,proba is\",yPredict[i,0],yPredict[i,1])\n",
    "       #         break\n",
    "                \n",
    "       #    if xtmp[jj]<=dt.tree_.threshold[jj]:\n",
    "       #       print(\" x[%d]<=%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "       #    else:\n",
    "       #       print(\" x[%d]>%.3f\" %(dt.tree_.feature[jj],dt.tree_.threshold[jj]))\n",
    "                    \n",
    "       finalPos = np.array(ind)[-1]\n",
    "       gini[i] = dt.tree_.impurity[finalPos]\n",
    "       \n",
    "       #print(\"d_path\",i,path,dt.tree_.impurity[finalPos])\n",
    "       #print(dt.tree_.feature[finalPos])\n",
    "       #print(dt.tree_.threshold[finalPos])\n",
    "       #print(dt.tree_.n_node_samples[finalPos])\n",
    "\n",
    "    \n",
    "       return gini,yPredict\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "def computeAndCompareHybridMode(x,y,dt,kerasPLabel,floorLabel):\n",
    "    nSamples,feturesNume  = x.shape\n",
    "    yHyLabel  = np.zeros((nSamples,1))\n",
    "    giniFloor,yPredictProFloor = getDTSamplesInfo(x,dt)\n",
    "    prdictMax = np.max(yPredictProFloor,axis=1)\n",
    "    \n",
    "    \n",
    "    index1 = np.argmax(yPredictProFloor, axis = 1)\n",
    "    index1 = index1.astype('int64')\n",
    "    hyCounter = nSamples\n",
    "    for i in range(nSamples):\n",
    "        yHyLabel[i] = floorLabel[index1[i]]\n",
    "        giniTmp = giniFloor[i]\n",
    "        probaTmp = prdictMax[i]\n",
    "        if giniTmp>0.1 or probaTmp<0.95:\n",
    "            yHyLabel[i] = kerasPLabel[i]\n",
    "            hyCounter = hyCounter-1\n",
    "        \n",
    "\n",
    "    print(\"混合识别的结果\\n\")\n",
    "    print('floorLabel\\n',floorLabel) \n",
    "    print('hyCounter\\n',hyCounter)    \n",
    "\n",
    "\n",
    "    tmp1 = classification_report(y,yHyLabel)\n",
    "    print('hybrid\\n',tmp1)\n",
    "    tmp1 = classification_report(y,kerasPLabel)\n",
    "    print('keras\\n',tmp1)\n",
    "    mat1num = confusion_matrix(y,yHyLabel)\n",
    "    mat2acc = confusion_matrix(y,yHyLabel,normalize='pred')\n",
    "    print('mat1num\\n',mat1num)\n",
    "    print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "    return\n",
    "'''\n",
    "from tqdm import tqdm\n",
    "\n",
    "def computeAndCompareHybridMode(x,y,dt,kerasPLabel,floorLabel):\n",
    "    nSamples,feturesNume  = x.shape\n",
    "    yHyLabel  = np.zeros((nSamples,1))\n",
    "    hyCounter = 0\n",
    "    for i in tqdm(range(nSamples)):\n",
    "        #print(i)\n",
    "        xtmp = x[i]\n",
    "        giniFloor,yPredictProFloor = getDTSamplesInfo([xtmp],dt)\n",
    "        giniTmp = giniFloor[0]\n",
    "        yPredictProFloorTmp = yPredictProFloor[0]\n",
    "        #print('gini',giniTmp )\n",
    "        #print('probPredict',yPredictProFloor0Tmp  )\n",
    "        if giniTmp >0.05 or max(yPredictProFloorTmp)<0.98:\n",
    "            yHyLabel[i] = kerasPLabel[i]\n",
    "        else:\n",
    "            #floorLabel= [3,4,210]\n",
    "            index = np.argmax(yPredictProFloorTmp)\n",
    "            yHyLabel[i] = floorLabel[index]\n",
    "            hyCounter = hyCounter+1\n",
    "    print('floorLabel\\n',floorLabel) \n",
    "    print('hyCounter\\n',hyCounter)    \n",
    "\n",
    "\n",
    "    tmp1 = classification_report(y,yHyLabel)\n",
    "    print('hybrid\\n',tmp1)\n",
    "    tmp1 = classification_report(y,kerasPLabel)\n",
    "    print('keras\\n',tmp1)\n",
    "    mat1num = confusion_matrix(y,yHyLabel)\n",
    "    mat2acc = confusion_matrix(y,yHyLabel,normalize='pred')\n",
    "    print('mat1num\\n',mat1num)\n",
    "    print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "    return\n",
    "'''\n",
    "##########################################################################\n",
    "###简单模型2，有隐藏层\n",
    "def kerasFitAndSaveSimple2(x,yOneHot,num_labels,filename):\n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 512\n",
    "    dropout_rate = 0.05\n",
    "    build_model = tf.keras.Sequential()\n",
    "    build_model.add(layers.Dense(relu_size, activation='relu',name=\"layer1\",input_shape=(features_size,)))\n",
    "    build_model.add(layers.Dropout(dropout_rate,name=\"Dropout1-2\"))\n",
    "    build_model.add(layers.Dense(relu_size/2, activation='relu',name=\"layer2\"))\n",
    "    build_model.add(layers.Dropout(dropout_rate,name=\"Dropout2-3\"))\n",
    "    build_model.add(layers.Dense(num_labels, activation='sigmoid',name=\"layer3\"))\n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    #enc = OneHotEncoder()\n",
    "    #enc.fit(y)  \n",
    "    #yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    build_model = keras.models.load_model(filename)\n",
    "    \n",
    "    build_model.fit([x],[yOneHot],epochs=3000, batch_size=10000*1)\n",
    "    #build_model.fit(x,yOneHot,epochs=1000, batch_size=80000*1)#GPU用这个\n",
    "    #build_model.save(\"kerasSimple2.h5\")\n",
    "    build_model.save(filename)\n",
    "    plot_model(build_model, to_file='KerasSimple2_HiddenLayer.png', show_shapes=True)\n",
    "    return build_model\n",
    "\n",
    "###简单模型3，resnet_like\n",
    "\n",
    "def global_model(dropout_rate, relu_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    return model\n",
    "\n",
    "def sigmoid_model(label_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(label_size, activation='sigmoid',name=\"global\"))\n",
    "    return model\n",
    "\n",
    "def kerasFitAndSaveSimple3LikeResnet(x,yOneHot,num_labels,saveName):\n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 512\n",
    "    dropout_rate = 0.05\n",
    "    hierarchy = [1,1,1]\n",
    "    global_models = []\n",
    "    label_size = num_labels\n",
    "    features = layers.Input(shape=(features_size,))\n",
    "    for i in range(len(hierarchy)):\n",
    "        if i == 0:\n",
    "            global_models.append(global_model(dropout_rate, relu_size)(features))\n",
    "        else:\n",
    "            global_models.append(global_model(dropout_rate, relu_size)(layers.concatenate([global_models[i-1], features])))\n",
    "\n",
    "    p_glob = sigmoid_model(label_size)(global_models[-1])\n",
    "    build_model = tf.keras.Model(inputs=[features], outputs=[p_glob])\n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    #enc = OneHotEncoder()\n",
    "    #enc.fit(y)  \n",
    "    #yOnehot=enc.transform(y).toarray()\n",
    "    \n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    build_model = keras.models.load_model(saveName)\n",
    "    #build_model.fit([x],[yOneHot],epochs=100, batch_size=10000*1)\n",
    "    build_model.fit(x,yOneHot,epochs=10000, batch_size=10000*1)#GPU用这个\n",
    "    #saveName = \"KerasSimple3_likeResnet.h5\"\n",
    "    build_model.save(saveName)\n",
    "    #plot_model(build_model, to_file='KerasSimple3_likeResnet.png', show_shapes=True)\n",
    "    return build_model\n",
    "\n",
    "def getKerasResnetRVL(x,enc,saveName):\n",
    "    model_name = saveName \n",
    "    model = keras.models.load_model(model_name)\n",
    "    y= model.predict([x], batch_size=2560)\n",
    "    nSamples = y.shape[0]\n",
    "    ###需要将预测出的值，转换01整数,并转为数字式\n",
    "    for i in range(y.shape[0]):\n",
    "        tmp = y[i]\n",
    "        index=  np.argmax(tmp)\n",
    "        y[i] = [0]*y.shape[1]\n",
    "        y[i,index]=1\n",
    "   \n",
    "\n",
    "    ###  \n",
    "    y= enc.inverse_transform(y)\n",
    "    y= y.reshape(-1,nSamples)[0]\n",
    "    return y\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "####用法国数据进行验证\n",
    "#############################################################\n",
    "print(\"建立多层独立决策树混合模型\")\n",
    "#############################################################\n",
    "\n",
    "file1 = \"./trainData/france_0_allSamples.csv\"\n",
    "print(\"reading data france\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "h,w = xyData.shape\n",
    "x = xyData[:,1:23]#简单处理与SUMO数据库一致\n",
    "x0 = xyData[:,1:w-1]#用所有的数据\n",
    "y0 = xyData[:,w-1]\n",
    "x0=x0.astype(np.float32)#GPU 加这个\n",
    "y0=y0.astype(np.int64)#GPU 加这个\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "x,y= ros.fit_resample(x0, y0)\n",
    "\n",
    "x=x.astype(np.float32)#GPU 加这个\n",
    "y=y.astype(np.int64)#GPU 加这个\n",
    "yl5 = y\n",
    "print(\"x.shape:\",x.shape,\"y.shape:\",y.shape,\"y.type:\", type(y) )\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "\n",
    "\n",
    "\n",
    "####\n",
    "'''\n",
    "file1 = \"./trainData/dataAllSim1000.csv\"\n",
    "print(\"reading data\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "\n",
    "xSumo = xyData[:,0:22]\n",
    "ySumo = xyData[:,22:26]\n",
    "ySumo= ySumo[:,2]#01234\n",
    "ySumo= ySumo.astype('int64')\n",
    "\n",
    "print(\"x.shape:\",x.shape,\"yl5.shape:\",yl5.shape)\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "\n",
    "\n",
    "x = np.concatenate((xSumo,x))\n",
    "y = np.concatenate((ySumo,y))\n",
    "yl5 = y\n",
    "print(\"x.shape:\",x.shape,\"y.shape:\",yl5.shape,\"y.type:\", type(yl5) )\n",
    "'''\n",
    "\n",
    "##########################################################################\n",
    "###keras拟合,oneHot\n",
    "nSamples,nFeatures =  x.shape\n",
    "enc = OneHotEncoder()\n",
    "yl5= yl5.reshape(nSamples,-1)\n",
    "enc.fit(yl5)  \n",
    "\n",
    "\n",
    "\n",
    "##keraskeras拟合\n",
    "filename = \"kerasSimple2FranceDataSetAll1.h5\"\n",
    "if 0:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, yl5, test_size = 0.5)\n",
    "    yOneHot=enc.transform(y_train).toarray()\n",
    "    num_labels = 5 \n",
    "    simpleMode2 = kerasFitAndSaveSimple2(x_train,yOneHot,num_labels,filename)\n",
    "\n",
    "filename = \"KerasSimple3_likeResnet_floor4_5label.h5\"\n",
    "if 1:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, yl5, test_size = 0.01)\n",
    "    \n",
    "    yOneHot=enc.transform( y_train).toarray()\n",
    "    num_labels = 5 \n",
    "    kerasModel3_floor4_5label = kerasFitAndSaveSimple3LikeResnet(x_train,yOneHot,num_labels,filename) \n",
    "\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "\n",
    "index = np.where((yl5 == 2) | (yl5 == 1))\n",
    "yl4 = yl5.copy()\n",
    "yl4[index]=21\n",
    "#print(yl4)\n",
    "\n",
    "\n",
    "index = np.where((yl5 == 2) | (yl5 == 1) | (yl5 == 0))\n",
    "yl3 = yl5.copy()\n",
    "yl3[index]=210\n",
    "#print(yl3)\n",
    "\n",
    "\n",
    "\n",
    "index = np.where( (yl5 == 3)|(yl5 == 2) | (yl5 == 1) | (yl5 == 0))\n",
    "yl2 = yl5.copy()\n",
    "yl2[index]=3210\n",
    "#print(yl2)\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "#hierachFloor['floor3'][\"dt\"] = dtFitAndSave(x,yl2,\"Floo3_2\")\n",
    "#hierachFloor['floor2'][\"dt\"] = dtFitAndSave(x,yl3,\"Floo2_3\")\n",
    "#hierachFloor['floor1'][\"dt\"] = dtFitAndSave(x,yl4,\"Floor1_4\")\n",
    "\n",
    "#dt_floor1_2label = dtFitAndSave(x,yl2,\"Floor1_2label\")\n",
    "#dt_floor2_3label = dtFitAndSave(x,yl3,\"Floor2_3label\")\n",
    "#dt_floor3_4label = dtFitAndSave(x,yl4,\"Floor3_4label\")\n",
    "x = x0\n",
    "yl5 = y0\n",
    "dt_floor4_5label = dtFitAndSave(x,yl5,\"Floor4_5label\")\n",
    "kerasFloors,yKerasP5,yKerasP4,yKerasP3,yKerasP2=getKerasModeFloors2(x,enc,filename)\n",
    "\n",
    "\n",
    "#floor=3 ,label=2\n",
    "#dt = hierachFloor['floor3'][\"dt\"]\n",
    "\n",
    "#floorLabel= [4,3210] \n",
    "#computeAndCompareHybridMode(x,yl2,dt,yKerasP2,floorLabel)\n",
    "\n",
    "\n",
    "\n",
    "dt =dt_floor4_5label\n",
    "floorLabel= [0,1,2,3,4] \n",
    "computeAndCompareHybridMode(x,yl5,dt,yKerasP5,floorLabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "34913ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "建立多层嵌套决策树模型\n",
      "0.主程序开始，建立多层嵌套决策树模型，3080ti的GPU是AMD2400CPU 运算速度100倍\n",
      "reading data france\n",
      "x0.shape: (623140, 46) y0.shape: (623140,) y0.type: <class 'numpy.ndarray'>\n",
      "原始样本分为3210和4两类\n",
      "3210样本分为210和3两类\n",
      "x.shape: (498512, 46) y.shape: (498512,) y.type: <class 'numpy.ndarray'>\n",
      "210样本分为10和2两类\n",
      "x.shape: (373884, 46) y.shape: (373884,) y.type: <class 'numpy.ndarray'>\n",
      "[10 10 10 ...  2  2  2]\n",
      "10样本分为0和1两类\n",
      "x.shape: (249256, 46) y.shape: (249256,) y.type: <class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 1 1]\n",
      "Floor3 训练\n",
      "x.shape: (373884, 46) y.shape: (373884,) y.type: <class 'numpy.ndarray'>\n",
      "y.shape: (373884, 1) y.type: <class 'numpy.ndarray'>\n",
      "纯决策树的识别\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.66      0.94      0.77    124628\n",
      "          10       0.96      0.75      0.85    249256\n",
      "\n",
      "    accuracy                           0.82    373884\n",
      "   macro avg       0.81      0.85      0.81    373884\n",
      "weighted avg       0.86      0.82      0.82    373884\n",
      "\n",
      "[[117570   7058]\n",
      " [ 61721 187535]]\n",
      "[[0.656 0.036]\n",
      " [0.344 0.964]]\n",
      "####################################################################Floor2 训练\n",
      "x.shape: (498512, 46) y.shape: (498512,) y.type: <class 'numpy.ndarray'>\n",
      "y.shape: (498512, 1) y.type: <class 'numpy.ndarray'>\n",
      "keras\n",
      "\n",
      "mat1num\n",
      " [[124628      0]\n",
      " [    33 373851]]\n",
      "mat2acc\n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "纯决策树的识别\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.69      0.70      0.70    124628\n",
      "         210       0.90      0.90      0.90    373884\n",
      "\n",
      "    accuracy                           0.85    498512\n",
      "   macro avg       0.80      0.80      0.80    498512\n",
      "weighted avg       0.85      0.85      0.85    498512\n",
      "\n",
      "[[ 87500  37128]\n",
      " [ 38677 335207]]\n",
      "[[0.693 0.1  ]\n",
      " [0.307 0.9  ]]\n",
      "##########################################################Floor1 训练\n",
      "x.shape: (623140, 46) y.shape: (623140,) y.type: <class 'numpy.ndarray'> y.unique [   4 3210]\n",
      "y.shape: (623140, 1) y.type: <class 'numpy.ndarray'>\n",
      "keras\n",
      "\n",
      "mat1num\n",
      " [[124567     61]\n",
      " [    50 498462]]\n",
      "mat2acc\n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "纯决策树的识别\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       0.73      0.18      0.28    124628\n",
      "        3210       0.83      0.98      0.90    498512\n",
      "\n",
      "    accuracy                           0.82    623140\n",
      "   macro avg       0.78      0.58      0.59    623140\n",
      "weighted avg       0.81      0.82      0.78    623140\n",
      "\n",
      "[[ 21903 102725]\n",
      " [  8114 490398]]\n",
      "[[0.73  0.173]\n",
      " [0.27  0.827]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################################\n",
    "print(\"建立多层嵌套决策树模型\")\n",
    "#############################################################\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "#import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "import copy\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "###############################################################\n",
    "\n",
    "def dtFitAndSave(x,y,saveName):\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=7,min_samples_leaf=100)\n",
    "    dt = dt.fit(x, y)\n",
    "    tree.plot_tree(dt)\n",
    "    #data=tree.export_graphviz(dt, out_file=None,class_names=None,filled=True) \n",
    "    #graph = graphviz.Source(data)\n",
    "    #graph.render(saveName)\n",
    "    \n",
    "    yPredict = dt.predict(x)\n",
    "    tmp1 = classification_report(y,yPredict)\n",
    "    print(\"纯决策树的识别\\n\",tmp1)\n",
    "    mat1num = confusion_matrix(y,yPredict)\n",
    "    mat2acc = confusion_matrix(y,yPredict,normalize='pred')\n",
    "    print(mat1num)\n",
    "    print(np.around(mat2acc , decimals=3))\n",
    "    #text_representation = tree.export_text(dt)\n",
    "    #print(text_representation)\n",
    "    #yPredict = dt.predict_proba(x)\n",
    "    #index = np.where((yPredict[:,1]<0.98)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.90)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.80)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.70)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    return dt,yPredict\n",
    "\n",
    "###############################################################\n",
    "###简单模型3，resnet_like\n",
    "\n",
    "def global_model(dropout_rate, relu_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    return model\n",
    "\n",
    "def sigmoid_model(label_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(label_size, activation='sigmoid',name=\"global\"))\n",
    "    return model\n",
    "\n",
    "def kerasFitAndSaveSimple3LikeResnet(x,yOneHot,num_labels,saveName):\n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 512\n",
    "    dropout_rate = 0.05\n",
    "    hierarchy = [1,1,1]\n",
    "    global_models = []\n",
    "    label_size = num_labels\n",
    "    features = layers.Input(shape=(features_size,))\n",
    "    for i in range(len(hierarchy)):\n",
    "        if i == 0:\n",
    "            global_models.append(global_model(dropout_rate, relu_size)(features))\n",
    "        else:\n",
    "            global_models.append(global_model(dropout_rate, relu_size)(layers.concatenate([global_models[i-1], features])))\n",
    "\n",
    "    p_glob = sigmoid_model(label_size)(global_models[-1])\n",
    "    build_model = tf.keras.Model(inputs=[features], outputs=[p_glob])\n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    #enc = OneHotEncoder()\n",
    "    #enc.fit(y)  \n",
    "    #yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    #build_model = keras.models.load_model(saveName)\n",
    "    #build_model.fit([x],[yOneHot],epochs=10, batch_size=10000*1)\n",
    "    build_model.fit(x,yOneHot,epochs=15000, batch_size=20000*1)#GPU用这个\n",
    "    #saveName = \"KerasSimple3_likeResnet.h5\"\n",
    "    build_model.save(saveName)\n",
    "    #plot_model(build_model, to_file='KerasSimple3_likeResnet.png', show_shapes=True)\n",
    "    return build_model\n",
    "\n",
    "def getKerasResnetRVL(x,enc,saveName):\n",
    "    model_name = saveName \n",
    "    model = keras.models.load_model(model_name)\n",
    "    y= model.predict([x], batch_size=2560)\n",
    "    nSamples = y.shape[0]\n",
    "    ###需要将预测出的值，转换01整数,并转为数字式\n",
    "    for i in range(y.shape[0]):\n",
    "        tmp = y[i]\n",
    "        index=  np.argmax(tmp)\n",
    "        y[i] = [0]*y.shape[1]\n",
    "        y[i,index]=1\n",
    "   \n",
    "\n",
    "    ###  \n",
    "    y= enc.inverse_transform(y)\n",
    "    y= y.reshape(-1,nSamples)[0]\n",
    "    \n",
    "    \n",
    "    return y\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################################################\n",
    "#############################################################\n",
    "print(\"0.主程序开始，建立多层嵌套决策树模型，3080ti的GPU是AMD2400CPU 运算速度100倍\")\n",
    "#############################################################\n",
    "file1 = \"./trainData/france_0_allSamples.csv\"\n",
    "print(\"reading data france\")\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "h,w = xyData.shape\n",
    "x = xyData[:,1:23]#简单处理与SUMO数据库一致\n",
    "x0rigin = xyData[:,1:w-1]#用所有的数据\n",
    "y0rigin  = xyData[:,w-1]\n",
    "x0rigin =x0rigin.astype(np.float32)#GPU 加这个\n",
    "y0rigin =y0rigin.astype(np.int64)#GPU 加这个\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "x0,y0= ros.fit_resample(x0rigin , y0rigin)\n",
    "\n",
    "x0=x0.astype(np.float32)#GPU 加这个\n",
    "y0=y0.astype(np.int64)#GPU 加这个\n",
    "yl5 = y0\n",
    "print(\"x0.shape:\",x0.shape,\"y0.shape:\",y0.shape,\"y0.type:\", type(y0) )\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "\n",
    "\n",
    "##################################\n",
    "print(\"原始样本分为3210和4两类\")\n",
    "index0 = np.where( (yl5 == 3)|(yl5 == 2) | (yl5 == 1) | (yl5 == 0))\n",
    "index1 = np.where( (yl5 ==4))\n",
    "x3210_4 = x0.copy()\n",
    "y3210_4 = yl5.copy()\n",
    "y3210_4[index0] = 3210\n",
    "\n",
    "#计算下层标记210,3,4,\n",
    "y5LabelFloor1 = yl5.copy()\n",
    "\n",
    "\n",
    "\n",
    "##################################\n",
    "print(\"3210样本分为210和3两类\")\n",
    "index0 = np.where( (yl5 == 2) | (yl5 == 1) | (yl5 == 0))\n",
    "index1 = np.where( (yl5 ==3))\n",
    "\n",
    "xTmp = x0[index0]\n",
    "yTmp = yl5[index0]\n",
    "yTmp[:] = 210\n",
    "\n",
    "x = np.concatenate((xTmp,x0[index1]),axis=0)\n",
    "y = np.concatenate((yTmp,yl5[index1]),axis=0)\n",
    "x210_3 = x\n",
    "y210_3 = y\n",
    "print(\"x.shape:\",x .shape,\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "\n",
    "\n",
    "\n",
    "##################################\n",
    "print(\"210样本分为10和2两类\")\n",
    "index0 = np.where((yl5 == 1) | (yl5 == 0))\n",
    "index1 = np.where( (yl5 ==2))\n",
    "xTmp = x0[index0]\n",
    "yTmp = yl5[index0]\n",
    "yTmp[:] = 10\n",
    "\n",
    "x = np.concatenate((xTmp,x0[index1]),axis=0)\n",
    "y = np.concatenate((yTmp,yl5[index1]),axis=0)\n",
    "x10_2 = x\n",
    "y10_2 = y\n",
    "print(\"x.shape:\",x .shape,\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "print(y10_2)\n",
    "\n",
    "\n",
    "##################################\n",
    "print(\"10样本分为0和1两类\")\n",
    "index0 = np.where( (yl5 == 0))\n",
    "index1 = np.where( (yl5 ==1))\n",
    "xTmp = x0[index0]\n",
    "yTmp = yl5[index0]\n",
    "\n",
    "x = np.concatenate((xTmp,x0[index1]),axis=0)\n",
    "y = np.concatenate((yTmp,yl5[index1]),axis=0)\n",
    "\n",
    "x1_0 = x\n",
    "y1_0 = y\n",
    "print(\"x.shape:\",x .shape,\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "print(y0_1)\n",
    "\n",
    "##################################################\n",
    "xFloors=  dict()\n",
    "yFloors =  dict()\n",
    "dtModeFloors=  dict()\n",
    "dtPredictLabel = dict()\n",
    "kerasPredictLabel = dict()\n",
    "kerasModelNameFloors =dict()\n",
    "encFloors= dict()\n",
    "#################################################\n",
    "\n",
    "if 0:\n",
    "    print(\"5label 模型\")\n",
    "    x=x0\n",
    "    y=yl5\n",
    "    x=x.astype(np.float32)#GPU 加这个\n",
    "    y=y.astype(np.int64)#GPU 加这个\n",
    "    print(\"x.shape:\",x .shape,\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "    \n",
    "    num_labels = 5 \n",
    "    nSamples,nFeatures =  x.shape\n",
    "    enc = OneHotEncoder()\n",
    "    y= y.reshape(nSamples,-1)\n",
    "    \n",
    "    print(\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "    enc.fit(y)\n",
    "    yOneHot=enc.transform(y).toarray()\n",
    "    saveName = \"hybrid2_KerasSimple3_likeResnet_5label.h5\"\n",
    "    if 0:\n",
    "        kerasModel3_5label = kerasFitAndSaveSimple3LikeResnet(x,yOneHot,num_labels,saveName)     \n",
    "    yKeras_5label=getKerasResnetRVL(x,enc,saveName)\n",
    "    dt_5label,dt_PredictLabel = dtFitAndSave(x,yl5,\"5label\")\n",
    "    enc_5label = enc\n",
    "    \n",
    "    xFloors[0] =  x.copy()\n",
    "    yFloors[0] =  y.copy()\n",
    "    dtModeFloors[0] =  dt_5label\n",
    "    dtPredictLabel[0] = dt_PredictLabel.copy()\n",
    "    kerasPredictLabel[0] = yKeras_5label.copy()\n",
    "    kerasModelNameFloors[0] =saveName\n",
    "    encFloors[0] = enc_5label\n",
    "\n",
    "    \n",
    "    \n",
    "if 0:\n",
    "    print(\"\\n ####################Floor4 训练###############\")\n",
    "    x= x1_0\n",
    "    y =y1_0\n",
    "    x=x.astype(np.float32)#GPU 加这个\n",
    "    y=y.astype(np.int64)#GPU 加这个\n",
    "    print(\"x.shape:\",x .shape,\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "    \n",
    "    num_labels = 2 \n",
    "    nSamples,nFeatures =  x.shape\n",
    "    enc = OneHotEncoder()\n",
    "    y= y.reshape(nSamples,-1)\n",
    "    \n",
    "    print(\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "    enc.fit(y)\n",
    "    yOneHot=enc.transform(y).toarray()\n",
    "    saveName = \"hybrid2_KerasSimple3_likeResnet_floor4.h5\"\n",
    "    print(saveName)\n",
    "    if 0:\n",
    "        kerasModel3_Floor4 = kerasFitAndSaveSimple3LikeResnet(x,yOneHot,num_labels,saveName)     \n",
    "    yKeras_Floor4=getKerasResnetRVL(x,enc,saveName)\n",
    "    dt_Floor4,dt_PredictLabel = dtFitAndSave(x,y,\"Floor4\")\n",
    "    enc_floor4 = enc\n",
    "    \n",
    "    xFloors[4] =  x.copy()\n",
    "    yFloors[4] =  y.copy()\n",
    "    dtModeFloors[4] =  dt_Floor4\n",
    "    dtPredictLabel[4] = dt_PredictLabel.copy()\n",
    "    kerasPredictLabel[4] = yKeras_Floor4.copy()\n",
    "    kerasModelNameFloors[4] =saveName\n",
    "    encFloors[4] = enc_floor4\n",
    "    \n",
    "    \n",
    "if 1:\n",
    "    print(\"Floor3 训练\")\n",
    "    x= x10_2\n",
    "    y =y10_2\n",
    "    x=x.astype(np.float32)#GPU 加这个\n",
    "    y=y.astype(np.int64)#GPU 加这个\n",
    "    print(\"x.shape:\",x .shape,\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "    \n",
    "    num_labels = 2 \n",
    "    nSamples,nFeatures =  x.shape\n",
    "    enc = OneHotEncoder()\n",
    "    y= y.reshape(nSamples,-1)\n",
    "    \n",
    "    print(\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "    enc.fit(y)\n",
    "    yOneHot=enc.transform(y).toarray()\n",
    "    saveName = \"hybrid2_KerasSimple3_likeResnet_floor3.h5\"\n",
    "    if 0:\n",
    "        kerasModel3_Floor3 = kerasFitAndSaveSimple3LikeResnet(x,yOneHot,num_labels,saveName)     \n",
    "    yKeras_Floor3=getKerasResnetRVL(x,enc,saveName)\n",
    "    dt_Floor3,dt_PredictLabel = dtFitAndSave(x,y,\"Floor3\")\n",
    "    enc_floor3 = enc\n",
    "    \n",
    "    xFloors[3] =  x.copy()\n",
    "    yFloors[3] =  y.copy()\n",
    "    dtModeFloors[3] =  dt_Floor3\n",
    "    dtPredictLabel[3] = dt_PredictLabel.copy()\n",
    "    kerasPredictLabel[3] = yKeras_Floor3.copy()\n",
    "    kerasModelNameFloors[3] =saveName\n",
    "    encFloors[3] = enc_floor3\n",
    "    \n",
    "if 1:\n",
    "    print(\"####################################################################Floor2 训练\")\n",
    "    x= x210_3\n",
    "    y =y210_3\n",
    "    x=x.astype(np.float32)#GPU 加这个\n",
    "    y=y.astype(np.int64)#GPU 加这个\n",
    "    print(\"x.shape:\",x .shape,\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "    \n",
    "    num_labels = 2 \n",
    "    nSamples,nFeatures =  x.shape\n",
    "    enc = OneHotEncoder()\n",
    "    y= y.reshape(nSamples,-1)\n",
    "    \n",
    "    print(\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "    enc.fit(y)\n",
    "    yOneHot=enc.transform(y).toarray()\n",
    "    saveName = \"hybrid2_KerasSimple3_likeResnet_floor2.h5\"\n",
    "    if 0:\n",
    "        kerasModel3_Floor2 = kerasFitAndSaveSimple3LikeResnet(x,yOneHot,num_labels,saveName)     \n",
    "        \n",
    "    yKeras_Floor2=getKerasResnetRVL(x,enc,saveName)\n",
    "    \n",
    "    \n",
    "    print('keras\\n')\n",
    "    mat1num = confusion_matrix(y, yKeras_Floor2)\n",
    "    mat2acc = confusion_matrix(y, yKeras_Floor2,normalize='pred')\n",
    "    print('mat1num\\n',mat1num)\n",
    "    print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    " \n",
    "    \n",
    "    dt_Floor2,dt_PredictLabel = dtFitAndSave(x,y,\"Floor2\")\n",
    "    enc_floor2 = enc\n",
    "    \n",
    "    \n",
    "    xFloors[2] =  x.copy()\n",
    "    yFloors[2] =  y.copy()\n",
    "    dtModeFloors[2] =  dt_Floor2\n",
    "    dtPredictLabel[2] = dt_PredictLabel.copy()\n",
    "    kerasPredictLabel[2] = yKeras_Floor2.copy()\n",
    "    kerasModelNameFloors[2] =saveName\n",
    "    encFloors[2] = enc_floor2\n",
    "    \n",
    "if 1:\n",
    "    print(\"##########################################################Floor1 训练\")\n",
    "    x= x3210_4\n",
    "    y =y3210_4\n",
    "    print(\"x.shape:\",x .shape,\"y.shape:\",y .shape,\"y.type:\", type(y) ,\"y.unique\",np.unique(y))\n",
    "    \n",
    "    num_labels = 2 \n",
    "    nSamples,nFeatures =  x.shape\n",
    "    enc = OneHotEncoder()\n",
    "    y= y.reshape(nSamples,-1)\n",
    "    \n",
    "    print(\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "    enc.fit(y)\n",
    "    yOneHot=enc.transform(y).toarray()\n",
    "    saveName = \"hybrid2_KerasSimple3_likeResnet_floor1.h5\"\n",
    "    if 0:\n",
    "\n",
    "        kerasModel3_Floor1 = kerasFitAndSaveSimple3LikeResnet(x,yOneHot,num_labels,saveName)     \n",
    "    yKeras_Floor1=getKerasResnetRVL(x,enc,saveName)\n",
    "    \n",
    "    \n",
    "    print('keras\\n')\n",
    "    mat1num = confusion_matrix(y, yKeras_Floor1)\n",
    "    mat2acc = confusion_matrix(y, yKeras_Floor1,normalize='pred')\n",
    "    print('mat1num\\n',mat1num)\n",
    "    print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    " \n",
    "\n",
    "    dt_Floor1,dt_PredictLabel = dtFitAndSave(x,y,\"Floor1\")\n",
    "    enc_floor1 = enc\n",
    "    \n",
    "    xFloors[1] =  x.copy()\n",
    "    yFloors[1] =  y.copy()\n",
    "    dtModeFloors[1] =  dt_Floor1\n",
    "    dtPredictLabel[1] = dt_PredictLabel.copy()\n",
    "    kerasPredictLabel[1] = yKeras_Floor1.copy()\n",
    "    kerasModelNameFloors[1] =saveName\n",
    "    encFloors[1] = enc_floor1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e264bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "60fb178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "论文比较图1\n",
      "多层嵌套准确率图1\n",
      "\n",
      "################分析第1层########################\n",
      "y.unique [   4 3210]\n",
      "混合识别中，决策树的数目和比例，hyCounter,278532,44.698%\n",
      "\n",
      "dt 准确率\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       0.73      0.18      0.28    124628\n",
      "        3210       0.83      0.98      0.90    498512\n",
      "\n",
      "    accuracy                           0.82    623140\n",
      "   macro avg       0.78      0.58      0.59    623140\n",
      "weighted avg       0.81      0.82      0.78    623140\n",
      "\n",
      "hybrid 准确率\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       1.00      0.99      0.99    124628\n",
      "        3210       1.00      1.00      1.00    498512\n",
      "\n",
      "    accuracy                           1.00    623140\n",
      "   macro avg       1.00      0.99      1.00    623140\n",
      "weighted avg       1.00      1.00      1.00    623140\n",
      "\n",
      "keras 准确率\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       1.00      1.00      1.00    124628\n",
      "        3210       1.00      1.00      1.00    498512\n",
      "\n",
      "    accuracy                           1.00    623140\n",
      "   macro avg       1.00      1.00      1.00    623140\n",
      "weighted avg       1.00      1.00      1.00    623140\n",
      "\n",
      "hybrid mat1num\n",
      " [[123348   1280]\n",
      " [   112 498400]]\n",
      "hybrid mat2acc\n",
      " [[0.999 0.003]\n",
      " [0.001 0.997]]\n",
      "keras mat1num\n",
      " [[124567     61]\n",
      " [    50 498462]]\n",
      "keras mat2acc\n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "################分析第2层########################\n",
      "y.unique [  3   4 210]\n",
      "混合识别中，决策树的数目和比例，hyCounter,248609,49.754%\n",
      "\n",
      "dt 准确率\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.69      0.70      0.70    124628\n",
      "           4       0.00      0.00      0.00      1280\n",
      "         210       0.90      0.90      0.90    373772\n",
      "\n",
      "    accuracy                           0.85    499680\n",
      "   macro avg       0.53      0.53      0.53    499680\n",
      "weighted avg       0.84      0.85      0.85    499680\n",
      "\n",
      "hybrid 准确率\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.99      0.99      0.99    124628\n",
      "           4       0.00      0.00      0.00      1280\n",
      "         210       0.99      1.00      1.00    373772\n",
      "\n",
      "    accuracy                           0.99    499680\n",
      "   macro avg       0.66      0.66      0.66    499680\n",
      "weighted avg       0.99      0.99      0.99    499680\n",
      "\n",
      "keras 准确率\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      1.00      1.00    124628\n",
      "           4       0.00      0.00      0.00      1280\n",
      "         210       1.00      1.00      1.00    373772\n",
      "\n",
      "    accuracy                           1.00    499680\n",
      "   macro avg       0.66      0.67      0.67    499680\n",
      "weighted avg       0.99      1.00      1.00    499680\n",
      "\n",
      "hybrid mat1num\n",
      " [[123111      0   1517]\n",
      " [   309      0    971]\n",
      " [   587      0 373185]]\n",
      "hybrid mat2acc\n",
      " [[0.993 0.    0.004]\n",
      " [0.002 0.    0.003]\n",
      " [0.005 0.    0.993]]\n",
      "keras mat1num\n",
      " [[124628      0      0]\n",
      " [   309      0    971]\n",
      " [    33      0 373739]]\n",
      "keras mat2acc\n",
      " [[0.997 0.    0.   ]\n",
      " [0.002 0.    0.003]\n",
      " [0.    0.    0.997]]\n",
      "\n",
      "################分析第3层########################\n",
      "y.unique [ 2  3  4 10]\n",
      "混合识别中，决策树的数目和比例，hyCounter,189257,50.378%\n",
      "\n",
      "dt 准确率\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.65      0.94      0.77    124628\n",
      "           3       0.00      0.00      0.00      1517\n",
      "           4       0.00      0.00      0.00       971\n",
      "          10       0.96      0.75      0.85    248557\n",
      "\n",
      "    accuracy                           0.81    375673\n",
      "   macro avg       0.40      0.42      0.40    375673\n",
      "weighted avg       0.85      0.81      0.81    375673\n",
      "\n",
      "hybrid 准确率\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.99      0.99      0.99    124628\n",
      "           3       0.00      0.00      0.00      1517\n",
      "           4       0.00      0.00      0.00       971\n",
      "          10       0.99      1.00      0.99    248557\n",
      "\n",
      "    accuracy                           0.99    375673\n",
      "   macro avg       0.49      0.50      0.50    375673\n",
      "weighted avg       0.98      0.99      0.99    375673\n",
      "\n",
      "keras 准确率\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.99      1.00      1.00    124628\n",
      "           3       0.00      0.00      0.00      1517\n",
      "           4       0.00      0.00      0.00       971\n",
      "          10       0.99      1.00      1.00    248557\n",
      "\n",
      "    accuracy                           0.99    375673\n",
      "   macro avg       0.50      0.50      0.50    375673\n",
      "weighted avg       0.99      0.99      0.99    375673\n",
      "\n",
      "hybrid mat1num\n",
      " [[123897      0      0    731]\n",
      " [   660      0      0    857]\n",
      " [   407      0      0    564]\n",
      " [   734      0      0 247823]]\n",
      "hybrid mat2acc\n",
      " [[0.986 0.    0.    0.003]\n",
      " [0.005 0.    0.    0.003]\n",
      " [0.003 0.    0.    0.002]\n",
      " [0.006 0.    0.    0.991]]\n",
      "keras mat1num\n",
      " [[124628      0      0      0]\n",
      " [   445      0      0   1072]\n",
      " [   300      0      0    671]\n",
      " [   119      0      0 248438]]\n",
      "keras mat2acc\n",
      " [[0.993 0.    0.    0.   ]\n",
      " [0.004 0.    0.    0.004]\n",
      " [0.002 0.    0.    0.003]\n",
      " [0.001 0.    0.    0.993]]\n",
      "\n",
      "################分析第4层########################\n",
      "y.unique [0 1 2 3 4]\n",
      "混合识别中，决策树的数目和比例，hyCounter,193865,77.554%\n",
      "\n",
      "dt 准确率\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93    123640\n",
      "           1       0.89      0.97      0.93    124183\n",
      "           2       0.00      0.00      0.00       731\n",
      "           3       0.00      0.00      0.00       857\n",
      "           4       0.00      0.00      0.00       564\n",
      "\n",
      "    accuracy                           0.93    249975\n",
      "   macro avg       0.37      0.37      0.37    249975\n",
      "weighted avg       0.92      0.93      0.92    249975\n",
      "\n",
      "hybrid 准确率\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    123640\n",
      "           1       0.96      1.00      0.98    124183\n",
      "           2       0.00      0.00      0.00       731\n",
      "           3       0.00      0.00      0.00       857\n",
      "           4       0.00      0.00      0.00       564\n",
      "\n",
      "    accuracy                           0.98    249975\n",
      "   macro avg       0.39      0.39      0.39    249975\n",
      "weighted avg       0.97      0.98      0.97    249975\n",
      "\n",
      "keras 准确率\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    123640\n",
      "           1       0.99      1.00      1.00    124183\n",
      "           2       0.00      0.00      0.00       731\n",
      "           3       0.00      0.00      0.00       857\n",
      "           4       0.00      0.00      0.00       564\n",
      "\n",
      "    accuracy                           0.99    249975\n",
      "   macro avg       0.40      0.40      0.40    249975\n",
      "weighted avg       0.98      0.99      0.99    249975\n",
      "\n",
      "hybrid mat1num\n",
      " [[120273   3367      0      0      0]\n",
      " [     0 124183      0      0      0]\n",
      " [   156    575      0      0      0]\n",
      " [   397    460      0      0      0]\n",
      " [   441    123      0      0      0]]\n",
      "hybrid mat2acc\n",
      " [[0.992 0.026 0.    0.    0.   ]\n",
      " [0.    0.965 0.    0.    0.   ]\n",
      " [0.001 0.004 0.    0.    0.   ]\n",
      " [0.003 0.004 0.    0.    0.   ]\n",
      " [0.004 0.001 0.    0.    0.   ]]\n",
      "keras mat1num\n",
      " [[123618     22      0      0      0]\n",
      " [     0 124183      0      0      0]\n",
      " [   292    439      0      0      0]\n",
      " [   469    388      0      0      0]\n",
      " [   502     62      0      0      0]]\n",
      "keras mat2acc\n",
      " [[0.99  0.    0.    0.    0.   ]\n",
      " [0.    0.993 0.    0.    0.   ]\n",
      " [0.002 0.004 0.    0.    0.   ]\n",
      " [0.004 0.003 0.    0.    0.   ]\n",
      " [0.004 0.    0.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "print(\"论文比较图1\")\n",
    "#############################################################\n",
    "def getKerasResnetLabel(x,enc,saveName):\n",
    "    model_name = saveName \n",
    "    model = keras.models.load_model(model_name)\n",
    "    y= model.predict([x], batch_size=2560)\n",
    "    nSamples = y.shape[0]\n",
    "    ###需要将预测出的值，转换01整数,并转为数字式\n",
    "    for i in range(y.shape[0]):\n",
    "        tmp = y[i]\n",
    "        index=  np.argmax(tmp)\n",
    "        y[i] = [0]*y.shape[1]\n",
    "        y[i,index]=1\n",
    " \n",
    "    y= enc.inverse_transform(y)\n",
    "    y= y.reshape(-1,nSamples)[0]\n",
    "    \n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "def hybridTest(x,y,dt,floorLabel,kerasLabel):\n",
    "    nSamples,feturesNume  = x.shape\n",
    "    yHyLabel  = np.zeros((nSamples,1))#混合模型预测标签\n",
    "    dtLabel = np.zeros((nSamples,1))#决策树模型预测标签\n",
    "    gini,yPredictProb= getDTSamplesInfo(x,dt)\n",
    "    prdictMax = np.max(yPredictProb,axis=1)\n",
    "    index1 = np.argmax(yPredictProb, axis = 1)\n",
    "    index1 = index1.astype('int64')\n",
    "\n",
    "    floorLabelTmp = np.array([floorLabel for i in range(nSamples) ])\n",
    "\n",
    "    \n",
    "    indexTmp1 = list(range(nSamples))\n",
    "    \n",
    "    dtLabel  = floorLabelTmp[indexTmp1,index1]\n",
    "    yHyLabel = dtLabel.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    tmp1 = np.where(gini>0.1)\n",
    "    tmp2 = np.where(prdictMax<0.9)\n",
    "    tmp3 = np.concatenate((tmp1[0],tmp2[0]),axis = 0)\n",
    "    index2 = np.unique(tmp3)\n",
    " \n",
    "    yHyLabel[index2] = kerasLabel[index2]\n",
    "    switch2KerasIndex = index2\n",
    "    hyCounter = nSamples-len(index2)                \n",
    "                      \n",
    "    \n",
    "\n",
    "\n",
    "    print('混合识别中，决策树的数目和比例，hyCounter,%d,%.3f%%\\n' %(hyCounter,hyCounter/nSamples*100))    \n",
    "    \n",
    "    tmp1 = classification_report(y,dtLabel)\n",
    "    print('dt 准确率\\n',tmp1)\n",
    "    \n",
    "    tmp1 = classification_report(y,yHyLabel)\n",
    "    print('hybrid 准确率\\n',tmp1)\n",
    "    tmp1 = classification_report(y,kerasLabel)\n",
    "    print('keras 准确率\\n',tmp1)\n",
    "    mat1num = confusion_matrix(y,yHyLabel)\n",
    "    mat2acc = confusion_matrix(y,yHyLabel,normalize='pred')\n",
    "    print('hybrid mat1num\\n',mat1num)\n",
    "    print('hybrid mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "    \n",
    "    \n",
    "    mat1num = confusion_matrix(y, kerasLabel)\n",
    "    mat2acc = confusion_matrix(y, kerasLabel,normalize='pred')\n",
    "    print('keras mat1num\\n',mat1num)\n",
    "    print('keras mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "    \n",
    "    \n",
    "    return dtLabel,yHyLabel,switch2KerasIndex\n",
    "\n",
    "#############################################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"多层嵌套准确率图1\")\n",
    "\n",
    "floorsLabel = [[43210],[4,3210],[3,210],[2,10],[0,1]];\n",
    "                      \n",
    "xFloorsTest = dict()\n",
    "yFloorsTest = dict()\n",
    "yOriginLabelFloorsTest = dict()\n",
    "\n",
    "xFloorsTest[1] = x3210_4#每层原始数据x, 训练和对比用\n",
    "yFloorsTest[1] = y3210_4#每层原始数据y，训练和对比用\n",
    "yOriginLabelFloorsTest[1]= yl5#每层5label原始数据y，训练和对比用\n",
    "\n",
    "dtPredictLabelTest = dict()\n",
    "kerasPredictLabelTest = dict()\n",
    "hybridPredictLabelTest = dict()                      \n",
    "switch2KerasIndexTest = dict()\n",
    "\n",
    "                      \n",
    "for i in [1,2,3,4]:\n",
    "    print(\"\\n################分析第%d层########################\" %i)\n",
    "    x = xFloorsTest[i]\n",
    "    y = yFloorsTest[i]\n",
    "    print(\"y.unique\",np.unique(y))\n",
    "    \n",
    "\n",
    "   \n",
    "    if i == 1:\n",
    "        dt = dt_Floor1\n",
    "        saveName = \"hybrid2_KerasSimple3_likeResnet_floor1.h5\"\n",
    "        kerasLabel = getKerasResnetLabel(x,enc_floor1,saveName)\n",
    "    if i == 2:\n",
    "        dt = dt_Floor2\n",
    "        saveName = \"hybrid2_KerasSimple3_likeResnet_floor2.h5\"\n",
    "        kerasLabel = getKerasResnetLabel(x,enc_floor2,saveName)\n",
    "    if i == 3:\n",
    "        dt = dt_Floor3\n",
    "        saveName = \"hybrid2_KerasSimple3_likeResnet_floor3.h5\"\n",
    "        kerasLabel = getKerasResnetLabel(x,enc_floor3,saveName)\n",
    "    if i == 4:\n",
    "        dt = dt_Floor4\n",
    "        saveName = \"hybrid2_KerasSimple3_likeResnet_floor4.h5\"\n",
    "        kerasLabel = getKerasResnetLabel(x,enc_floor4,saveName)\n",
    "    \n",
    "    \n",
    "   \n",
    "  \n",
    " \n",
    "    floorLabel = floorsLabel[i]\n",
    "    dtLabel,yHyLabel, switch2KerasIndex = hybridTest(x,y,dt,floorLabel,kerasLabel)\n",
    "                      \n",
    "    dtPredictLabelTest[i] = dtLabel\n",
    "    kerasPredictLabelTest[i] =kerasLabel\n",
    "    hybridPredictLabelTest[i] = yHyLabel               \n",
    "    switch2KerasIndexTest[i] =switch2KerasIndex\n",
    "    \n",
    "    \n",
    "    y5Label = yOriginLabelFloorsTest[i]#当前层x数据，对应的5label数据\n",
    "    if i == 1:#将3210转为210,3\n",
    "        indexTmp = np.where(yHyLabel == 3210)#上级预测为3210\n",
    "        xFloorsTest[2] = x[indexTmp]#获得预测标签为3210的x数据\n",
    "        \n",
    "        tmpY= y5Label[indexTmp]#获得预测标签为3210的y数据（对应原始5label）\n",
    "        yOriginLabelFloorsTest[2] = tmpY.copy()#获得预测标签为3210的y数据（对应原始5label），并保存起来给到下一层\n",
    "        \n",
    "        index0 = np.where( (tmpY == 2) | (tmpY == 1) | (tmpY== 0))#将其中标签为2，1，0的y数据转为标签210\n",
    "        tmpY[index0] = 210\n",
    "        yFloorsTest[2] = tmpY.copy()#将其中标签为2，1，0的y数据转为标签210,并给到下一层Floor\n",
    "        \n",
    "\n",
    "        \n",
    "       \n",
    "                      \n",
    "    if i == 2:\n",
    "        indexTmp = np.where(yHyLabel == 210)\n",
    "        xFloorsTest[3] = x[indexTmp]#获得预测标签为210的x数据(注意x是上级预测为3210的数据)\n",
    "        \n",
    "        tmpY= y5Label[indexTmp]#获得预测标签为210的y数据（对应原始5label）\n",
    "        yOriginLabelFloorsTest[3] = tmpY.copy()#获得预测标签为210的y数据（对应原始5label），并保存起来给到下一层\n",
    "        \n",
    "        index0 = np.where( (tmpY == 1) | (tmpY== 0))#将其中标签为1，0的y数据转为标签10\n",
    "        tmpY[index0] = 10\n",
    "        yFloorsTest[3] = tmpY.copy()#将其中标签为1，0的y数据转为标签10,并给到下一层Floor\n",
    "      \n",
    "\n",
    "\n",
    "    if i == 3:\n",
    "        indexTmp = np.where(yHyLabel == 10)\n",
    "        xFloorsTest[4] = x[indexTmp]#获得预测标签为10的x数据(注意x是上级预测为210的数据)\n",
    "        \n",
    "        tmpY= y5Label[indexTmp]#获得预测标签为10的y数据（对应原始5label）\n",
    "        yOriginLabelFloorsTest[4] = tmpY.copy()#获得预测标签为210的y数据（对应原始5label），并保存起来给到下一层\n",
    "        \n",
    "        \n",
    "        index0 = np.where(tmpY == 1)#将其中标签为1，0的y数据转为标签10\n",
    "        tmpY[index0] = 1\n",
    "        \n",
    "        index0 = np.where(tmpY == 0)#将其中标签为1，0的y数据转为标签10\n",
    "        tmpY[index0] = 0\n",
    "        \n",
    "        yFloorsTest[4] = tmpY.copy()#将其中标签为1，0的y数据转为标签10,并给到下一层Floor\n",
    "     \n",
    " \n",
    "    \n",
    "\n",
    "                      \n",
    "        \n",
    "                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2950bfcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (1196287352.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [9]\u001b[1;36m\u001b[0m\n\u001b[1;33m    ！nvidia-smi\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "！nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f98ada1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 8 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([8,8,0,0,4,5,6,8,1,2,3])\n",
    "b =[1,1,1,1,1]\n",
    "c = a[b]\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57098281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e807844f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mainTestCSVMLP3(hmcnf_keras).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:gpu2python3.8] *",
   "language": "python",
   "name": "conda-env-gpu2python3.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
