{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f6c25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-26T03:55:17.555121Z",
     "start_time": "2023-01-26T03:55:17.435109Z"
    }
   },
   "outputs": [],
   "source": [
    "#一些常用的命令\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#一些常用的命令\n",
    "!git status\n",
    "!git add .\n",
    "!git commit -m \"correct and optimize some code\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dbf652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T14:33:49.232503Z",
     "start_time": "2023-02-13T14:31:39.188869Z"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "print(\"0.主程序开始，建立多层嵌套决策树模型，3080ti的GPU是AMD2400CPU 运算速度100倍\")\n",
    "print(\"0.这是简化程序，原始带有更多测试和原始模型的程序在mainTestCSVMLP3(hmcnf_keras).ipynb\")\n",
    "print(\"0.这是简化程序，只训练和测试5label模型,编号为0\")\n",
    "########################################################################################################################\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "#import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "import copy\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import pickle  \n",
    "\n",
    "########################################################################################################################\n",
    "#######开始为功能函数\n",
    "#######函数用于决策树分析\n",
    "\n",
    "def dtFitAndSave(x,y,saveName):\n",
    "    str1=\"dtFitAndSave,用于决策树拟合和识别\"\n",
    "    \n",
    "    dt = tree.DecisionTreeClassifier(max_depth=7,min_samples_leaf=100)\n",
    "    dt = dt.fit(x, y)\n",
    "    tree.plot_tree(dt)\n",
    "    #data=tree.export_graphviz(dt, out_file=None,class_names=None,filled=True) \n",
    "    #graph = graphviz.Source(data)\n",
    "    #graph.render(saveName)\n",
    "    \n",
    "    yPredict = dt.predict(x)\n",
    "    tmp1 = classification_report(y,yPredict)\n",
    "    print(\"纯决策树的识别\\n\",tmp1)\n",
    "    mat1num = confusion_matrix(y,yPredict)\n",
    "    mat2acc = confusion_matrix(y,yPredict,normalize='pred')\n",
    "    print(mat1num)\n",
    "    print(np.around(mat2acc , decimals=3))\n",
    "    #text_representation = tree.export_text(dt)\n",
    "    #print(text_representation)\n",
    "    #yPredict = dt.predict_proba(x)\n",
    "    #index = np.where((yPredict[:,1]<0.98)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.90)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.80)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.70)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    return dt,yPredict\n",
    "\n",
    "########################################################################################################################\n",
    "###简单模型3，resnet_like\n",
    "\n",
    "def global_model(dropout_rate, relu_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    return model\n",
    "\n",
    "def sigmoid_model(label_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(label_size, activation='sigmoid',name=\"global\"))\n",
    "    return model\n",
    "\n",
    "def kerasFitAndSaveSimple3LikeResnet(x,yOneHot,num_labels,saveName):\n",
    "    str1=\"kerasFitAndSaveSimple3LikeResnet,用于resnet_like的神经网络拟合和识别\"\n",
    "    \n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 512\n",
    "    dropout_rate = 0.05\n",
    "    hierarchy = [1,1,1]#三层，对于当前数据集已经足够了\n",
    "    global_models = []\n",
    "    label_size = num_labels\n",
    "    features = layers.Input(shape=(features_size,))\n",
    "    for i in range(len(hierarchy)):\n",
    "        if i == 0:\n",
    "            global_models.append(global_model(dropout_rate, relu_size)(features))\n",
    "        else:\n",
    "            global_models.append(global_model(dropout_rate, relu_size)(layers.concatenate([global_models[i-1], features])))\n",
    "\n",
    "    p_glob = sigmoid_model(label_size)(global_models[-1])\n",
    "    build_model = tf.keras.Model(inputs=[features], outputs=[p_glob])\n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    #enc = OneHotEncoder()\n",
    "    #enc.fit(y)  \n",
    "    #yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    if 1:\n",
    "       build_model = keras.models.load_model(saveName)\n",
    "    \n",
    "    #build_model.fit([x],[yOneHot],epochs=10, batch_size=10000*1)\n",
    "    build_model.fit(x,yOneHot,epochs=15000, batch_size=20000*1)#GPU用这个\n",
    "    #saveName = \"KerasSimple3_likeResnet.h5\"\n",
    "    build_model.save(saveName)\n",
    "    #plot_model(build_model, to_file='KerasSimple3_likeResnet.png', show_shapes=True)\n",
    "    return build_model\n",
    "########################################################################################################################\n",
    "def getKerasResnetRVL(x,enc,saveName):\n",
    "    model_name = saveName \n",
    "    model = keras.models.load_model(model_name)\n",
    "    y= model.predict([x], batch_size=2560)\n",
    "    nSamples = y.shape[0]\n",
    "    ###需要将预测出的值，转换01整数,并转为数字式\n",
    "    for i in range(y.shape[0]):\n",
    "        tmp = y[i]\n",
    "        index=  np.argmax(tmp)\n",
    "        y[i] = [0]*y.shape[1]\n",
    "        y[i,index]=1\n",
    "   \n",
    "\n",
    "    ###  \n",
    "    y= enc.inverse_transform(y)\n",
    "    y= y.reshape(-1,nSamples)[0]\n",
    "    \n",
    "    \n",
    "    return y\n",
    "\n",
    "def string2int(inputString):\n",
    "     #print(inputString)\n",
    "     tmp = 0\n",
    "     try:\n",
    "         strTmp=[str(ord(x)) for x in inputString]\n",
    "         tmp=tmp.join(strTmp)\n",
    "         tmp = float(tmp)/(len(inputString)*128)\n",
    "     except:\n",
    "         #print(inputString)\n",
    "         strTmp = inputString\n",
    "         tmp= \"0\"\n",
    "         tmp = 0\n",
    "     return tmp\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "print(\"0.主程序开始，建立多层嵌套决策树模型，3080ti的GPU是AMD2400CPU 运算速度100倍\")\n",
    "########################################################################################################################\n",
    "\n",
    "print(\"reading data france,读取数据并且把数据进行onehot处理\")\n",
    "file1 = \"./trainData/france_0_allSamples1.csv\"\n",
    "\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "h,w = xyData.shape\n",
    "#x = xyData[:,1:23]#简单处理与SUMO数据库一致\n",
    "x0rigin = xyData[:,1:w-1]#用所有的数据\n",
    "y0rigin  = xyData[:,w-1]\n",
    "\n",
    "x0rigin[:,6] = [string2int(inputString) for inputString in x0rigin[:,6] ]#字符串vehLaneID 变为整数\n",
    "\n",
    "x0rigin =x0rigin.astype(np.float32)#GPU 加这个\n",
    "y0rigin =y0rigin.astype(np.int64)#GPU 加这个\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "x0,y0= ros.fit_resample(x0rigin , y0rigin)#对数据不平衡进行处理，保证样本数一致\n",
    "\n",
    "x0=x0.astype(np.float32)#GPU 加这个\n",
    "y0=y0.astype(np.int64)#GPU 加这个\n",
    "yl5 = y0\n",
    "print(\"x0.shape:\",x0.shape,\"y0.shape:\",y0.shape,\"y0.type:\", type(y0) )\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "print(\"准备字典，用于保存训练后的数据\")\n",
    "\n",
    "xFloors=  dict()\n",
    "yFloors =  dict()\n",
    "dtModeFloors=  dict()\n",
    "dtPredictLabel = dict()\n",
    "kerasPredictLabel = dict()\n",
    "kerasModelNameFloors =dict()\n",
    "encFloors= dict()\n",
    "########################################################################################################################\n",
    "###现在暂时不训练多层模型，只训练5label模型\n",
    "if 1:\n",
    "    print(\"5label 模型\")\n",
    "    x=x0\n",
    "    y=yl5\n",
    "    x=x.astype(np.float32)#GPU 加这个\n",
    "    y=y.astype(np.int64)#GPU 加这个\n",
    "    print(\"x.shape:\",x .shape,\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "    \n",
    "    num_labels = 5 \n",
    "    nSamples,nFeatures =  x.shape\n",
    "    enc = OneHotEncoder()\n",
    "    y= y.reshape(nSamples,-1)\n",
    "    \n",
    "    print(\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "    enc.fit(y)\n",
    "    yOneHot=enc.transform(y).toarray()\n",
    "    saveName = \"hybrid2_KerasSimple3_likeResnet_5label.h5\"\n",
    "    saveName = \"./4LayerModelGPU/model.h5\"\n",
    "    if 0:\n",
    "        kerasModel3_5label = kerasFitAndSaveSimple3LikeResnet(x,yOneHot,num_labels,saveName)     \n",
    "    yKeras_5label=getKerasResnetRVL(x,enc,saveName)\n",
    "    \n",
    "    print('keras\\n')\n",
    "    mat1num = confusion_matrix(y, yKeras_5label)\n",
    "    mat2acc = confusion_matrix(y, yKeras_5label,normalize='pred')\n",
    "    print('mat1num\\n',mat1num)\n",
    "    print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dt_5label,dt_PredictLabel = dtFitAndSave(x,yl5,\"5label\")\n",
    "    enc_5label = enc\n",
    "    \n",
    "    xFloors[0] =  x.copy()\n",
    "    yFloors[0] =  y.copy()\n",
    "    dtModeFloors[0] =  dt_5label\n",
    "    dtPredictLabel[0] = dt_PredictLabel.copy()\n",
    "    kerasPredictLabel[0] = yKeras_5label.copy()\n",
    "    kerasModelNameFloors[0] =saveName\n",
    "    encFloors[0] = enc_5label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8674b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T14:36:52.438549Z",
     "start_time": "2023-02-13T14:36:16.048928Z"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "print(\"1.接编号为0的主程序,对于输入的一个样本识别与各个类别的距离，并转换为概率\")\n",
    "print(\"2.对较低概率的样本进行蒙特卡洛模拟分析，原始对应程序为mainSimSumoFranceDatra\")\n",
    "print(\"3.程序编号为1\")\n",
    "########################################################################################################################\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "#import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "import copy\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "########################################################################################################################\n",
    "###自定义log,用于记录\n",
    "def log(info,logtype=0):\n",
    "    \n",
    "    #*args\n",
    "    if logtype == -1:\n",
    "        return\n",
    "    if logtype == 0:\n",
    "        print(info)        \n",
    "\n",
    "\n",
    "    \n",
    "########################################################################################################################\n",
    "print(\"1.1 主程序开始，接编号为0的主程序,对于输入的一个样本识别与各个类别的距离，并转换为概率\")\n",
    "########################################################################################################################\n",
    "logtype=0\n",
    "\n",
    "xi=x0\n",
    "yi=yl5\n",
    "modeSaveName = \"hybrid2_KerasSimple3_likeResnet_5label.h5\"\n",
    "model = keras.models.load_model(modeSaveName)\n",
    "yout= model.predict([xi], batch_size=2560)\n",
    "#log(xi,logtype)\n",
    "#log(yi,logtype)\n",
    "#log(yout,logtype)\n",
    "ymax1=np.max(yout,axis=1)\n",
    "index = np.where(ymax1<0.95)[0]#提取最大值小于0.95的例子\n",
    "ylowpraPredictNN=yout[index]#对较低概率的样本\n",
    "xlowpra=xi[index]\n",
    "ylowpraLabel = yi[index]\n",
    "#log(xi,logtype)\n",
    "#log(yi,logtype)\n",
    "#log(ylowpra)\n",
    "#log(xlowpra)\n",
    "#log(index)\n",
    "\n",
    "    \n",
    "#######保存为pickle文件\n",
    "\n",
    "##保存低概率的样本\n",
    "fpk=open('lowprobSamples.pkf','wb+')  \n",
    "pickle.dump([index,xlowpra,ylowpraLabel,ylowpraPredictNN],fpk)  \n",
    "fpk.close() \n",
    "del xlowpra,ylowpraLabel\n",
    "fpk=open('lowprobSamples.pkf','rb')   \n",
    "[index1,xlowprob1,ylowprobLabel1,ylowprobPredictNN1]=pickle.load(fpk)  \n",
    "fpk.close()  \n",
    "\n",
    "\n",
    "log(index1)\n",
    "#log(ylowprobLabel1)\n",
    "log(np.round(ylowprobPredictNN1,2))\n",
    "\n",
    "##保存所有的的样本\n",
    "fpk=open('allSamples5label.pkf','wb+')  \n",
    "pickle.dump([x0,yl5,yout],fpk)  \n",
    "fpk.close() \n",
    "\n",
    "fpk=open('allSamples5label.pkf','rb')   \n",
    "[x0tmp,yl5tmp,ykerasNNtmp]=pickle.load(fpk)  \n",
    "fpk.close()  \n",
    "\n",
    "#log(np.round(ykerasNNtmp,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c074866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T09:51:42.931165Z",
     "start_time": "2023-01-28T09:51:42.771943Z"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "print(\"接程序1.1: 1.2 对较低概率的样本进行蒙特卡洛模拟分析,原始对应程序为mainSimSumoFranceDatra\")\n",
    "print(\"因为配置失误，采用将低概率的样本进行保存为文件，然后再root用户下命令行模式用SUMO模拟（不使用conda）\")\n",
    "########################################################################################################################\n",
    "!python runSumoSimFun.py#运行runSumoSimFun.py 中test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f393658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T14:37:52.867395Z",
     "start_time": "2023-02-13T14:37:49.763146Z"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "print(\"接程序1.2: 1.3 对较低概率的样本进行蒙特卡洛模拟分析,将数据存为pickle文件\")\n",
    "print(\"因为配置失误，采用将低概率的样本进行保存为文件，然后再root用户下命令行模式用SUMO模拟（不使用conda）\")\n",
    "########################################################################################################################\n",
    "\n",
    "!python3 runSumoSimFun.py\n",
    "#运行runSumoSimFun.py 中test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add02d9c-af03-4a00-8629-42b8a751033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "print(\"接程序1.3: 1.4 对模拟后的数据进行分析，计算正确率\")\n",
    "########################################################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report    \n",
    "import numpy as np\n",
    "print(\"对于低概率样本的识别结果，采用keras和MCS的识别结果对比\")\n",
    "file1 = \"./data1.csv\"\n",
    "xyDataTmp = pd.read_csv(file1,index_col=0)\n",
    "\n",
    "print(xyDataTmp.head(3))\n",
    "print(xyDataTmp.info())\n",
    "\n",
    "file1 = \"./trainData/france_0_allSamples1.csv\"\n",
    "xyOrigin = pd.read_csv(file1,index_col=0)\n",
    "\n",
    "originlabel =  xyDataTmp.iloc[:,1].to_numpy()\n",
    "keraslabel =   xyDataTmp.iloc[:,2].to_numpy()      \n",
    "mcslabel =     xyDataTmp.iloc[:,3].to_numpy()\n",
    "\n",
    "    \n",
    "print('\\nmcs_origin')\n",
    "mat1num = confusion_matrix(originlabel, mcslabel)\n",
    "mat2acc = confusion_matrix(originlabel, mcslabel,normalize='pred')\n",
    "print('mat1num\\n',mat1num)\n",
    "print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "      \n",
    "print('\\nmcs_keras')\n",
    "mat1num = confusion_matrix(mcslabel, keraslabel)\n",
    "mat2acc = confusion_matrix(mcslabel, keraslabel,normalize='pred')\n",
    "print('mat1num\\n',mat1num)\n",
    "print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "      \n",
    "      \n",
    "#\n",
    "tmp = xyDataTmp[\"origin speedFlag\"] - xyDataTmp[\"predicted Labels By MCS\"] >0\n",
    "dfTmp1 = xyDataTmp[tmp]\n",
    "\n",
    "dfTmp2 = xyDataTmp[tmp]\n",
    "\n",
    "df2 =  xyOrigin.iloc[dfTmp2.index,:]      \n",
    "df2[\"vehLaneID\"].hist(figsize=(6, 4))\n",
    "print(df2.info())      \n",
    "tmp = xyDataTmp[\"origin speedFlag\"] - xyDataTmp[\"predicted Labels By MCS\"] >=3\n",
    "dfTmp2 = xyDataTmp[tmp]\n",
    "\n",
    "    \n",
    "      \n",
    "tmp = xyDataTmp[\"predicted Labels By MCS\"] - xyDataTmp[\"origin speedFlag\"]>0\n",
    "dfTmp3 = xyDataTmp[tmp]\n",
    "      \n",
    "tmp = xyDataTmp[\"predicted Labels By MCS\"] - xyDataTmp[\"origin speedFlag\"]>=3\n",
    "dfTmp4 = xyDataTmp[tmp]\n",
    "\n",
    "    \n",
    "      \n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46c252",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T10:10:55.559866Z",
     "start_time": "2023-01-27T10:10:53.398090Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c877a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T09:04:50.440620Z",
     "start_time": "2023-01-28T09:04:50.239643Z"
    }
   },
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b3f88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T03:05:13.857103Z",
     "start_time": "2023-01-29T03:05:13.853125Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timestr= datetime.now()\n",
    "print(timestr)\n",
    "\n",
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e281fc84-e6c1-4671-9323-70c1fdbb7210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensor23py36cpu] *",
   "language": "python",
   "name": "conda-env-tensor23py36cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
