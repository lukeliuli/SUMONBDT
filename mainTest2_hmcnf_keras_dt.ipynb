{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f6c25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-26T03:55:17.555121Z",
     "start_time": "2023-01-26T03:55:17.435109Z"
    }
   },
   "outputs": [],
   "source": [
    "#一些常用的命令\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#一些常用的命令\n",
    "!git status\n",
    "!git add .\n",
    "!git commit -m \"correct and optimize some code\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44dbf652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T02:41:46.508174Z",
     "start_time": "2023-01-29T02:41:11.360211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.主程序开始，建立多层嵌套决策树模型，3080ti的GPU是AMD2400CPU 运算速度100倍\n",
      "0.这是简化程序，原始带有更多测试和原始模型的程序在mainTestCSVMLP3(hmcnf_keras).ipynb\n",
      "0.这是简化程序，只训练和测试5label模型,编号为0\n",
      "0.主程序开始，建立多层嵌套决策树模型，3080ti的GPU是AMD2400CPU 运算速度100倍\n",
      "reading data france,读取数据并且把数据进行onehot处理\n",
      "x0.shape: (628555, 48) y0.shape: (628555,) y0.type: <class 'numpy.ndarray'>\n",
      "准备字典，用于保存训练后的数据\n",
      "5label 模型\n",
      "x.shape: (628555, 48) y.shape: (628555,) y.type: <class 'numpy.ndarray'>\n",
      "y.shape: (628555, 1) y.type: <class 'numpy.ndarray'>\n",
      "Epoch 1/15000\n",
      " 5/32 [===>..........................] - ETA: 46s - loss: 1.0807 - accuracy: 0.8863"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-90f2a0370926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0msaveName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hybrid2_KerasSimple3_likeResnet_5label.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mkerasModel3_5label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkerasFitAndSaveSimple3LikeResnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myOneHot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0myKeras_5label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetKerasResnetRVL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-90f2a0370926>\u001b[0m in \u001b[0;36mkerasFitAndSaveSimple3LikeResnet\u001b[0;34m(x, yOneHot, num_labels, saveName)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m#build_model.fit([x],[yOneHot],epochs=10, batch_size=10000*1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mbuild_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myOneHot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#GPU用这个\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;31m#saveName = \"KerasSimple3_likeResnet.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mbuild_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor23py36cpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor23py36cpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor23py36cpu/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor23py36cpu/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniconda3/envs/tensor23py36cpu/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor23py36cpu/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor23py36cpu/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor23py36cpu/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/tensor23py36cpu/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "print(\"0.主程序开始，建立多层嵌套决策树模型，3080ti的GPU是AMD2400CPU 运算速度100倍\")\n",
    "print(\"0.这是简化程序，原始带有更多测试和原始模型的程序在mainTestCSVMLP3(hmcnf_keras).ipynb\")\n",
    "print(\"0.这是简化程序，只训练和测试5label模型,编号为0\")\n",
    "########################################################################################################################\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "#import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "import copy\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import pickle  \n",
    "\n",
    "########################################################################################################################\n",
    "#######开始为功能函数\n",
    "#######函数用于决策树分析\n",
    "\n",
    "def dtFitAndSave(x,y,saveName):\n",
    "    str1=\"dtFitAndSave,用于决策树拟合和识别\"\n",
    "    \n",
    "    dt = tree.DecisionTreeClassifier(max_depth=7,min_samples_leaf=100)\n",
    "    dt = dt.fit(x, y)\n",
    "    tree.plot_tree(dt)\n",
    "    #data=tree.export_graphviz(dt, out_file=None,class_names=None,filled=True) \n",
    "    #graph = graphviz.Source(data)\n",
    "    #graph.render(saveName)\n",
    "    \n",
    "    yPredict = dt.predict(x)\n",
    "    tmp1 = classification_report(y,yPredict)\n",
    "    print(\"纯决策树的识别\\n\",tmp1)\n",
    "    mat1num = confusion_matrix(y,yPredict)\n",
    "    mat2acc = confusion_matrix(y,yPredict,normalize='pred')\n",
    "    print(mat1num)\n",
    "    print(np.around(mat2acc , decimals=3))\n",
    "    #text_representation = tree.export_text(dt)\n",
    "    #print(text_representation)\n",
    "    #yPredict = dt.predict_proba(x)\n",
    "    #index = np.where((yPredict[:,1]<0.98)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.90)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.80)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    #index = np.where((yPredict[:,1]<0.70)&(yPredict[:,1]>0.5))\n",
    "    #print(index[0].shape,index)\n",
    "    return dt,yPredict\n",
    "\n",
    "########################################################################################################################\n",
    "###简单模型3，resnet_like\n",
    "\n",
    "def global_model(dropout_rate, relu_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(relu_size, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    return model\n",
    "\n",
    "def sigmoid_model(label_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(label_size, activation='sigmoid',name=\"global\"))\n",
    "    return model\n",
    "\n",
    "def kerasFitAndSaveSimple3LikeResnet(x,yOneHot,num_labels,saveName):\n",
    "    str1=\"kerasFitAndSaveSimple3LikeResnet,用于resnet_like的神经网络拟合和识别\"\n",
    "    \n",
    "    nSamples,features_size = x.shape\n",
    "    relu_size = 512\n",
    "    dropout_rate = 0.05\n",
    "    hierarchy = [1,1,1]#三层，对于当前数据集已经足够了\n",
    "    global_models = []\n",
    "    label_size = num_labels\n",
    "    features = layers.Input(shape=(features_size,))\n",
    "    for i in range(len(hierarchy)):\n",
    "        if i == 0:\n",
    "            global_models.append(global_model(dropout_rate, relu_size)(features))\n",
    "        else:\n",
    "            global_models.append(global_model(dropout_rate, relu_size)(layers.concatenate([global_models[i-1], features])))\n",
    "\n",
    "    p_glob = sigmoid_model(label_size)(global_models[-1])\n",
    "    build_model = tf.keras.Model(inputs=[features], outputs=[p_glob])\n",
    "    #model = tf.keras.Model(inputs=[features], outputs=[build_model])\n",
    "    #enc = OneHotEncoder()\n",
    "    #enc.fit(y)  \n",
    "    #yOnehot=enc.transform(y).toarray()\n",
    "    build_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    if 1:\n",
    "       build_model = keras.models.load_model(saveName)\n",
    "    \n",
    "    #build_model.fit([x],[yOneHot],epochs=10, batch_size=10000*1)\n",
    "    build_model.fit(x,yOneHot,epochs=15000, batch_size=20000*1)#GPU用这个\n",
    "    #saveName = \"KerasSimple3_likeResnet.h5\"\n",
    "    build_model.save(saveName)\n",
    "    #plot_model(build_model, to_file='KerasSimple3_likeResnet.png', show_shapes=True)\n",
    "    return build_model\n",
    "########################################################################################################################\n",
    "def getKerasResnetRVL(x,enc,saveName):\n",
    "    model_name = saveName \n",
    "    model = keras.models.load_model(model_name)\n",
    "    y= model.predict([x], batch_size=2560)\n",
    "    nSamples = y.shape[0]\n",
    "    ###需要将预测出的值，转换01整数,并转为数字式\n",
    "    for i in range(y.shape[0]):\n",
    "        tmp = y[i]\n",
    "        index=  np.argmax(tmp)\n",
    "        y[i] = [0]*y.shape[1]\n",
    "        y[i,index]=1\n",
    "   \n",
    "\n",
    "    ###  \n",
    "    y= enc.inverse_transform(y)\n",
    "    y= y.reshape(-1,nSamples)[0]\n",
    "    \n",
    "    \n",
    "    return y\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "print(\"0.主程序开始，建立多层嵌套决策树模型，3080ti的GPU是AMD2400CPU 运算速度100倍\")\n",
    "########################################################################################################################\n",
    "\n",
    "print(\"reading data france,读取数据并且把数据进行onehot处理\")\n",
    "file1 = \"./trainData/france_0_allSamples1.csv\"\n",
    "\n",
    "xyDataTmp = pd.read_csv(file1)\n",
    "#print(xyDataTmp.info())\n",
    "xyData = np.array(xyDataTmp)\n",
    "h,w = xyData.shape\n",
    "#x = xyData[:,1:23]#简单处理与SUMO数据库一致\n",
    "x0rigin = xyData[:,1:w-1]#用所有的数据\n",
    "y0rigin  = xyData[:,w-1]\n",
    "x0rigin =x0rigin.astype(np.float32)#GPU 加这个\n",
    "y0rigin =y0rigin.astype(np.int64)#GPU 加这个\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "x0,y0= ros.fit_resample(x0rigin , y0rigin)#对数据不平衡进行处理，保证样本数一致\n",
    "\n",
    "x0=x0.astype(np.float32)#GPU 加这个\n",
    "y0=y0.astype(np.int64)#GPU 加这个\n",
    "yl5 = y0\n",
    "print(\"x0.shape:\",x0.shape,\"y0.shape:\",y0.shape,\"y0.type:\", type(y0) )\n",
    "del xyDataTmp #节省内存\n",
    "del xyData #节省内存\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "print(\"准备字典，用于保存训练后的数据\")\n",
    "\n",
    "xFloors=  dict()\n",
    "yFloors =  dict()\n",
    "dtModeFloors=  dict()\n",
    "dtPredictLabel = dict()\n",
    "kerasPredictLabel = dict()\n",
    "kerasModelNameFloors =dict()\n",
    "encFloors= dict()\n",
    "########################################################################################################################\n",
    "###现在暂时不训练多层模型，只训练5label模型\n",
    "if 1:\n",
    "    print(\"5label 模型\")\n",
    "    x=x0\n",
    "    y=yl5\n",
    "    x=x.astype(np.float32)#GPU 加这个\n",
    "    y=y.astype(np.int64)#GPU 加这个\n",
    "    print(\"x.shape:\",x .shape,\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "    \n",
    "    num_labels = 5 \n",
    "    nSamples,nFeatures =  x.shape\n",
    "    enc = OneHotEncoder()\n",
    "    y= y.reshape(nSamples,-1)\n",
    "    \n",
    "    print(\"y.shape:\",y .shape,\"y.type:\", type(y) )\n",
    "    enc.fit(y)\n",
    "    yOneHot=enc.transform(y).toarray()\n",
    "    saveName = \"hybrid2_KerasSimple3_likeResnet_5label.h5\"\n",
    "    if 1:\n",
    "        kerasModel3_5label = kerasFitAndSaveSimple3LikeResnet(x,yOneHot,num_labels,saveName)     \n",
    "    yKeras_5label=getKerasResnetRVL(x,enc,saveName)\n",
    "    \n",
    "    print('keras\\n')\n",
    "    mat1num = confusion_matrix(y, yKeras_5label)\n",
    "    mat2acc = confusion_matrix(y, yKeras_5label,normalize='pred')\n",
    "    print('mat1num\\n',mat1num)\n",
    "    print('mat2acc\\n',np.around(mat2acc , decimals=3))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dt_5label,dt_PredictLabel = dtFitAndSave(x,yl5,\"5label\")\n",
    "    enc_5label = enc\n",
    "    \n",
    "    xFloors[0] =  x.copy()\n",
    "    yFloors[0] =  y.copy()\n",
    "    dtModeFloors[0] =  dt_5label\n",
    "    dtPredictLabel[0] = dt_PredictLabel.copy()\n",
    "    kerasPredictLabel[0] = yKeras_5label.copy()\n",
    "    kerasModelNameFloors[0] =saveName\n",
    "    encFloors[0] = enc_5label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8674b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T02:42:09.461585Z",
     "start_time": "2023-01-29T02:41:59.202827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.接编号为0的主程序,对于输入的一个样本识别与各个类别的距离，并转换为概率\n",
      "2.对较低概率的样本进行蒙特卡洛模拟分析，原始对应程序为mainSimSumoFranceDatra\n",
      "3.程序编号为1\n",
      "1.1 主程序开始，接编号为0的主程序,对于输入的一个样本识别与各个类别的距离，并转换为概率\n",
      "[[0.03 0.93 0.   0.   0.  ]\n",
      " [0.11 0.88 0.   0.   0.  ]\n",
      " [0.16 0.84 0.   0.   0.  ]\n",
      " ...\n",
      " [0.03 0.01 0.14 0.19 0.62]\n",
      " [0.24 0.   0.   0.   0.86]\n",
      " [0.04 0.01 0.01 0.   0.78]]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "print(\"1.接编号为0的主程序,对于输入的一个样本识别与各个类别的距离，并转换为概率\")\n",
    "print(\"2.对较低概率的样本进行蒙特卡洛模拟分析，原始对应程序为mainSimSumoFranceDatra\")\n",
    "print(\"3.程序编号为1\")\n",
    "########################################################################################################################\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "#import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "import copy\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "########################################################################################################################\n",
    "###自定义log,用于记录\n",
    "def log(info,logtype=0):\n",
    "    \n",
    "    #*args\n",
    "    if logtype == -1:\n",
    "        return\n",
    "    if logtype == 0:\n",
    "        print(info)        \n",
    "\n",
    "\n",
    "    \n",
    "########################################################################################################################\n",
    "print(\"1.1 主程序开始，接编号为0的主程序,对于输入的一个样本识别与各个类别的距离，并转换为概率\")\n",
    "########################################################################################################################\n",
    "logtype=0\n",
    "\n",
    "xi=x0\n",
    "yi=yl5\n",
    "modeSaveName = \"hybrid2_KerasSimple3_likeResnet_5label.h5\"\n",
    "model = keras.models.load_model(modeSaveName)\n",
    "yout= model.predict([xi], batch_size=2560)\n",
    "#log(xi,logtype)\n",
    "#log(yi,logtype)\n",
    "#log(yout,logtype)\n",
    "ymax1=np.max(yout,axis=1)\n",
    "index = np.where(ymax1<0.95)[0]#提取最大值小于0.95的例子\n",
    "ylowpraPredictNN=yout[index]#对较低概率的样本\n",
    "xlowpra=xi[index]\n",
    "ylowpraLabel = yi[index]\n",
    "#log(xi,logtype)\n",
    "#log(yi,logtype)\n",
    "#log(ylowpra)\n",
    "#log(xlowpra)\n",
    "#log(index)\n",
    "\n",
    "    \n",
    "#######保存为pickle文件\n",
    "\n",
    "##保存低概率的样本\n",
    "fpk=open('lowprobSamples.pkf','wb+')  \n",
    "pickle.dump([xlowpra,ylowpraLabel,ylowpraPredictNN],fpk)  \n",
    "fpk.close() \n",
    "del xlowpra,ylowpraLabel\n",
    "fpk=open('lowprobSamples.pkf','rb')   \n",
    "[xlowprob1,ylowprobLabel1,ylowprobPredictNN1]=pickle.load(fpk)  \n",
    "fpk.close()  \n",
    "\n",
    "\n",
    "#log(xlowprob1)\n",
    "#log(ylowprobLabel1)\n",
    "log(np.round(ylowprobPredictNN1,2))\n",
    "\n",
    "##保存所有的的样本\n",
    "fpk=open('allSamples5label.pkf','wb+')  \n",
    "pickle.dump([x0,yl5,yout],fpk)  \n",
    "fpk.close() \n",
    "\n",
    "fpk=open('allSamples5label.pkf','rb')   \n",
    "[x0tmp,yl5tmp,ykerasNNtmp]=pickle.load(fpk)  \n",
    "fpk.close()  \n",
    "\n",
    "log(np.round(ykerasNNtmp,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c074866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T09:51:42.931165Z",
     "start_time": "2023-01-28T09:51:42.771943Z"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "print(\"接程序1.1: 1.2 对较低概率的样本进行蒙特卡洛模拟分析,原始对应程序为mainSimSumoFranceDatra\")\n",
    "print(\"因为配置失误，采用将低概率的样本进行保存为文件，然后再root用户下命令行模式用SUMO模拟（不使用conda）\")\n",
    "########################################################################################################################\n",
    "!python runSumoSimFun.py#运行runSumoSimFun.py 中test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f393658",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-01-30T02:30:57.064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "接程序1.2: 1.3 对较低概率的样本进行蒙特卡洛模拟分析,将数据存为pickle文件\n",
      "因为配置失误，采用将低概率的样本进行保存为文件，然后再root用户下命令行模式用SUMO模拟（不使用conda）\n",
      "对输入的样本进行蒙特卡洛模拟分析，原始对应程序为mainSimSumoFranceData,需要在docker的原始环境下运行，没有conda\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/liuli/SUMONBDT/runSumoSimFun.py\", line 15, in <module>\n",
      "    import numpy as np\n",
      "ModuleNotFoundError: No module named 'numpy'\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "print(\"接程序1.2: 1.3 对较低概率的样本进行蒙特卡洛模拟分析,将数据存为pickle文件\")\n",
    "print(\"因为配置失误，采用将低概率的样本进行保存为文件，然后再root用户下命令行模式用SUMO模拟（不使用conda）\")\n",
    "########################################################################################################################\n",
    "\n",
    "!python3 runSumoSimFun.py\n",
    "#运行runSumoSimFun.py 中test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46c252",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T10:10:55.559866Z",
     "start_time": "2023-01-27T10:10:53.398090Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c877a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T09:04:50.440620Z",
     "start_time": "2023-01-28T09:04:50.239643Z"
    }
   },
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a52b3f88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T03:05:13.857103Z",
     "start_time": "2023-01-29T03:05:13.853125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-29 11:05:13.854376\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "timestr= datetime.now()\n",
    "print(timestr)\n",
    "\n",
    "!conda info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensor23py36cpu] *",
   "language": "python",
   "name": "conda-env-tensor23py36cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
