{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a93409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (fc1): Linear(in_features=14, out_features=200, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fc4): Linear(in_features=100, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "(723532,)\n",
      "(723532, 14)\n",
      "cpu\n",
      "start training\n",
      "##########one 20 batch totally time cost 0.455\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.179 | Acc: 92.539 | correct, total: (9476,10240)\n",
      "##########one 20 batch totally time cost 3.645\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.170 | Acc: 92.964 | correct, total: (104715,112640)\n",
      "##########one 20 batch totally time cost 6.833\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.168 | Acc: 93.028 | correct, total: (200047,215040)\n",
      "##########one 20 batch totally time cost 10.106\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.167 | Acc: 93.066 | correct, total: (295430,317440)\n",
      "##########one 20 batch totally time cost 13.361\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.166 | Acc: 93.051 | correct, total: (390664,419840)\n",
      "##########one 20 batch totally time cost 16.626\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.165 | Acc: 93.093 | correct, total: (486170,522240)\n",
      "##########one 20 batch totally time cost 20.248\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.165 | Acc: 93.115 | correct, total: (581636,624640)\n",
      "##########one 20 batch totally time cost 23.425\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.164 | Acc: 93.127 | correct, total: (673805,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 0 |time: 23 | Acc: 93.588 | correct, total: (1354272,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    549429\n",
      "           1       0.83      0.90      0.87     86375\n",
      "           2       0.94      0.54      0.69     60284\n",
      "           3       0.89      0.80      0.84     27444\n",
      "\n",
      "    accuracy                           0.94    723532\n",
      "   macro avg       0.91      0.81      0.84    723532\n",
      "weighted avg       0.94      0.94      0.94    723532\n",
      "\n",
      "[[547748   1651     30      0]\n",
      " [  7382  78114     33    846]\n",
      " [ 14026  11700  32697   1861]\n",
      " [  1279   2168   2089  21908]]\n",
      "########################################################################\n",
      "##########one 20 batch totally time cost 0.420\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.170 | Acc: 92.832 | correct, total: (9506,10240)\n",
      "##########one 20 batch totally time cost 3.750\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.160 | Acc: 93.283 | correct, total: (105074,112640)\n",
      "##########one 20 batch totally time cost 7.024\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.162 | Acc: 93.212 | correct, total: (200443,215040)\n",
      "##########one 20 batch totally time cost 10.294\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.163 | Acc: 93.184 | correct, total: (295803,317440)\n",
      "##########one 20 batch totally time cost 13.621\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.163 | Acc: 93.172 | correct, total: (391173,419840)\n",
      "##########one 20 batch totally time cost 16.922\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.163 | Acc: 93.167 | correct, total: (486554,522240)\n",
      "##########one 20 batch totally time cost 20.257\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.162 | Acc: 93.170 | correct, total: (581976,624640)\n",
      "##########one 20 batch totally time cost 23.426\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.162 | Acc: 93.167 | correct, total: (674094,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 1 |time: 23 | Acc: 93.663 | correct, total: (1355366,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98    549429\n",
      "           1       0.85      0.88      0.86     86375\n",
      "           2       0.96      0.57      0.72     60284\n",
      "           3       0.80      0.90      0.85     27444\n",
      "\n",
      "    accuracy                           0.94    723532\n",
      "   macro avg       0.89      0.84      0.85    723532\n",
      "weighted avg       0.94      0.94      0.94    723532\n",
      "\n",
      "[[546385   3009     35      0]\n",
      " [  7249  75729   1199   2198]\n",
      " [ 12853   8902  34422   4107]\n",
      " [  1508   1082    118  24736]]\n",
      "########################################################################\n",
      "##########one 20 batch totally time cost 0.408\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.158 | Acc: 93.203 | correct, total: (9544,10240)\n",
      "##########one 20 batch totally time cost 3.775\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.160 | Acc: 93.250 | correct, total: (105037,112640)\n",
      "##########one 20 batch totally time cost 7.409\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.159 | Acc: 93.276 | correct, total: (200581,215040)\n",
      "##########one 20 batch totally time cost 10.715\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.158 | Acc: 93.298 | correct, total: (296165,317440)\n",
      "##########one 20 batch totally time cost 14.060\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.158 | Acc: 93.296 | correct, total: (391696,419840)\n",
      "##########one 20 batch totally time cost 17.374\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.157 | Acc: 93.320 | correct, total: (487356,522240)\n",
      "##########one 20 batch totally time cost 20.694\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.158 | Acc: 93.290 | correct, total: (582724,624640)\n",
      "##########one 20 batch totally time cost 23.944\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.158 | Acc: 93.276 | correct, total: (674883,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 2 |time: 23 | Acc: 93.556 | correct, total: (1353819,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    549429\n",
      "           1       0.81      0.90      0.85     86375\n",
      "           2       0.95      0.55      0.70     60284\n",
      "           3       0.83      0.86      0.84     27444\n",
      "\n",
      "    accuracy                           0.94    723532\n",
      "   macro avg       0.89      0.82      0.84    723532\n",
      "weighted avg       0.94      0.94      0.93    723532\n",
      "\n",
      "[[544432   4937     60      0]\n",
      " [  6393  77563     98   2321]\n",
      " [ 12031  12211  33437   2605]\n",
      " [  1174   1136   1630  23504]]\n",
      "########################################################################\n",
      "##########one 20 batch totally time cost 0.406\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.154 | Acc: 93.467 | correct, total: (9571,10240)\n",
      "##########one 20 batch totally time cost 3.708\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.158 | Acc: 93.219 | correct, total: (105002,112640)\n",
      "##########one 20 batch totally time cost 7.058\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.161 | Acc: 93.121 | correct, total: (200248,215040)\n",
      "##########one 20 batch totally time cost 10.344\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.159 | Acc: 93.231 | correct, total: (295951,317440)\n",
      "##########one 20 batch totally time cost 13.629\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.158 | Acc: 93.263 | correct, total: (391556,419840)\n",
      "##########one 20 batch totally time cost 16.989\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.157 | Acc: 93.305 | correct, total: (487276,522240)\n",
      "##########one 20 batch totally time cost 20.308\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.156 | Acc: 93.352 | correct, total: (583114,624640)\n",
      "##########one 20 batch totally time cost 23.513\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.156 | Acc: 93.355 | correct, total: (675453,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 3 |time: 23 | Acc: 93.718 | correct, total: (1356163,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98    549429\n",
      "           1       0.85      0.88      0.86     86375\n",
      "           2       0.97      0.57      0.72     60284\n",
      "           3       0.83      0.86      0.85     27444\n",
      "\n",
      "    accuracy                           0.94    723532\n",
      "   macro avg       0.90      0.83      0.85    723532\n",
      "weighted avg       0.94      0.94      0.94    723532\n",
      "\n",
      "[[546659   2742     28      0]\n",
      " [  8231  75831    513   1800]\n",
      " [ 12966   9741  34574   3003]\n",
      " [  1902   1237    659  23646]]\n",
      "########################################################################\n",
      "##########one 20 batch totally time cost 0.474\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.158 | Acc: 93.398 | correct, total: (9564,10240)\n",
      "##########one 20 batch totally time cost 3.777\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.158 | Acc: 93.309 | correct, total: (105103,112640)\n",
      "##########one 20 batch totally time cost 7.140\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.155 | Acc: 93.380 | correct, total: (200805,215040)\n",
      "##########one 20 batch totally time cost 10.435\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.154 | Acc: 93.457 | correct, total: (296671,317440)\n",
      "##########one 20 batch totally time cost 13.771\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.155 | Acc: 93.401 | correct, total: (392133,419840)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 20 batch totally time cost 17.143\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.155 | Acc: 93.404 | correct, total: (487795,522240)\n",
      "##########one 20 batch totally time cost 20.430\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.154 | Acc: 93.427 | correct, total: (583581,624640)\n",
      "##########one 20 batch totally time cost 23.646\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.156 | Acc: 93.385 | correct, total: (675673,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 4 |time: 23 | Acc: 92.281 | correct, total: (1335372,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96    549429\n",
      "           1       0.74      0.90      0.82     86375\n",
      "           2       0.77      0.56      0.65     60284\n",
      "           3       0.67      0.86      0.75     27444\n",
      "\n",
      "    accuracy                           0.91    723532\n",
      "   macro avg       0.79      0.82      0.80    723532\n",
      "weighted avg       0.92      0.91      0.91    723532\n",
      "\n",
      "[[524049  13365   5420   6595]\n",
      " [  3791  78049   2121   2414]\n",
      " [ 11229  12265  33868   2922]\n",
      " [    17   1350   2344  23733]]\n",
      "########################################################################\n",
      "##########one 20 batch totally time cost 0.470\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.190 | Acc: 91.533 | correct, total: (9373,10240)\n",
      "##########one 20 batch totally time cost 3.784\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.170 | Acc: 92.716 | correct, total: (104435,112640)\n",
      "##########one 20 batch totally time cost 7.071\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.163 | Acc: 93.051 | correct, total: (200097,215040)\n",
      "##########one 20 batch totally time cost 10.417\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.158 | Acc: 93.227 | correct, total: (295941,317440)\n",
      "##########one 20 batch totally time cost 13.740\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.157 | Acc: 93.293 | correct, total: (391680,419840)\n",
      "##########one 20 batch totally time cost 17.032\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.156 | Acc: 93.355 | correct, total: (487536,522240)\n",
      "##########one 20 batch totally time cost 20.422\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.156 | Acc: 93.349 | correct, total: (583093,624640)\n",
      "##########one 20 batch totally time cost 23.645\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.156 | Acc: 93.351 | correct, total: (675425,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 5 |time: 23 | Acc: 93.289 | correct, total: (1349958,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    549429\n",
      "           1       0.84      0.85      0.84     86375\n",
      "           2       0.95      0.53      0.68     60284\n",
      "           3       0.87      0.78      0.82     27444\n",
      "\n",
      "    accuracy                           0.93    723532\n",
      "   macro avg       0.90      0.79      0.83    723532\n",
      "weighted avg       0.93      0.93      0.93    723532\n",
      "\n",
      "[[548001   1422      6      0]\n",
      " [ 12078  73286     16    995]\n",
      " [ 15338  10870  31962   2114]\n",
      " [  2397   2069   1694  21284]]\n",
      "########################################################################\n",
      "##########one 20 batch totally time cost 0.411\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.171 | Acc: 93.008 | correct, total: (9524,10240)\n",
      "##########one 20 batch totally time cost 3.788\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.155 | Acc: 93.419 | correct, total: (105227,112640)\n",
      "##########one 20 batch totally time cost 7.087\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.153 | Acc: 93.521 | correct, total: (201108,215040)\n",
      "##########one 20 batch totally time cost 10.430\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.154 | Acc: 93.460 | correct, total: (296678,317440)\n",
      "##########one 20 batch totally time cost 13.794\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.155 | Acc: 93.410 | correct, total: (392174,419840)\n",
      "##########one 20 batch totally time cost 17.151\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.154 | Acc: 93.421 | correct, total: (487881,522240)\n",
      "##########one 20 batch totally time cost 20.531\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.155 | Acc: 93.375 | correct, total: (583255,624640)\n",
      "##########one 20 batch totally time cost 23.730\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.155 | Acc: 93.368 | correct, total: (675547,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 6 |time: 23 | Acc: 93.709 | correct, total: (1356024,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    549429\n",
      "           1       0.81      0.91      0.85     86375\n",
      "           2       0.98      0.57      0.72     60284\n",
      "           3       0.82      0.91      0.86     27444\n",
      "\n",
      "    accuracy                           0.94    723532\n",
      "   macro avg       0.89      0.84      0.85    723532\n",
      "weighted avg       0.94      0.94      0.94    723532\n",
      "\n",
      "[[542732   6620      8     69]\n",
      " [  5479  78638    170   2088]\n",
      " [ 11547  11089  34160   3488]\n",
      " [   739   1301    457  24947]]\n",
      "########################################################################\n",
      "##########one 20 batch totally time cost 0.409\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.159 | Acc: 93.232 | correct, total: (9547,10240)\n",
      "##########one 20 batch totally time cost 3.804\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.158 | Acc: 93.274 | correct, total: (105064,112640)\n",
      "##########one 20 batch totally time cost 7.089\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.158 | Acc: 93.272 | correct, total: (200573,215040)\n",
      "##########one 20 batch totally time cost 10.378\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.157 | Acc: 93.316 | correct, total: (296222,317440)\n",
      "##########one 20 batch totally time cost 13.755\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.156 | Acc: 93.330 | correct, total: (391838,419840)\n",
      "##########one 20 batch totally time cost 17.360\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.155 | Acc: 93.362 | correct, total: (487572,522240)\n",
      "##########one 20 batch totally time cost 20.669\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.155 | Acc: 93.385 | correct, total: (583321,624640)\n",
      "##########one 20 batch totally time cost 23.955\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.155 | Acc: 93.368 | correct, total: (675544,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 7 |time: 23 | Acc: 93.573 | correct, total: (1354059,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98    549429\n",
      "           1       0.79      0.90      0.84     86375\n",
      "           2       0.96      0.58      0.73     60284\n",
      "           3       0.80      0.92      0.86     27444\n",
      "\n",
      "    accuracy                           0.94    723532\n",
      "   macro avg       0.88      0.85      0.85    723532\n",
      "weighted avg       0.94      0.94      0.94    723532\n",
      "\n",
      "[[540137   9069    155     68]\n",
      " [  5134  77809    906   2526]\n",
      " [ 11050  10244  35264   3726]\n",
      " [   859   1021    259  25305]]\n",
      "########################################################################\n",
      "##########one 20 batch totally time cost 0.410\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.154 | Acc: 93.369 | correct, total: (9561,10240)\n",
      "##########one 20 batch totally time cost 3.703\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.158 | Acc: 93.248 | correct, total: (105034,112640)\n",
      "##########one 20 batch totally time cost 7.082\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.156 | Acc: 93.368 | correct, total: (200778,215040)\n",
      "##########one 20 batch totally time cost 10.366\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.154 | Acc: 93.428 | correct, total: (296578,317440)\n",
      "##########one 20 batch totally time cost 13.656\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.154 | Acc: 93.447 | correct, total: (392327,419840)\n",
      "##########one 20 batch totally time cost 17.014\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.153 | Acc: 93.456 | correct, total: (488067,522240)\n",
      "##########one 20 batch totally time cost 20.307\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.153 | Acc: 93.449 | correct, total: (583722,624640)\n",
      "##########one 20 batch totally time cost 23.581\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.154 | Acc: 93.426 | correct, total: (675968,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 8 |time: 23 | Acc: 93.812 | correct, total: (1357525,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    549429\n",
      "           1       0.84      0.89      0.86     86375\n",
      "           2       0.96      0.57      0.71     60284\n",
      "           3       0.84      0.87      0.85     27444\n",
      "\n",
      "    accuracy                           0.94    723532\n",
      "   macro avg       0.90      0.83      0.85    723532\n",
      "weighted avg       0.94      0.94      0.94    723532\n",
      "\n",
      "[[546745   2660     24      0]\n",
      " [  7156  76559   1147   1513]\n",
      " [ 12708  10137  34282   3157]\n",
      " [  1636   1471    366  23971]]\n",
      "########################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 20 batch totally time cost 0.482\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.164 | Acc: 93.184 | correct, total: (9542,10240)\n",
      "##########one 20 batch totally time cost 3.805\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.156 | Acc: 93.390 | correct, total: (105194,112640)\n",
      "##########one 20 batch totally time cost 7.226\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.154 | Acc: 93.447 | correct, total: (200948,215040)\n",
      "##########one 20 batch totally time cost 10.548\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.157 | Acc: 93.319 | correct, total: (296233,317440)\n",
      "##########one 20 batch totally time cost 13.838\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.157 | Acc: 93.295 | correct, total: (391689,419840)\n",
      "##########one 20 batch totally time cost 17.208\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.156 | Acc: 93.334 | correct, total: (487429,522240)\n",
      "##########one 20 batch totally time cost 20.524\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.156 | Acc: 93.359 | correct, total: (583155,624640)\n",
      "##########one 20 batch totally time cost 23.758\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.155 | Acc: 93.373 | correct, total: (675587,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 9 |time: 23 | Acc: 93.834 | correct, total: (1357843,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    549429\n",
      "           1       0.85      0.89      0.87     86375\n",
      "           2       0.98      0.56      0.71     60284\n",
      "           3       0.83      0.88      0.86     27444\n",
      "\n",
      "    accuracy                           0.94    723532\n",
      "   macro avg       0.91      0.83      0.85    723532\n",
      "weighted avg       0.94      0.94      0.94    723532\n",
      "\n",
      "[[547792   1629      8      0]\n",
      " [  7669  76636    245   1825]\n",
      " [ 13399  10243  33681   2961]\n",
      " [  1486   1447    364  24147]]\n",
      "########################################################################\n",
      "##########one 20 batch totally time cost 0.474\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.154 | Acc: 93.203 | correct, total: (9544,10240)\n",
      "##########one 20 batch totally time cost 3.790\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.153 | Acc: 93.367 | correct, total: (105169,112640)\n",
      "##########one 20 batch totally time cost 7.124\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.155 | Acc: 93.330 | correct, total: (200696,215040)\n",
      "##########one 20 batch totally time cost 10.510\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.154 | Acc: 93.356 | correct, total: (296350,317440)\n",
      "##########one 20 batch totally time cost 13.837\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.154 | Acc: 93.407 | correct, total: (392161,419840)\n",
      "##########one 20 batch totally time cost 17.176\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.153 | Acc: 93.422 | correct, total: (487889,522240)\n",
      "##########one 20 batch totally time cost 20.564\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.154 | Acc: 93.398 | correct, total: (583402,624640)\n",
      "##########one 20 batch totally time cost 23.789\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.153 | Acc: 93.437 | correct, total: (676050,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 10 |time: 23 | Acc: 93.730 | correct, total: (1356336,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    549429\n",
      "           1       0.79      0.92      0.85     86375\n",
      "           2       0.97      0.57      0.72     60284\n",
      "           3       0.87      0.88      0.87     27444\n",
      "\n",
      "    accuracy                           0.94    723532\n",
      "   macro avg       0.90      0.84      0.86    723532\n",
      "weighted avg       0.94      0.94      0.94    723532\n",
      "\n",
      "[[542531   6779    119      0]\n",
      " [  5502  79154    187   1532]\n",
      " [ 11582  12079  34382   2241]\n",
      " [   729   1757    739  24219]]\n",
      "########################################################################\n",
      "##########one 20 batch totally time cost 0.405\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.146 | Acc: 93.857 | correct, total: (9611,10240)\n",
      "##########one 20 batch totally time cost 3.860\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.151 | Acc: 93.595 | correct, total: (105425,112640)\n",
      "##########one 20 batch totally time cost 7.188\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.153 | Acc: 93.523 | correct, total: (201111,215040)\n",
      "##########one 20 batch totally time cost 10.586\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.152 | Acc: 93.540 | correct, total: (296933,317440)\n",
      "##########one 20 batch totally time cost 13.941\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.152 | Acc: 93.515 | correct, total: (392612,419840)\n",
      "##########one 20 batch totally time cost 17.299\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.153 | Acc: 93.466 | correct, total: (488117,522240)\n",
      "##########one 20 batch totally time cost 20.691\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.153 | Acc: 93.451 | correct, total: (583734,624640)\n",
      "##########one 20 batch totally time cost 23.931\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.154 | Acc: 93.443 | correct, total: (676089,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 11 |time: 23 | Acc: 93.502 | correct, total: (1353035,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    549429\n",
      "           1       0.82      0.87      0.85     86375\n",
      "           2       0.93      0.54      0.68     60284\n",
      "           3       0.86      0.78      0.82     27444\n",
      "\n",
      "    accuracy                           0.94    723532\n",
      "   macro avg       0.89      0.80      0.83    723532\n",
      "weighted avg       0.94      0.94      0.93    723532\n",
      "\n",
      "[[547646   1777      6      0]\n",
      " [  8976  75534    107   1758]\n",
      " [ 13715  12388  32454   1727]\n",
      " [  1540   2226   2366  21312]]\n",
      "########################################################################\n",
      "##########one 20 batch totally time cost 0.411\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.153 | Acc: 93.613 | correct, total: (9586,10240)\n",
      "##########one 20 batch totally time cost 3.809\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.154 | Acc: 93.456 | correct, total: (105269,112640)\n",
      "##########one 20 batch totally time cost 7.154\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.153 | Acc: 93.497 | correct, total: (201056,215040)\n",
      "##########one 20 batch totally time cost 10.486\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.153 | Acc: 93.470 | correct, total: (296710,317440)\n",
      "##########one 20 batch totally time cost 13.884\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.153 | Acc: 93.460 | correct, total: (392382,419840)\n",
      "##########one 20 batch totally time cost 18.429\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.153 | Acc: 93.458 | correct, total: (488075,522240)\n",
      "##########one 20 batch totally time cost 21.764\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.156 | Acc: 93.325 | correct, total: (582946,624640)\n",
      "##########one 20 batch totally time cost 25.153\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.157 | Acc: 93.298 | correct, total: (675039,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 12 |time: 25 | Acc: 93.657 | correct, total: (1355271,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    549429\n",
      "           1       0.87      0.87      0.87     86375\n",
      "           2       0.96      0.55      0.70     60284\n",
      "           3       0.79      0.88      0.83     27444\n",
      "\n",
      "    accuracy                           0.94    723532\n",
      "   macro avg       0.89      0.82      0.84    723532\n",
      "weighted avg       0.94      0.94      0.94    723532\n",
      "\n",
      "[[547750   1673      6      0]\n",
      " [  7918  75147   1252   2058]\n",
      " [ 13691   8898  33302   4393]\n",
      " [  1998   1156    257  24033]]\n",
      "########################################################################\n",
      "##########one 20 batch totally time cost 0.421\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.158 | Acc: 93.574 | correct, total: (9582,10240)\n",
      "##########one 20 batch totally time cost 3.746\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.155 | Acc: 93.293 | correct, total: (105085,112640)\n",
      "##########one 20 batch totally time cost 7.194\n",
      "batchIndex 41 |trainLen 142 | Loss: 0.154 | Acc: 93.393 | correct, total: (200833,215040)\n",
      "##########one 20 batch totally time cost 10.523\n",
      "batchIndex 61 |trainLen 142 | Loss: 0.153 | Acc: 93.442 | correct, total: (296621,317440)\n",
      "##########one 20 batch totally time cost 13.921\n",
      "batchIndex 81 |trainLen 142 | Loss: 0.153 | Acc: 93.425 | correct, total: (392237,419840)\n",
      "##########one 20 batch totally time cost 17.280\n",
      "batchIndex 101 |trainLen 142 | Loss: 0.153 | Acc: 93.413 | correct, total: (487842,522240)\n",
      "##########one 20 batch totally time cost 21.401\n",
      "batchIndex 121 |trainLen 142 | Loss: 0.154 | Acc: 93.415 | correct, total: (583506,624640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########one 20 batch totally time cost 24.670\n",
      "batchIndex 141 |trainLen 142 | Loss: 0.155 | Acc: 93.352 | correct, total: (675428,723532)\n",
      "\n",
      "\n",
      " Eval--epochIndex 13 |time: 24 | Acc: 93.876 | correct, total: (1358442,1447064)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    549429\n",
      "           1       0.85      0.90      0.87     86375\n",
      "           2       0.97      0.57      0.72     60284\n",
      "           3       0.83      0.89      0.86     27444\n",
      "\n",
      "    accuracy                           0.94    723532\n",
      "   macro avg       0.91      0.84      0.86    723532\n",
      "weighted avg       0.95      0.94      0.94    723532\n",
      "\n",
      "[[546886   2524     19      0]\n",
      " [  6563  77408    787   1617]\n",
      " [ 13244   9439  34382   3219]\n",
      " [  1585   1402    119  24338]]\n",
      "########################################################################\n",
      "##########one 20 batch totally time cost 0.482\n",
      "batchIndex 1 |trainLen 142 | Loss: 0.153 | Acc: 93.643 | correct, total: (9589,10240)\n",
      "##########one 20 batch totally time cost 3.838\n",
      "batchIndex 21 |trainLen 142 | Loss: 0.153 | Acc: 93.461 | correct, total: (105275,112640)\n"
     ]
    }
   ],
   "source": [
    "###用于测试csv和mlp\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 五层神经网络\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 200)\n",
    "        self.fc3 = nn.Linear(200, 100)\n",
    "        self.fc4 = nn.Linear(100, num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "\n",
    "mlp = NeuralNet(14,200,4)\n",
    "print(mlp)\n",
    "\n",
    "##############################################读写CSV\n",
    "file1 = \"./trainData/dataAllSim.csv\"\n",
    "##方式1\n",
    "#data1=[]\n",
    "#csv_reader = csv.reader(open(file1))\n",
    "#for row in csv_reader:\n",
    "#        data1.append(row)\n",
    "#print(data1[0])        \n",
    "\n",
    "##方式2\n",
    "#https://blog.csdn.net/zw__chen/article/details/82806900\n",
    "csvfile = open(file1, 'r')\n",
    "xyData= np.loadtxt(file1,delimiter=',',skiprows=1)\n",
    "x = xyData[:,0:-1]\n",
    "y = xyData[:,-1]\n",
    "print(y.shape )\n",
    "print(x.shape )\n",
    "x1 =torch.from_numpy(x)\n",
    "y1 =torch.from_numpy(y)\n",
    "\n",
    "dataset1 = TensorDataset(x1.float(),y1.long())\n",
    "\n",
    "#train_dataset, test_dataset = random_split(\n",
    "#    dataset=dataset1,\n",
    "#    lengths=[7, 3],\n",
    "#    generator=torch.Generator().manual_seed(0)\n",
    "#)\n",
    "\n",
    "#################################\n",
    "#数据准备：平衡\n",
    "tmp = y\n",
    "trainratio = np.bincount(tmp.astype(\"int64\"))\n",
    "train_weights = 1./trainratio\n",
    "train_weights[0]= train_weights[0]*2\n",
    "train_sampleweights = torch.from_numpy(train_weights)\n",
    "train_sampler = WeightedRandomSampler(weights=train_sampleweights, num_samples = len(y))\n",
    "#train_loader = DataLoader( dataset1, batch_size=5120, num_workers=1, sampler=train_sampler)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset1, batch_size=5120, shuffle=True)\n",
    "\n",
    "#准备设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == 'cuda':\n",
    "    mlp = torch.nn.DataParallel(mlp)\n",
    "    cudnn.benchmark = True\n",
    "    mlp =  mlp.to(device)\n",
    "print(device)\n",
    "\n",
    "#准备模型\n",
    "modelPathName = \"./trainedModes/\"+\"redTLS1.modeparams\"\n",
    "params = torch.load(modelPathName)\n",
    "mlp.load_state_dict(params['net'])\n",
    "\n",
    "\n",
    "#################################\n",
    "#训练开始\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mlp.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "running_loss = 0\n",
    "startEpoch = 0\n",
    "epochs = 3000#大概8小时\n",
    "print(\"start training\")\n",
    "\n",
    "for epoch in range(startEpoch, epochs):  # 多批次循环\n",
    "\n",
    "    mlp.train()\n",
    "    time_start = time.time()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # 获取输入\n",
    "        #print(epoch,i)\n",
    "        inputs, labels = data\n",
    "        #inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs=inputs.type(torch.float32)\n",
    "        labels=labels\n",
    "\n",
    "        if device == 'cuda':\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 梯度置0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 正向传播，反向传播，优化a\n",
    "        outputs = mlp(inputs)\n",
    "        #print(\"inputs:\",inputs)\n",
    "        #print(\"###################################\")\n",
    "        #print(\"outputs:\",outputs)\n",
    "        #print(\"labels\",labels)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        #print(\"loss:\",loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        #print(\"labels.size(0):\",labels.size(0))\n",
    "        #print(\"predicted:\",predicted)\n",
    "        #print(\"predicted.eq(labels).sum().item():\",predicted.eq(labels).sum().item())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        #os.input()\n",
    "        if i % 20 == 1:  # 每200批次打印一次\n",
    "         time_end = time.time()\n",
    "         print('##########one 20 batch totally time cost %.3f' %(time_end-time_start))\n",
    "         print(\"batchIndex %d |trainLen %d | Loss: %.3f | Acc: %.3f | correct, total: (%d,%d)\" % (\n",
    "             i, len(train_loader), running_loss/(i+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    time_end = time.time()\n",
    "    \n",
    "\n",
    "    state = {\"net\": mlp.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    modelPathName = \"./trainedModes/\"+\"redTLS.modeparams\"\n",
    "    torch.save(state, modelPathName)\n",
    "    params = torch.load(modelPathName)\n",
    "    mlp.load_state_dict(params['net'])\n",
    "    optimizer.load_state_dict(params['optimizer'])\n",
    "    \n",
    "    #用全训练集合进行评估\n",
    "    mlp.eval()\n",
    "    labels = y1.long()\n",
    "    outputs = mlp(x1.float())\n",
    "    _, predicted = torch.max(outputs.data,1)\n",
    "    total += labels.size(0)\n",
    "    correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    print(\"\\n\\n Eval--epochIndex %d |time: %d | Acc: %.3f | correct, total: (%d,%d)\" % (\n",
    "         epoch, (time_end-time_start), 100.*correct/total, correct, total))\n",
    "    tmp1 = classification_report(labels,predicted)\n",
    "    tmp2 = confusion_matrix(labels,predicted)\n",
    "    print(tmp1)\n",
    "    print(tmp2)\n",
    "  \n",
    "    print(\"########################################################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60100f74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[542965   6462      2      0]\n",
      " [  5609  78786     53   1927]\n",
      " [ 12006  12810  33190   2278]\n",
      " [   809   1579   2335  22721]]\n"
     ]
    }
   ],
   "source": [
    "print(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2710fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"net\": mlp.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "modelPathName = \"./trainedModes/\"+\"redTLS1.modeparams\"\n",
    "torch.save(state, modelPathName)\n",
    "params = torch.load(modelPathName)\n",
    "mlp.load_state_dict(params['net'])\n",
    "optimizer.load_state_dict(params['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de7729a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[549429  86375  60284  27444]\n",
      "[75.93706982 11.93796543  8.33190515  3.7930596 ]\n",
      "[ 2.74010234 17.42971566 24.97332111 54.85686088]\n"
     ]
    }
   ],
   "source": [
    "tmp = y\n",
    "trainratio = np.bincount(tmp.astype(\"int64\"))\n",
    "train_weights = 1./trainratio\n",
    "print(trainratio),print(trainratio/sum(trainratio)*100),print(train_weights/sum(train_weights)*100)\n",
    "\n",
    "train_sampleweights = torch.from_numpy(train_weights)\n",
    "train_sampler = WeightedRandomSampler(weights=train_sampleweights, num_samples = 2*len(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
