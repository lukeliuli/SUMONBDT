{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a93409",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (fc1): Linear(in_features=22, out_features=200, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fc4): Linear(in_features=100, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "(7262460,)\n",
      "(7262460, 22)\n",
      "cpu\n",
      "start training\n",
      "##########one 100 batch totally time cost 1.029\n",
      "batchIndex 1 |trainLen 1419 | Loss: 1.058 | Acc: 64.004 | correct, total: (6554,10240)\n",
      "##########one 100 batch totally time cost 8.732\n",
      "batchIndex 101 |trainLen 1419 | Loss: 0.609 | Acc: 78.778 | correct, total: (411409,522240)\n",
      "##########one 100 batch totally time cost 16.483\n",
      "batchIndex 201 |trainLen 1419 | Loss: 0.515 | Acc: 81.206 | correct, total: (839866,1034240)\n",
      "##########one 100 batch totally time cost 24.219\n",
      "batchIndex 301 |trainLen 1419 | Loss: 0.465 | Acc: 82.583 | correct, total: (1276936,1546240)\n",
      "##########one 100 batch totally time cost 31.927\n",
      "batchIndex 401 |trainLen 1419 | Loss: 0.432 | Acc: 83.506 | correct, total: (1718758,2058240)\n",
      "##########one 100 batch totally time cost 39.529\n",
      "batchIndex 501 |trainLen 1419 | Loss: 0.409 | Acc: 84.164 | correct, total: (2163223,2570240)\n",
      "##########one 100 batch totally time cost 47.208\n",
      "batchIndex 601 |trainLen 1419 | Loss: 0.392 | Acc: 84.666 | correct, total: (2609602,3082240)\n",
      "##########one 100 batch totally time cost 54.879\n",
      "batchIndex 701 |trainLen 1419 | Loss: 0.378 | Acc: 85.096 | correct, total: (3058552,3594240)\n",
      "##########one 100 batch totally time cost 62.637\n",
      "batchIndex 801 |trainLen 1419 | Loss: 0.367 | Acc: 85.466 | correct, total: (3509427,4106240)\n",
      "##########one 100 batch totally time cost 70.370\n",
      "batchIndex 901 |trainLen 1419 | Loss: 0.357 | Acc: 85.796 | correct, total: (3962265,4618240)\n",
      "##########one 100 batch totally time cost 77.978\n",
      "batchIndex 1001 |trainLen 1419 | Loss: 0.349 | Acc: 86.071 | correct, total: (4415643,5130240)\n",
      "##########one 100 batch totally time cost 85.602\n",
      "batchIndex 1101 |trainLen 1419 | Loss: 0.342 | Acc: 86.306 | correct, total: (4869614,5642240)\n",
      "##########one 100 batch totally time cost 93.280\n",
      "batchIndex 1201 |trainLen 1419 | Loss: 0.335 | Acc: 86.536 | correct, total: (5325614,6154240)\n",
      "##########one 100 batch totally time cost 100.892\n",
      "batchIndex 1301 |trainLen 1419 | Loss: 0.329 | Acc: 86.744 | correct, total: (5782581,6666240)\n",
      "##########one 100 batch totally time cost 108.558\n",
      "batchIndex 1401 |trainLen 1419 | Loss: 0.324 | Acc: 86.930 | correct, total: (6240060,7178240)\n"
     ]
    }
   ],
   "source": [
    "###用于测试csv和mlp\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# 五层神经网络\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 200)\n",
    "        self.fc3 = nn.Linear(200, 100)\n",
    "        self.fc4 = nn.Linear(100, num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "\n",
    "mlp = NeuralNet(22,200,4)\n",
    "print(mlp)\n",
    "\n",
    "##############################################读写CSV\n",
    "file1 = \"./trainData/dataAllSim.csv\"\n",
    "##方式1\n",
    "#data1=[]\n",
    "#csv_reader = csv.reader(open(file1))\n",
    "#for row in csv_reader:\n",
    "#        data1.append(row)\n",
    "#print(data1[0])        \n",
    "\n",
    "##方式2\n",
    "#https://blog.csdn.net/zw__chen/article/details/82806900\n",
    "csvfile = open(file1, 'r')\n",
    "xyData= np.loadtxt(file1,delimiter=',',skiprows=1)\n",
    "x = xyData[:,0:-1]\n",
    "y = xyData[:,-1]\n",
    "print(y.shape )\n",
    "print(x.shape )\n",
    "x1 =torch.from_numpy(x)\n",
    "y1 =torch.from_numpy(y)\n",
    "\n",
    "dataset1 = TensorDataset(x1.float(),y1.long())\n",
    "print(\"testing\")\n",
    "\n",
    "#train_dataset, test_dataset = random_split(\n",
    "#    dataset=dataset1,\n",
    "#    lengths=[7, 3],\n",
    "#    generator=torch.Generator().manual_seed(0)\n",
    "#)\n",
    "\n",
    "#################################\n",
    "#数据准备：平衡\n",
    "tmp = y\n",
    "trainratio = np.bincount(tmp.astype(\"int64\"))\n",
    "train_weights = 1./trainratio\n",
    "train_weights[0]= train_weights[0]*2\n",
    "train_sampleweights = torch.from_numpy(train_weights)\n",
    "train_sampler = WeightedRandomSampler(weights=train_sampleweights, num_samples = len(y))\n",
    "#train_loader = DataLoader( dataset1, batch_size=5120, num_workers=1, sampler=train_sampler)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset1, batch_size=2048*5, shuffle=True)\n",
    "\n",
    "#准备设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == 'cuda':\n",
    "    mlp = torch.nn.DataParallel(mlp)\n",
    "    cudnn.benchmark = True\n",
    "    mlp =  mlp.to(device)\n",
    "print(device)\n",
    "\n",
    "#准备模型\n",
    "modelPathName = \"./trainedModes/\"+\"redTLS.modeparams\"\n",
    "params = torch.load(modelPathName)\n",
    "mlp.load_state_dict(params['net'])\n",
    "\n",
    "\n",
    "#################################\n",
    "#训练开始\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mlp.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "running_loss = 0\n",
    "startEpoch = 0\n",
    "epochs = 3000#大概8小时\n",
    "print(\"start training\")\n",
    "\n",
    "for epoch in range(startEpoch, epochs):  # 多批次循环\n",
    "\n",
    "    mlp.train()\n",
    "    time_start = time.time()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "    Alllabels = []\n",
    "    Allpredicted = []\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # 获取输入\n",
    "        #print(epoch,i)\n",
    "        inputs, labels = data\n",
    "        #inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs=inputs.type(torch.float32)\n",
    "        labels=labels\n",
    "\n",
    "        if device == 'cuda':\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 梯度置0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 正向传播，反向传播，优化a\n",
    "        outputs = mlp(inputs)\n",
    "        #print(\"inputs:\",inputs)\n",
    "        #print(\"###################################\")\n",
    "        #print(\"outputs:\",outputs)\n",
    "        #print(\"labels\",labels)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        #print(\"loss:\",loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        Alllabels.extend(labels.numpy())\n",
    "        Allpredicted.extend(predicted.numpy())\n",
    "        #print(\"labels.size(0):\",labels.size(0))\n",
    "        #print(\"predicted:\",predicted)\n",
    "        #print(\"predicted.eq(labels).sum().item():\",predicted.eq(labels).sum().item())\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        #os.input()\n",
    "        if i % 100 == 99:  # 每100批次打印一次\n",
    "         time_end = time.time()\n",
    "         print('##########epoch：%d,one 100 batch totally time cost %.3f' %(epoch,time_end-time_start))\n",
    "         print(\"batchIndex %d |trainLen %d | Loss: %.3f | Acc: %.3f | correct, total: (%d,%d)\" % (\n",
    "             i, len(train_loader), running_loss/(i+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    time_end = time.time()\n",
    "    \n",
    "    print(\"end %d epoch,totally time cost %.3f\" %(epoch,time_end-time_start))\n",
    "    state = {\"net\": mlp.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    modelPathName = \"./trainedModes/\"+\"redTLS.modeparams\"\n",
    "    torch.save(state, modelPathName)\n",
    "    params = torch.load(modelPathName)\n",
    "    mlp.load_state_dict(params['net'])\n",
    "    optimizer.load_state_dict(params['optimizer'])\n",
    "    \n",
    "    \n",
    "    #用全训练集合进行评估\n",
    "    #print(\"start eavl\")\n",
    "    #mlp.eval()\n",
    "    #labels = y1.long()\n",
    "    #print(\"start eavl 1\")\n",
    "    #outputs = mlp(x1.type(torch.float32))\n",
    "    #print(\"start eavl 2\")\n",
    "    #_, predicted = torch.max(outputs.data,1)\n",
    "    \n",
    "    #print(\"start eavl 3\")\n",
    "    #total += labels.size(0)\n",
    "    #correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    #print(\"\\n\\n Eval--epochIndex %d |time: %d | Acc: %.3f | correct, total: (%d,%d)\" % (\n",
    "    #     epoch, (time_end-time_start), 100.*correct/total, correct, total))\n",
    "    tmp1 = classification_report(Alllabels,Allpredicted)\n",
    "    tmp2 = confusion_matrix(Alllabels,Allpredicted)\n",
    "    print(tmp1)\n",
    "    print(tmp2)\n",
    "  \n",
    "    print(\"########################################################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c006541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2710fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"net\": mlp.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "modelPathName = \"./trainedModes/\"+\"redTLS1.modeparams\"\n",
    "torch.save(state, modelPathName)\n",
    "params = torch.load(modelPathName)\n",
    "mlp.load_state_dict(params['net'])\n",
    "optimizer.load_state_dict(params['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7729a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = y\n",
    "trainratio = np.bincount(tmp.astype(\"int64\"))\n",
    "train_weights = 1./trainratio\n",
    "print(trainratio),print(trainratio/sum(trainratio)*100),print(train_weights/sum(train_weights)*100)\n",
    "\n",
    "train_sampleweights = torch.from_numpy(train_weights)\n",
    "train_sampler = WeightedRandomSampler(weights=train_sampleweights, num_samples = 2*len(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
